{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('insurance.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28</td>\n",
       "      <td>female</td>\n",
       "      <td>37.620</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3766.88380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>30.800</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>12105.32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>38.280</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>10226.28420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>56</td>\n",
       "      <td>male</td>\n",
       "      <td>19.950</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northeast</td>\n",
       "      <td>22412.64850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>38</td>\n",
       "      <td>male</td>\n",
       "      <td>19.300</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>15820.69900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     sex     bmi  children smoker     region      charges\n",
       "0    19    male     NaN         0    yes        NaN  16884.92400\n",
       "1    18    male  33.770         1     no        NaN   1725.55230\n",
       "2    28    male  33.000         3     no        NaN   4449.46200\n",
       "3    33    male  22.705         0     no        NaN  21984.47061\n",
       "4    32    male  28.880         0     no        NaN   3866.85520\n",
       "..  ...     ...     ...       ...    ...        ...          ...\n",
       "95   28  female  37.620         1     no  southeast   3766.88380\n",
       "96   54  female  30.800         3     no  southwest  12105.32000\n",
       "97   55    male  38.280         0     no  southeast  10226.28420\n",
       "98   56    male  19.950         0    yes  northeast  22412.64850\n",
       "99   38    male  19.300         0    yes  southwest  15820.69900\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Columns: 7 entries, age to charges\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=False,memory_usage=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1337 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1316 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of                age          bmi     children       charges\n",
       "count  1338.000000  1337.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.665464     1.094918  13270.422265\n",
       "std      14.049960     6.100000     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.290000     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.700000     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.transpose of                age          bmi     children       charges\n",
       "count  1338.000000  1337.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.665464     1.094918  13270.422265\n",
       "std      14.049960     6.100000     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.290000     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.700000     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(exclude='object').transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.   ,    nan],\n",
       "       [18.   , 33.77 ],\n",
       "       [28.   , 33.   ],\n",
       "       [33.   , 22.705],\n",
       "       [32.   , 28.88 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.values)\n",
    "df[['age','bmi']].head(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 'male' nan 0 'yes' nan 16884.924]\n",
      "[18 'male' 33.77 1 'no' nan 1725.5523]\n",
      "[28 'male' 33.0 3 'no' nan 4449.462]\n",
      "[33 'male' 22.705 0 'no' nan 21984.47061]\n",
      "[32 'male' 28.88 0 'no' nan 3866.8552]\n",
      "[31 'female' 25.74 0 'no' nan 3756.6216]\n",
      "[46 'female' 33.44 1 'no' nan 8240.5896]\n",
      "[37 'female' 27.74 3 'no' nan 7281.5056]\n",
      "[37 'male' 29.83 2 'no' nan 6406.4107]\n",
      "[60 'female' 25.84 0 'no' nan 28923.13692]\n",
      "[25 'male' 26.22 0 'no' nan 2721.3208]\n",
      "[62 'female' 26.29 0 'yes' nan 27808.7251]\n",
      "[23 'male' 34.4 0 'no' nan 1826.843]\n",
      "[56 'female' 39.82 0 'no' nan 11090.7178]\n",
      "[27 'male' 42.13 0 'yes' nan 39611.7577]\n",
      "[19 'male' 24.6 1 'no' nan 1837.237]\n",
      "[52 'female' 30.78 1 'no' nan 10797.3362]\n",
      "[23 'male' 23.845 0 'no' nan 2395.17155]\n",
      "[56 'male' 40.3 0 'no' nan 10602.385]\n",
      "[30 'male' 35.3 0 'yes' nan 36837.467]\n",
      "[60 'female' 36.005 0 'no' nan 13228.84695]\n",
      "[30 'female' 32.4 1 'no' nan 4149.736]\n",
      "[18 'male' 34.1 0 'no' 'southeast' 1137.011]\n",
      "[34 'female' 31.92 1 'yes' 'northeast' 37701.8768]\n",
      "[37 'male' 28.025 2 'no' 'northwest' 6203.90175]\n",
      "[59 'female' 27.72 3 'no' 'southeast' 14001.1338]\n",
      "[63 'female' 23.085 0 'no' 'northeast' 14451.83515]\n",
      "[55 'female' 32.775 2 'no' 'northwest' 12268.63225]\n",
      "[23 'male' 17.385 1 'no' 'northwest' 2775.19215]\n",
      "[31 'male' 36.3 2 'yes' 'southwest' 38711.0]\n",
      "[22 'male' 35.6 0 'yes' 'southwest' 35585.576]\n",
      "[18 'female' 26.315 0 'no' 'northeast' 2198.18985]\n",
      "[19 'female' 28.6 5 'no' 'southwest' 4687.797]\n",
      "[63 'male' 28.31 0 'no' 'northwest' 13770.0979]\n",
      "[28 'male' 36.4 1 'yes' 'southwest' 51194.55914]\n",
      "[19 'male' 20.425 0 'no' 'northwest' 1625.43375]\n",
      "[62 'female' 32.965 3 'no' 'northwest' 15612.19335]\n",
      "[26 'male' 20.8 0 'no' 'southwest' 2302.3]\n",
      "[35 'male' 36.67 1 'yes' 'northeast' 39774.2763]\n",
      "[60 'male' 39.9 0 'yes' 'southwest' 48173.361]\n",
      "[24 'female' 26.6 0 'no' 'northeast' 3046.062]\n",
      "[31 'female' 36.63 2 'no' 'southeast' 4949.7587]\n",
      "[41 'male' 21.78 1 'no' 'southeast' 6272.4772]\n",
      "[37 'female' 30.8 2 'no' 'southeast' 6313.759]\n",
      "[38 'male' 37.05 1 'no' 'northeast' 6079.6715]\n",
      "[55 'male' 37.3 0 'no' 'southwest' 20630.28351]\n",
      "[18 'female' 38.665 2 'no' 'northeast' 3393.35635]\n",
      "[28 'female' 34.77 0 'no' 'northwest' 3556.9223]\n",
      "[60 'female' 24.53 0 'no' 'southeast' 12629.8967]\n",
      "[36 'male' 35.2 1 'yes' 'southeast' 38709.176]\n",
      "[18 'female' 35.625 0 'no' 'northeast' 2211.13075]\n",
      "[21 'female' 33.63 2 'no' 'northwest' 3579.8287]\n",
      "[48 'male' 28.0 1 'yes' 'southwest' 23568.272]\n",
      "[36 'male' 34.43 0 'yes' 'southeast' 37742.5757]\n",
      "[40 'female' 28.69 3 'no' 'northwest' 8059.6791]\n",
      "[58 'male' 36.955 2 'yes' 'northwest' 47496.49445]\n",
      "[58 'female' 31.825 2 'no' 'northeast' 13607.36875]\n",
      "[18 'male' 31.68 2 'yes' 'southeast' 34303.1672]\n",
      "[53 'female' 22.88 1 'yes' 'southeast' 23244.7902]\n",
      "[34 'female' 37.335 2 'no' 'northwest' 5989.52365]\n",
      "[43 'male' 27.36 3 'no' 'northeast' 8606.2174]\n",
      "[25 'male' 33.66 4 'no' 'southeast' 4504.6624]\n",
      "[64 'male' 24.7 1 'no' 'northwest' 30166.61817]\n",
      "[28 'female' 25.935 1 'no' 'northwest' 4133.64165]\n",
      "[20 'female' 22.42 0 'yes' 'northwest' 14711.7438]\n",
      "[19 'female' 28.9 0 'no' 'southwest' 1743.214]\n",
      "[61 'female' 39.1 2 'no' 'southwest' 14235.072]\n",
      "[40 'male' 26.315 1 'no' 'northwest' 6389.37785]\n",
      "[40 'female' 36.19 0 'no' 'southeast' 5920.1041]\n",
      "[28 'male' 23.98 3 'yes' 'southeast' 17663.1442]\n",
      "[27 'female' 24.75 0 'yes' 'southeast' 16577.7795]\n",
      "[31 'male' 28.5 5 'no' 'northeast' 6799.458]\n",
      "[53 'female' 28.1 3 'no' 'southwest' 11741.726]\n",
      "[58 'male' 32.01 1 'no' 'southeast' 11946.6259]\n",
      "[44 'male' 27.4 2 'no' 'southwest' 7726.854]\n",
      "[57 'male' 34.01 0 'no' 'northwest' 11356.6609]\n",
      "[29 'female' 29.59 1 'no' 'southeast' 3947.4131]\n",
      "[21 'male' 35.53 0 'no' 'southeast' 1532.4697]\n",
      "[22 'female' 39.805 0 'no' 'northeast' 2755.02095]\n",
      "[41 'female' 32.965 0 'no' 'northwest' 6571.02435]\n",
      "[31 'male' 26.885 1 'no' 'northeast' 4441.21315]\n",
      "[45 'female' 38.285 0 'no' 'northeast' 7935.29115]\n",
      "[22 'male' 37.62 1 'yes' 'southeast' 37165.1638]\n",
      "[48 'female' 41.23 4 'no' 'northwest' 11033.6617]\n",
      "[37 'female' 34.8 2 'yes' 'southwest' 39836.519]\n",
      "[45 'male' 22.895 2 'yes' 'northwest' 21098.55405]\n",
      "[57 'female' 31.16 0 'yes' 'northwest' 43578.9394]\n",
      "[56 'female' 27.2 0 'no' 'southwest' 11073.176]\n",
      "[46 'female' 27.74 0 'no' 'northwest' 8026.6666]\n",
      "[55 'female' 26.98 0 'no' 'northwest' 11082.5772]\n",
      "[21 'female' 39.49 0 'no' 'southeast' 2026.9741]\n",
      "[53 'female' 24.795 1 'no' 'northwest' 10942.13205]\n",
      "[59 'male' 29.83 3 'yes' 'northeast' 30184.9367]\n",
      "[35 'male' 34.77 2 'no' 'northwest' 5729.0053]\n",
      "[64 'female' 31.3 2 'yes' 'southwest' 47291.055]\n",
      "[28 'female' 37.62 1 'no' 'southeast' 3766.8838]\n",
      "[54 'female' 30.8 3 'no' 'southwest' 12105.32]\n",
      "[55 'male' 38.28 0 'no' 'southeast' 10226.2842]\n",
      "[56 'male' 19.95 0 'yes' 'northeast' 22412.6485]\n",
      "[38 'male' 19.3 0 'yes' 'southwest' 15820.699]\n",
      "[41 'female' 31.6 0 'no' 'southwest' 6186.127]\n",
      "[30 'male' 25.46 0 'no' 'northeast' 3645.0894]\n",
      "[18 'female' 30.115 0 'no' 'northeast' 21344.8467]\n",
      "[61 'female' 29.92 3 'yes' 'southeast' 30942.1918]\n",
      "[34 'female' 27.5 1 'no' 'southwest' 5003.853]\n",
      "[20 'male' 28.025 1 'yes' 'northwest' 17560.37975]\n",
      "[19 'female' 28.4 1 'no' 'southwest' 2331.519]\n",
      "[26 'male' 30.875 2 'no' 'northwest' 3877.30425]\n",
      "[29 'male' 27.94 0 'no' 'southeast' 2867.1196]\n",
      "[63 'male' 35.09 0 'yes' 'southeast' 47055.5321]\n",
      "[54 'male' 33.63 1 'no' 'northwest' 10825.2537]\n",
      "[55 'female' 29.7 2 'no' 'southwest' 11881.358]\n",
      "[37 'male' 30.8 0 'no' 'southwest' 4646.759]\n",
      "[21 'female' 35.72 0 'no' 'northwest' 2404.7338]\n",
      "[52 'male' 32.205 3 'no' 'northeast' 11488.31695]\n",
      "[60 'male' 28.595 0 'no' 'northeast' 30259.99556]\n",
      "[58 'male' 49.06 0 'no' 'southeast' 11381.3254]\n",
      "[29 'female' 27.94 1 'yes' 'southeast' 19107.7796]\n",
      "[49 'female' 27.17 0 'no' 'southeast' 8601.3293]\n",
      "[37 'female' 23.37 2 'no' 'northwest' 6686.4313]\n",
      "[44 'male' 37.1 2 'no' 'southwest' 7740.337]\n",
      "[18 'male' 23.75 0 'no' 'northeast' 1705.6245]\n",
      "[20 'female' 28.975 0 'no' 'northwest' 2257.47525]\n",
      "[44 'male' 31.35 1 'yes' 'northeast' 39556.4945]\n",
      "[47 'female' 33.915 3 'no' 'northwest' 10115.00885]\n",
      "[26 'female' 28.785 0 'no' 'northeast' 3385.39915]\n",
      "[19 'female' 28.3 0 'yes' 'southwest' 17081.08]\n",
      "[52 'female' 37.4 0 'no' 'southwest' 9634.538]\n",
      "[32 'female' 17.765 2 'yes' 'northwest' 32734.1863]\n",
      "[38 'male' 34.7 2 'no' 'southwest' 6082.405]\n",
      "[59 'female' 26.505 0 'no' 'northeast' 12815.44495]\n",
      "[61 'female' 22.04 0 'no' 'northeast' 13616.3586]\n",
      "[53 'female' 35.9 2 'no' 'southwest' 11163.568]\n",
      "[19 'male' 25.555 0 'no' 'northwest' 1632.56445]\n",
      "[20 'female' 28.785 0 'no' 'northeast' 2457.21115]\n",
      "[22 'female' 28.05 0 'no' 'southeast' 2155.6815]\n",
      "[19 'male' 34.1 0 'no' 'southwest' 1261.442]\n",
      "[22 'male' 25.175 0 'no' 'northwest' 2045.68525]\n",
      "[54 'female' 31.9 3 'no' 'southeast' 27322.73386]\n",
      "[22 'female' 36.0 0 'no' 'southwest' 2166.732]\n",
      "[34 'male' 22.42 2 'no' 'northeast' 27375.90478]\n",
      "[26 'male' 32.49 1 'no' 'northeast' 3490.5491]\n",
      "[34 'male' 25.3 2 'yes' 'southeast' 18972.495]\n",
      "[29 'male' 29.735 2 'no' 'northwest' 18157.876]\n",
      "[30 'male' 28.69 3 'yes' 'northwest' 20745.9891]\n",
      "[29 'female' 38.83 3 'no' 'southeast' 5138.2567]\n",
      "[46 'male' 30.495 3 'yes' 'northwest' 40720.55105]\n",
      "[51 'female' 37.73 1 'no' 'southeast' 9877.6077]\n",
      "[53 'female' 37.43 1 'no' 'northwest' 10959.6947]\n",
      "[19 'male' 28.4 1 'no' 'southwest' 1842.519]\n",
      "[35 'male' 24.13 1 'no' 'northwest' 5125.2157]\n",
      "[48 'male' 29.7 0 'no' 'southeast' 7789.635]\n",
      "[32 'female' 37.145 3 'no' 'northeast' 6334.34355]\n",
      "[42 'female' 23.37 0 'yes' 'northeast' 19964.7463]\n",
      "[40 'female' 25.46 1 'no' 'northeast' 7077.1894]\n",
      "[44 'male' 39.52 0 'no' 'northwest' 6948.7008]\n",
      "[48 'male' 24.42 0 'yes' 'southeast' 21223.6758]\n",
      "[18 'male' 25.175 0 'yes' 'northeast' 15518.18025]\n",
      "[30 'male' 35.53 0 'yes' 'southeast' 36950.2567]\n",
      "[50 'female' 27.83 3 'no' 'southeast' 19749.38338]\n",
      "[42 'female' 26.6 0 'yes' 'northwest' 21348.706]\n",
      "[18 'female' 36.85 0 'yes' 'southeast' 36149.4835]\n",
      "[54 'male' 39.6 1 'no' 'southwest' 10450.552]\n",
      "[32 'female' 29.8 2 'no' 'southwest' 5152.134]\n",
      "[37 'male' 29.64 0 'no' 'northwest' 5028.1466]\n",
      "[47 'male' 28.215 4 'no' 'northeast' 10407.08585]\n",
      "[20 'female' 37.0 5 'no' 'southwest' 4830.63]\n",
      "[32 'female' 33.155 3 'no' 'northwest' 6128.79745]\n",
      "[19 'female' 31.825 1 'no' 'northwest' 2719.27975]\n",
      "[27 'male' 18.905 3 'no' 'northeast' 4827.90495]\n",
      "[63 'male' 41.47 0 'no' 'southeast' 13405.3903]\n",
      "[49 'male' 30.3 0 'no' 'southwest' 8116.68]\n",
      "[18 'male' 15.96 0 'no' 'northeast' 1694.7964]\n",
      "[35 'female' 34.8 1 'no' 'southwest' 5246.047]\n",
      "[24 'female' 33.345 0 'no' 'northwest' 2855.43755]\n",
      "[63 'female' 37.7 0 'yes' 'southwest' 48824.45]\n",
      "[38 'male' 27.835 2 'no' 'northwest' 6455.86265]\n",
      "[54 'male' 29.2 1 'no' 'southwest' 10436.096]\n",
      "[46 'female' 28.9 2 'no' 'southwest' 8823.279]\n",
      "[41 'female' 33.155 3 'no' 'northeast' 8538.28845]\n",
      "[58 'male' 28.595 0 'no' 'northwest' 11735.87905]\n",
      "[18 'female' 38.28 0 'no' 'southeast' 1631.8212]\n",
      "[22 'male' 19.95 3 'no' 'northeast' 4005.4225]\n",
      "[44 'female' 26.41 0 'no' 'northwest' 7419.4779]\n",
      "[44 'male' 30.69 2 'no' 'southeast' 7731.4271]\n",
      "[36 'male' 41.895 3 'yes' 'northeast' 43753.33705]\n",
      "[26 'female' 29.92 2 'no' 'southeast' 3981.9768]\n",
      "[30 'female' 30.9 3 'no' 'southwest' 5325.651]\n",
      "[41 'female' 32.2 1 'no' 'southwest' 6775.961]\n",
      "[29 'female' 32.11 2 'no' 'northwest' 4922.9159]\n",
      "[61 'male' 31.57 0 'no' 'southeast' 12557.6053]\n",
      "[36 'female' 26.2 0 'no' 'southwest' 4883.866]\n",
      "[25 'male' 25.74 0 'no' 'southeast' 2137.6536]\n",
      "[56 'female' 26.6 1 'no' 'northwest' 12044.342]\n",
      "[18 'male' 34.43 0 'no' 'southeast' 1137.4697]\n",
      "[19 'male' 30.59 0 'no' 'northwest' 1639.5631]\n",
      "[39 'female' 32.8 0 'no' 'southwest' 5649.715]\n",
      "[45 'female' 28.6 2 'no' 'southeast' 8516.829]\n",
      "[51 'female' 18.05 0 'no' 'northwest' 9644.2525]\n",
      "[64 'female' 39.33 0 'no' 'northeast' 14901.5167]\n",
      "[19 'female' 32.11 0 'no' 'northwest' 2130.6759]\n",
      "[48 'female' 32.23 1 'no' 'southeast' 8871.1517]\n",
      "[60 'female' 24.035 0 'no' 'northwest' 13012.20865]\n",
      "[27 'female' 36.08 0 'yes' 'southeast' 37133.8982]\n",
      "[46 'male' 22.3 0 'no' 'southwest' 7147.105]\n",
      "[28 'female' 28.88 1 'no' 'northeast' 4337.7352]\n",
      "[59 'male' 26.4 0 'no' 'southeast' 11743.299]\n",
      "[35 'male' 27.74 2 'yes' 'northeast' 20984.0936]\n",
      "[63 'female' 31.8 0 'no' 'southwest' 13880.949]\n",
      "[40 'male' 41.23 1 'no' 'northeast' 6610.1097]\n",
      "[20 'male' 33.0 1 'no' 'southwest' 1980.07]\n",
      "[40 'male' 30.875 4 'no' 'northwest' 8162.71625]\n",
      "[24 'male' 28.5 2 'no' 'northwest' 3537.703]\n",
      "[34 'female' 26.73 1 'no' 'southeast' 5002.7827]\n",
      "[45 'female' 30.9 2 'no' 'southwest' 8520.026]\n",
      "[41 'female' 37.1 2 'no' 'southwest' 7371.772]\n",
      "[53 'female' 26.6 0 'no' 'northwest' 10355.641]\n",
      "[27 'male' 23.1 0 'no' 'southeast' 2483.736]\n",
      "[26 'female' 29.92 1 'no' 'southeast' 3392.9768]\n",
      "[24 'female' 23.21 0 'no' 'southeast' 25081.76784]\n",
      "[34 'female' 33.7 1 'no' 'southwest' 5012.471]\n",
      "[53 'female' 33.25 0 'no' 'northeast' 10564.8845]\n",
      "[32 'male' 30.8 3 'no' 'southwest' 5253.524]\n",
      "[19 'male' 34.8 0 'yes' 'southwest' 34779.615]\n",
      "[42 'male' 24.64 0 'yes' 'southeast' 19515.5416]\n",
      "[55 'male' 33.88 3 'no' 'southeast' 11987.1682]\n",
      "[28 'male' 38.06 0 'no' 'southeast' 2689.4954]\n",
      "[58 'female' 41.91 0 'no' 'southeast' 24227.33724]\n",
      "[41 'female' 31.635 1 'no' 'northeast' 7358.17565]\n",
      "[47 'male' 25.46 2 'no' 'northeast' 9225.2564]\n",
      "[42 'female' 36.195 1 'no' 'northwest' 7443.64305]\n",
      "[59 'female' 27.83 3 'no' 'southeast' 14001.2867]\n",
      "[19 'female' 17.8 0 'no' 'southwest' 1727.785]\n",
      "[59 'male' 27.5 1 'no' 'southwest' 12333.828]\n",
      "[39 'male' 24.51 2 'no' 'northwest' 6710.1919]\n",
      "[40 'female' 22.22 2 'yes' 'southeast' 19444.2658]\n",
      "[18 'female' 26.73 0 'no' 'southeast' 1615.7667]\n",
      "[31 'male' 38.39 2 'no' 'southeast' 4463.2051]\n",
      "[19 'male' 29.07 0 'yes' 'northwest' 17352.6803]\n",
      "[44 'male' 38.06 1 'no' 'southeast' 7152.6714]\n",
      "[23 'female' 36.67 2 'yes' 'northeast' 38511.6283]\n",
      "[33 'female' 22.135 1 'no' 'northeast' 5354.07465]\n",
      "[55 'female' 26.8 1 'no' 'southwest' 35160.13457]\n",
      "[40 'male' 35.3 3 'no' 'southwest' 7196.867]\n",
      "[63 'female' 27.74 0 'yes' 'northeast' 29523.1656]\n",
      "[54 'male' 30.02 0 'no' 'northwest' 24476.47851]\n",
      "[60 'female' 38.06 0 'no' 'southeast' 12648.7034]\n",
      "[24 'male' 35.86 0 'no' 'southeast' 1986.9334]\n",
      "[19 'male' 20.9 1 'no' 'southwest' 1832.094]\n",
      "[29 'male' 28.975 1 'no' 'northeast' 4040.55825]\n",
      "[18 'male' 17.29 2 'yes' 'northeast' 12829.4551]\n",
      "[63 'female' 32.2 2 'yes' 'southwest' 47305.305]\n",
      "[54 'male' 34.21 2 'yes' 'southeast' 44260.7499]\n",
      "[27 'male' 30.3 3 'no' 'southwest' 4260.744]\n",
      "[50 'male' 31.825 0 'yes' 'northeast' 41097.16175]\n",
      "[55 'female' 25.365 3 'no' 'northeast' 13047.33235]\n",
      "[56 'male' 33.63 0 'yes' 'northwest' 43921.1837]\n",
      "[38 'female' 40.15 0 'no' 'southeast' 5400.9805]\n",
      "[51 'male' 24.415 4 'no' 'northwest' 11520.09985]\n",
      "[19 'male' 31.92 0 'yes' 'northwest' 33750.2918]\n",
      "[58 'female' 25.2 0 'no' 'southwest' 11837.16]\n",
      "[20 'female' 26.84 1 'yes' 'southeast' 17085.2676]\n",
      "[52 'male' 24.32 3 'yes' 'northeast' 24869.8368]\n",
      "[19 'male' 36.955 0 'yes' 'northwest' 36219.40545]\n",
      "[53 'female' 38.06 3 'no' 'southeast' 20462.99766]\n",
      "[46 'male' 42.35 3 'yes' 'southeast' 46151.1245]\n",
      "[40 'male' 19.8 1 'yes' 'southeast' 17179.522]\n",
      "[59 'female' 32.395 3 'no' 'northeast' 14590.63205]\n",
      "[45 'male' 30.2 1 'no' 'southwest' 7441.053]\n",
      "[49 'male' 25.84 1 'no' 'northeast' 9282.4806]\n",
      "[18 'male' 29.37 1 'no' 'southeast' 1719.4363]\n",
      "[50 'male' 34.2 2 'yes' 'southwest' 42856.838]\n",
      "[41 'male' 37.05 2 'no' 'northwest' 7265.7025]\n",
      "[50 'male' 27.455 1 'no' 'northeast' 9617.66245]\n",
      "[25 'male' 27.55 0 'no' 'northwest' 2523.1695]\n",
      "[47 'female' 26.6 2 'no' 'northeast' 9715.841]\n",
      "[19 'male' 20.615 2 'no' 'northwest' 2803.69785]\n",
      "[22 'female' 24.3 0 'no' 'southwest' 2150.469]\n",
      "[59 'male' 31.79 2 'no' 'southeast' 12928.7911]\n",
      "[51 'female' 21.56 1 'no' 'southeast' 9855.1314]\n",
      "[40 'female' 28.12 1 'yes' 'northeast' 22331.5668]\n",
      "[54 'male' 40.565 3 'yes' 'northeast' 48549.17835]\n",
      "[30 'male' 27.645 1 'no' 'northeast' 4237.12655]\n",
      "[55 'female' 32.395 1 'no' 'northeast' 11879.10405]\n",
      "[52 'female' 31.2 0 'no' 'southwest' 9625.92]\n",
      "[46 'male' 26.62 1 'no' 'southeast' 7742.1098]\n",
      "[46 'female' 48.07 2 'no' 'northeast' 9432.9253]\n",
      "[63 'female' 26.22 0 'no' 'northwest' 14256.1928]\n",
      "[59 'female' 36.765 1 'yes' 'northeast' 47896.79135]\n",
      "[52 'male' 26.4 3 'no' 'southeast' 25992.82104]\n",
      "[28 'female' 33.4 0 'no' 'southwest' 3172.018]\n",
      "[29 'male' 29.64 1 'no' 'northeast' 20277.80751]\n",
      "[25 'male' 45.54 2 'yes' 'southeast' 42112.2356]\n",
      "[22 'female' 28.82 0 'no' 'southeast' 2156.7518]\n",
      "[25 'male' 26.8 3 'no' 'southwest' 3906.127]\n",
      "[18 'male' 22.99 0 'no' 'northeast' 1704.5681]\n",
      "[19 'male' 27.7 0 'yes' 'southwest' 16297.846]\n",
      "[47 'male' 25.41 1 'yes' 'southeast' 21978.6769]\n",
      "[31 'male' 34.39 3 'yes' 'northwest' 38746.3551]\n",
      "[48 'female' 28.88 1 'no' 'northwest' 9249.4952]\n",
      "[36 'male' 27.55 3 'no' 'northeast' 6746.7425]\n",
      "[53 'female' 22.61 3 'yes' 'northeast' 24873.3849]\n",
      "[56 'female' 37.51 2 'no' 'southeast' 12265.5069]\n",
      "[28 'female' 33.0 2 'no' 'southeast' 4349.462]\n",
      "[57 'female' 38.0 2 'no' 'southwest' 12646.207]\n",
      "[29 'male' 33.345 2 'no' 'northwest' 19442.3535]\n",
      "[28 'female' 27.5 2 'no' 'southwest' 20177.67113]\n",
      "[30 'female' 33.33 1 'no' 'southeast' 4151.0287]\n",
      "[58 'male' 34.865 0 'no' 'northeast' 11944.59435]\n",
      "[41 'female' 33.06 2 'no' 'northwest' 7749.1564]\n",
      "[50 'male' 26.6 0 'no' 'southwest' 8444.474]\n",
      "[19 'female' 24.7 0 'no' 'southwest' 1737.376]\n",
      "[43 'male' 35.97 3 'yes' 'southeast' 42124.5153]\n",
      "[49 'male' 35.86 0 'no' 'southeast' 8124.4084]\n",
      "[27 'female' 31.4 0 'yes' 'southwest' 34838.873]\n",
      "[52 'male' 33.25 0 'no' 'northeast' 9722.7695]\n",
      "[50 'male' 32.205 0 'no' 'northwest' 8835.26495]\n",
      "[54 'male' 32.775 0 'no' 'northeast' 10435.06525]\n",
      "[44 'female' 27.645 0 'no' 'northwest' 7421.19455]\n",
      "[32 'male' 37.335 1 'no' 'northeast' 4667.60765]\n",
      "[34 'male' 25.27 1 'no' 'northwest' 4894.7533]\n",
      "[26 'female' 29.64 4 'no' 'northeast' 24671.66334]\n",
      "[34 'male' 30.8 0 'yes' 'southwest' 35491.64]\n",
      "[57 'male' 40.945 0 'no' 'northeast' 11566.30055]\n",
      "[29 'male' 27.2 0 'no' 'southwest' 2866.091]\n",
      "[40 'male' 34.105 1 'no' 'northeast' 6600.20595]\n",
      "[27 'female' 23.21 1 'no' 'southeast' 3561.8889]\n",
      "[45 'male' 36.48 2 'yes' 'northwest' 42760.5022]\n",
      "[64 'female' 33.8 1 'yes' 'southwest' 47928.03]\n",
      "[52 'male' 36.7 0 'no' 'southwest' 9144.565]\n",
      "[61 'female' 36.385 1 'yes' 'northeast' 48517.56315]\n",
      "[52 'male' 27.36 0 'yes' 'northwest' 24393.6224]\n",
      "[61 'female' 31.16 0 'no' 'northwest' 13429.0354]\n",
      "[56 'female' 28.785 0 'no' 'northeast' 11658.37915]\n",
      "[43 'female' 35.72 2 'no' 'northeast' 19144.57652]\n",
      "[64 'male' 34.5 0 'no' 'southwest' 13822.803]\n",
      "[60 'male' 25.74 0 'no' 'southeast' 12142.5786]\n",
      "[62 'male' 27.55 1 'no' 'northwest' 13937.6665]\n",
      "[50 'male' 32.3 1 'yes' 'northeast' 41919.097]\n",
      "[46 'female' 27.72 1 'no' 'southeast' 8232.6388]\n",
      "[24 'female' 27.6 0 'no' 'southwest' 18955.22017]\n",
      "[62 'male' 30.02 0 'no' 'northwest' 13352.0998]\n",
      "[60 'female' 27.55 0 'no' 'northeast' 13217.0945]\n",
      "[63 'male' 36.765 0 'no' 'northeast' 13981.85035]\n",
      "[49 'female' 41.47 4 'no' 'southeast' 10977.2063]\n",
      "[34 'female' 29.26 3 'no' 'southeast' 6184.2994]\n",
      "[33 'male' 35.75 2 'no' 'southeast' 4889.9995]\n",
      "[46 'male' 33.345 1 'no' 'northeast' 8334.45755]\n",
      "[36 'female' 29.92 1 'no' 'southeast' 5478.0368]\n",
      "[19 'male' 27.835 0 'no' 'northwest' 1635.73365]\n",
      "[57 'female' 23.18 0 'no' 'northwest' 11830.6072]\n",
      "[50 'female' 25.6 0 'no' 'southwest' 8932.084]\n",
      "[30 'female' 27.7 0 'no' 'southwest' 3554.203]\n",
      "[33 'male' 35.245 0 'no' 'northeast' 12404.8791]\n",
      "[18 'female' 38.28 0 'no' 'southeast' 14133.03775]\n",
      "[46 'male' 27.6 0 'no' 'southwest' 24603.04837]\n",
      "[46 'male' 43.89 3 'no' 'southeast' 8944.1151]\n",
      "[47 'male' 29.83 3 'no' 'northwest' 9620.3307]\n",
      "[23 'male' 41.91 0 'no' 'southeast' 1837.2819]\n",
      "[18 'female' 20.79 0 'no' 'southeast' 1607.5101]\n",
      "[48 'female' 32.3 2 'no' 'northeast' 10043.249]\n",
      "[35 'male' 30.5 1 'no' 'southwest' 4751.07]\n",
      "[19 'female' 21.7 0 'yes' 'southwest' 13844.506]\n",
      "[21 'female' 26.4 1 'no' 'southwest' 2597.779]\n",
      "[21 'female' 21.89 2 'no' 'southeast' 3180.5101]\n",
      "[49 'female' 30.78 1 'no' 'northeast' 9778.3472]\n",
      "[56 'female' 32.3 3 'no' 'northeast' 13430.265]\n",
      "[42 'female' 24.985 2 'no' 'northwest' 8017.06115]\n",
      "[44 'male' 32.015 2 'no' 'northwest' 8116.26885]\n",
      "[18 'male' 30.4 3 'no' 'northeast' 3481.868]\n",
      "[61 'female' 21.09 0 'no' 'northwest' 13415.0381]\n",
      "[57 'female' 22.23 0 'no' 'northeast' 12029.2867]\n",
      "[42 'female' 33.155 1 'no' 'northeast' 7639.41745]\n",
      "[26 'male' 32.9 2 'yes' 'southwest' 36085.219]\n",
      "[20 'male' 33.33 0 'no' 'southeast' 1391.5287]\n",
      "[23 'female' 28.31 0 'yes' 'northwest' 18033.9679]\n",
      "[39 'female' 24.89 3 'yes' 'northeast' 21659.9301]\n",
      "[24 'male' 40.15 0 'yes' 'southeast' 38126.2465]\n",
      "[64 'female' 30.115 3 'no' 'northwest' 16455.70785]\n",
      "[62 'male' 31.46 1 'no' 'southeast' 27000.98473]\n",
      "[27 'female' 17.955 2 'yes' 'northeast' 15006.57945]\n",
      "[55 'male' 30.685 0 'yes' 'northeast' 42303.69215]\n",
      "[55 'male' 33.0 0 'no' 'southeast' 20781.48892]\n",
      "[35 'female' 43.34 2 'no' 'southeast' 5846.9176]\n",
      "[44 'male' 22.135 2 'no' 'northeast' 8302.53565]\n",
      "[19 'male' 34.4 0 'no' 'southwest' 1261.859]\n",
      "[58 'female' 39.05 0 'no' 'southeast' 11856.4115]\n",
      "[50 'male' 25.365 2 'no' 'northwest' 30284.64294]\n",
      "[26 'female' 22.61 0 'no' 'northwest' 3176.8159]\n",
      "[24 'female' 30.21 3 'no' 'northwest' 4618.0799]\n",
      "[48 'male' 35.625 4 'no' 'northeast' 10736.87075]\n",
      "[19 'female' 37.43 0 'no' 'northwest' 2138.0707]\n",
      "[48 'male' 31.445 1 'no' 'northeast' 8964.06055]\n",
      "[49 'male' 31.35 1 'no' 'northeast' 9290.1395]\n",
      "[46 'female' 32.3 2 'no' 'northeast' 9411.005]\n",
      "[46 'male' 19.855 0 'no' 'northwest' 7526.70645]\n",
      "[43 'female' 34.4 3 'no' 'southwest' 8522.003]\n",
      "[21 'male' 31.02 0 'no' 'southeast' 16586.49771]\n",
      "[64 'male' 25.6 2 'no' 'southwest' 14988.432]\n",
      "[18 'female' 38.17 0 'no' 'southeast' 1631.6683]\n",
      "[51 'female' 20.6 0 'no' 'southwest' 9264.797]\n",
      "[47 'male' 47.52 1 'no' 'southeast' 8083.9198]\n",
      "[64 'female' 32.965 0 'no' 'northwest' 14692.66935]\n",
      "[49 'male' 32.3 3 'no' 'northwest' 10269.46]\n",
      "[31 'male' 20.4 0 'no' 'southwest' 3260.199]\n",
      "[52 'female' 38.38 2 'no' 'northeast' 11396.9002]\n",
      "[33 'female' 24.31 0 'no' 'southeast' 4185.0979]\n",
      "[47 'female' 23.6 1 'no' 'southwest' 8539.671]\n",
      "[38 'male' 21.12 3 'no' 'southeast' 6652.5288]\n",
      "[32 'male' 30.03 1 'no' 'southeast' 4074.4537]\n",
      "[19 'male' 17.48 0 'no' 'northwest' 1621.3402]\n",
      "[44 'female' 20.235 1 'yes' 'northeast' 19594.80965]\n",
      "[26 'female' 17.195 2 'yes' 'northeast' 14455.64405]\n",
      "[25 'male' 23.9 5 'no' 'southwest' 5080.096]\n",
      "[19 'female' 35.15 0 'no' 'northwest' 2134.9015]\n",
      "[43 'female' 35.64 1 'no' 'southeast' 7345.7266]\n",
      "[52 'male' 34.1 0 'no' 'southeast' 9140.951]\n",
      "[36 'female' 22.6 2 'yes' 'southwest' 18608.262]\n",
      "[64 'male' 39.16 1 'no' 'southeast' 14418.2804]\n",
      "[63 'female' 26.98 0 'yes' 'northwest' 28950.4692]\n",
      "[64 'male' 33.88 0 'yes' 'southeast' 46889.2612]\n",
      "[61 'male' 35.86 0 'yes' 'southeast' 46599.1084]\n",
      "[40 'male' 32.775 1 'yes' 'northeast' 39125.33225]\n",
      "[25 'male' 30.59 0 'no' 'northeast' 2727.3951]\n",
      "[48 'male' 30.2 2 'no' 'southwest' 8968.33]\n",
      "[45 'male' 24.31 5 'no' 'southeast' 9788.8659]\n",
      "[38 'female' 27.265 1 'no' 'northeast' 6555.07035]\n",
      "[18 'female' 29.165 0 'no' 'northeast' 7323.734819]\n",
      "[21 'female' 16.815 1 'no' 'northeast' 3167.45585]\n",
      "[27 'female' 30.4 3 'no' 'northwest' 18804.7524]\n",
      "[19 'male' 33.1 0 'no' 'southwest' 23082.95533]\n",
      "[29 'female' 20.235 2 'no' 'northwest' 4906.40965]\n",
      "[42 'male' 26.9 0 'no' 'southwest' 5969.723]\n",
      "[60 'female' 30.5 0 'no' 'southwest' 12638.195]\n",
      "[31 'male' 28.595 1 'no' 'northwest' 4243.59005]\n",
      "[60 'male' 33.11 3 'no' 'southeast' 13919.8229]\n",
      "[22 'male' 31.73 0 'no' 'northeast' 2254.7967]\n",
      "[35 'male' 28.9 3 'no' 'southwest' 5926.846]\n",
      "[52 'female' 46.75 5 'no' 'southeast' 12592.5345]\n",
      "[26 'male' 29.45 0 'no' 'northeast' 2897.3235]\n",
      "[31 'female' 32.68 1 'no' 'northwest' 4738.2682]\n",
      "[33 'female' 33.5 0 'yes' 'southwest' 37079.372]\n",
      "[18 'male' 43.01 0 'no' 'southeast' 1149.3959]\n",
      "[59 'female' 36.52 1 'no' 'southeast' 28287.89766]\n",
      "[56 'male' 26.695 1 'yes' 'northwest' 26109.32905]\n",
      "[45 'female' 33.1 0 'no' 'southwest' 7345.084]\n",
      "[60 'male' 29.64 0 'no' 'northeast' 12730.9996]\n",
      "[56 'female' 25.65 0 'no' 'northwest' 11454.0215]\n",
      "[40 'female' 29.6 0 'no' 'southwest' 5910.944]\n",
      "[35 'male' 38.6 1 'no' 'southwest' 4762.329]\n",
      "[39 'male' 29.6 4 'no' 'southwest' 7512.267]\n",
      "[30 'male' 24.13 1 'no' 'northwest' 4032.2407]\n",
      "[24 'male' 23.4 0 'no' 'southwest' 1969.614]\n",
      "[20 'male' 29.735 0 'no' 'northwest' 1769.53165]\n",
      "[32 'male' 46.53 2 'no' 'southeast' 4686.3887]\n",
      "[59 'male' 37.4 0 'no' 'southwest' 21797.0004]\n",
      "[55 'female' 30.14 2 'no' 'southeast' 11881.9696]\n",
      "[57 'female' 30.495 0 'no' 'northwest' 11840.77505]\n",
      "[56 'male' 39.6 0 'no' 'southwest' 10601.412]\n",
      "[40 'female' 33.0 3 'no' 'southeast' 7682.67]\n",
      "[49 'female' 36.63 3 'no' 'southeast' 10381.4787]\n",
      "[42 'male' 30.0 0 'yes' 'southwest' 22144.032]\n",
      "[62 'female' 38.095 2 'no' 'northeast' 15230.32405]\n",
      "[56 'male' 25.935 0 'no' 'northeast' 11165.41765]\n",
      "[19 'male' 25.175 0 'no' 'northwest' 1632.03625]\n",
      "[30 'female' 28.38 1 'yes' 'southeast' 19521.9682]\n",
      "[60 'female' 28.7 1 'no' 'southwest' 13224.693]\n",
      "[56 'female' 33.82 2 'no' 'northwest' 12643.3778]\n",
      "[28 'female' 24.32 1 'no' 'northeast' 23288.9284]\n",
      "[18 'female' 24.09 1 'no' 'southeast' 2201.0971]\n",
      "[27 'male' 32.67 0 'no' 'southeast' 2497.0383]\n",
      "[18 'female' 30.115 0 'no' 'northeast' 2203.47185]\n",
      "[19 'female' 29.8 0 'no' 'southwest' 1744.465]\n",
      "[47 'female' 33.345 0 'no' 'northeast' 20878.78443]\n",
      "[54 'male' 25.1 3 'yes' 'southwest' 25382.297]\n",
      "[61 'male' 28.31 1 'yes' 'northwest' 28868.6639]\n",
      "[24 'male' 28.5 0 'yes' 'northeast' 35147.52848]\n",
      "[25 'male' 35.625 0 'no' 'northwest' 2534.39375]\n",
      "[21 'male' 36.85 0 'no' 'southeast' 1534.3045]\n",
      "[23 'male' 32.56 0 'no' 'southeast' 1824.2854]\n",
      "[63 'male' 41.325 3 'no' 'northwest' 15555.18875]\n",
      "[49 'male' 37.51 2 'no' 'southeast' 9304.7019]\n",
      "[18 'female' 31.35 0 'no' 'southeast' 1622.1885]\n",
      "[51 'female' 39.5 1 'no' 'southwest' 9880.068]\n",
      "[48 'male' 34.3 3 'no' 'southwest' 9563.029]\n",
      "[31 'female' 31.065 0 'no' 'northeast' 4347.02335]\n",
      "[54 'female' 21.47 3 'no' 'northwest' 12475.3513]\n",
      "[19 'male' 28.7 0 'no' 'southwest' 1253.936]\n",
      "[44 'female' 38.06 0 'yes' 'southeast' 48885.13561]\n",
      "[53 'male' 31.16 1 'no' 'northwest' 10461.9794]\n",
      "[19 'female' 32.9 0 'no' 'southwest' 1748.774]\n",
      "[61 'female' 25.08 0 'no' 'southeast' 24513.09126]\n",
      "[18 'female' 25.08 0 'no' 'northeast' 2196.4732]\n",
      "[61 'male' 43.4 0 'no' 'southwest' 12574.049]\n",
      "[21 'male' 25.7 4 'yes' 'southwest' 17942.106]\n",
      "[20 'male' 27.93 0 'no' 'northeast' 1967.0227]\n",
      "[31 'female' 23.6 2 'no' 'southwest' 4931.647]\n",
      "[45 'male' 28.7 2 'no' 'southwest' 8027.968]\n",
      "[44 'female' 23.98 2 'no' 'southeast' 8211.1002]\n",
      "[62 'female' 39.2 0 'no' 'southwest' 13470.86]\n",
      "[29 'male' 34.4 0 'yes' 'southwest' 36197.699]\n",
      "[43 'male' 26.03 0 'no' 'northeast' 6837.3687]\n",
      "[51 'male' 23.21 1 'yes' 'southeast' 22218.1149]\n",
      "[19 'male' 30.25 0 'yes' 'southeast' 32548.3405]\n",
      "[38 'female' 28.93 1 'no' 'southeast' 5974.3847]\n",
      "[37 'male' 30.875 3 'no' 'northwest' 6796.86325]\n",
      "[22 'male' 31.35 1 'no' 'northwest' 2643.2685]\n",
      "[21 'male' 23.75 2 'no' 'northwest' 3077.0955]\n",
      "[24 'female' 25.27 0 'no' 'northeast' 3044.2133]\n",
      "[57 'female' 28.7 0 'no' 'southwest' 11455.28]\n",
      "[56 'male' 32.11 1 'no' 'northeast' 11763.0009]\n",
      "[27 'male' 33.66 0 'no' 'southeast' 2498.4144]\n",
      "[51 'male' 22.42 0 'no' 'northeast' 9361.3268]\n",
      "[19 'male' 30.4 0 'no' 'southwest' 1256.299]\n",
      "[39 'male' 28.3 1 'yes' 'southwest' 21082.16]\n",
      "[58 'male' 35.7 0 'no' 'southwest' 11362.755]\n",
      "[20 'male' 35.31 1 'no' 'southeast' 27724.28875]\n",
      "[45 'male' 30.495 2 'no' 'northwest' 8413.46305]\n",
      "[35 'female' 31.0 1 'no' 'southwest' 5240.765]\n",
      "[31 'male' 30.875 0 'no' 'northeast' 3857.75925]\n",
      "[50 'female' 27.36 0 'no' 'northeast' 25656.57526]\n",
      "[32 'female' 44.22 0 'no' 'southeast' 3994.1778]\n",
      "[51 'female' 33.915 0 'no' 'northeast' 9866.30485]\n",
      "[38 'female' 37.73 0 'no' 'southeast' 5397.6167]\n",
      "[42 'male' 26.07 1 'yes' 'southeast' 38245.59327]\n",
      "[18 'female' 33.88 0 'no' 'southeast' 11482.63485]\n",
      "[19 'female' 30.59 2 'no' 'northwest' 24059.68019]\n",
      "[51 'female' 25.8 1 'no' 'southwest' 9861.025]\n",
      "[46 'male' 39.425 1 'no' 'northeast' 8342.90875]\n",
      "[18 'male' 25.46 0 'no' 'northeast' 1708.0014]\n",
      "[57 'male' 42.13 1 'yes' 'southeast' 48675.5177]\n",
      "[62 'female' 31.73 0 'no' 'northeast' 14043.4767]\n",
      "[59 'male' 29.7 2 'no' 'southeast' 12925.886]\n",
      "[37 'male' 36.19 0 'no' 'southeast' 19214.70553]\n",
      "[64 'male' 40.48 0 'no' 'southeast' 13831.1152]\n",
      "[38 'male' 28.025 1 'no' 'northeast' 6067.12675]\n",
      "[33 'female' 38.9 3 'no' 'southwest' 5972.378]\n",
      "[46 'female' 30.2 2 'no' 'southwest' 8825.086]\n",
      "[46 'female' 28.05 1 'no' 'southeast' 8233.0975]\n",
      "[53 'male' 31.35 0 'no' 'southeast' 27346.04207]\n",
      "[34 'female' 38.0 3 'no' 'southwest' 6196.448]\n",
      "[20 'female' 31.79 2 'no' 'southeast' 3056.3881]\n",
      "[63 'female' 36.3 0 'no' 'southeast' 13887.204]\n",
      "[54 'female' 47.41 0 'yes' 'southeast' 63770.42801]\n",
      "[54 'male' 30.21 0 'no' 'northwest' 10231.4999]\n",
      "[49 'male' 25.84 2 'yes' 'northwest' 23807.2406]\n",
      "[28 'male' 35.435 0 'no' 'northeast' 3268.84665]\n",
      "[54 'female' 46.7 2 'no' 'southwest' 11538.421]\n",
      "[25 'female' 28.595 0 'no' 'northeast' 3213.62205]\n",
      "[43 'female' 46.2 0 'yes' 'southeast' 45863.205]\n",
      "[63 'male' 30.8 0 'no' 'southwest' 13390.559]\n",
      "[32 'female' 28.93 0 'no' 'southeast' 3972.9247]\n",
      "[62 'male' 21.4 0 'no' 'southwest' 12957.118]\n",
      "[52 'female' 31.73 2 'no' 'northwest' 11187.6567]\n",
      "[25 'female' 41.325 0 'no' 'northeast' 17878.90068]\n",
      "[28 'male' 23.8 2 'no' 'southwest' 3847.674]\n",
      "[46 'male' 33.44 1 'no' 'northeast' 8334.5896]\n",
      "[34 'male' 34.21 0 'no' 'southeast' 3935.1799]\n",
      "[35 'female' 34.105 3 'yes' 'northwest' 39983.42595]\n",
      "[19 'male' 35.53 0 'no' 'northwest' 1646.4297]\n",
      "[46 'female' 19.95 2 'no' 'northwest' 9193.8385]\n",
      "[54 'female' 32.68 0 'no' 'northeast' 10923.9332]\n",
      "[27 'male' 30.5 0 'no' 'southwest' 2494.022]\n",
      "[50 'male' 44.77 1 'no' 'southeast' 9058.7303]\n",
      "[18 'female' 32.12 2 'no' 'southeast' 2801.2588]\n",
      "[19 'female' 30.495 0 'no' 'northwest' 2128.43105]\n",
      "[38 'female' 40.565 1 'no' 'northwest' 6373.55735]\n",
      "[41 'male' 30.59 2 'no' 'northwest' 7256.7231]\n",
      "[49 'female' 31.9 5 'no' 'southwest' 11552.904]\n",
      "[48 'male' 40.565 2 'yes' 'northwest' 45702.02235]\n",
      "[31 'female' 29.1 0 'no' 'southwest' 3761.292]\n",
      "[18 'female' 37.29 1 'no' 'southeast' 2219.4451]\n",
      "[30 'female' 43.12 2 'no' 'southeast' 4753.6368]\n",
      "[62 'female' 36.86 1 'no' 'northeast' 31620.00106]\n",
      "[57 'female' 34.295 2 'no' 'northeast' 13224.05705]\n",
      "[58 'female' 27.17 0 'no' 'northwest' 12222.8983]\n",
      "[22 'male' 26.84 0 'no' 'southeast' 1664.9996]\n",
      "[31 'female' 38.095 1 'yes' 'northeast' 58571.07448]\n",
      "[52 'male' 30.2 1 'no' 'southwest' 9724.53]\n",
      "[25 'female' 23.465 0 'no' 'northeast' 3206.49135]\n",
      "[59 'male' 25.46 1 'no' 'northeast' 12913.9924]\n",
      "[19 'male' 30.59 0 'no' 'northwest' 1639.5631]\n",
      "[39 'male' 45.43 2 'no' 'southeast' 6356.2707]\n",
      "[32 'female' 23.65 1 'no' 'southeast' 17626.23951]\n",
      "[19 'male' 20.7 0 'no' 'southwest' 1242.816]\n",
      "[33 'female' 28.27 1 'no' 'southeast' 4779.6023]\n",
      "[21 'male' 20.235 3 'no' 'northeast' 3861.20965]\n",
      "[34 'female' 30.21 1 'yes' 'northwest' 43943.8761]\n",
      "[61 'female' 35.91 0 'no' 'northeast' 13635.6379]\n",
      "[38 'female' 30.69 1 'no' 'southeast' 5976.8311]\n",
      "[58 'female' 29.0 0 'no' 'southwest' 11842.442]\n",
      "[47 'male' 19.57 1 'no' 'northwest' 8428.0693]\n",
      "[20 'male' 31.13 2 'no' 'southeast' 2566.4707]\n",
      "[21 'female' 21.85 1 'yes' 'northeast' 15359.1045]\n",
      "[41 'male' 40.26 0 'no' 'southeast' 5709.1644]\n",
      "[46 'female' 33.725 1 'no' 'northeast' 8823.98575]\n",
      "[42 'female' 29.48 2 'no' 'southeast' 7640.3092]\n",
      "[34 'female' 33.25 1 'no' 'northeast' 5594.8455]\n",
      "[43 'male' 32.6 2 'no' 'southwest' 7441.501]\n",
      "[52 'female' 37.525 2 'no' 'northwest' 33471.97189]\n",
      "[18 'female' 39.16 0 'no' 'southeast' 1633.0444]\n",
      "[51 'male' 31.635 0 'no' 'northwest' 9174.13565]\n",
      "[56 'female' 25.3 0 'no' 'southwest' 11070.535]\n",
      "[64 'female' 39.05 3 'no' 'southeast' 16085.1275]\n",
      "[19 'female' 28.31 0 'yes' 'northwest' 17468.9839]\n",
      "[51 'female' 34.1 0 'no' 'southeast' 9283.562]\n",
      "[27 'female' 25.175 0 'no' 'northeast' 3558.62025]\n",
      "[59 'female' 23.655 0 'yes' 'northwest' 25678.77845]\n",
      "[28 'male' 26.98 2 'no' 'northeast' 4435.0942]\n",
      "[30 'male' 37.8 2 'yes' 'southwest' 39241.442]\n",
      "[47 'female' 29.37 1 'no' 'southeast' 8547.6913]\n",
      "[38 'female' 34.8 2 'no' 'southwest' 6571.544]\n",
      "[18 'female' 33.155 0 'no' 'northeast' 2207.69745]\n",
      "[34 'female' 19.0 3 'no' 'northeast' 6753.038]\n",
      "[20 'female' 33.0 0 'no' 'southeast' 1880.07]\n",
      "[47 'female' 36.63 1 'yes' 'southeast' 42969.8527]\n",
      "[56 'female' 28.595 0 'no' 'northeast' 11658.11505]\n",
      "[49 'male' 25.6 2 'yes' 'southwest' 23306.547]\n",
      "[19 'female' 33.11 0 'yes' 'southeast' 34439.8559]\n",
      "[55 'female' 37.1 0 'no' 'southwest' 10713.644]\n",
      "[30 'male' 31.4 1 'no' 'southwest' 3659.346]\n",
      "[37 'male' 34.1 4 'yes' 'southwest' 40182.246]\n",
      "[49 'female' 21.3 1 'no' 'southwest' 9182.17]\n",
      "[18 'male' 33.535 0 'yes' 'northeast' 34617.84065]\n",
      "[59 'male' 28.785 0 'no' 'northwest' 12129.61415]\n",
      "[29 'female' 26.03 0 'no' 'northwest' 3736.4647]\n",
      "[36 'male' 28.88 3 'no' 'northeast' 6748.5912]\n",
      "[33 'male' 42.46 1 'no' 'southeast' 11326.71487]\n",
      "[58 'male' 38.0 0 'no' 'southwest' 11365.952]\n",
      "[44 'female' 38.95 0 'yes' 'northwest' 42983.4585]\n",
      "[53 'male' 36.1 1 'no' 'southwest' 10085.846]\n",
      "[24 'male' 29.3 0 'no' 'southwest' 1977.815]\n",
      "[29 'female' 35.53 0 'no' 'southeast' 3366.6697]\n",
      "[40 'male' 22.705 2 'no' 'northeast' 7173.35995]\n",
      "[51 'male' 39.7 1 'no' 'southwest' 9391.346]\n",
      "[64 'male' 38.19 0 'no' 'northeast' 14410.9321]\n",
      "[19 'female' 24.51 1 'no' 'northwest' 2709.1119]\n",
      "[35 'female' 38.095 2 'no' 'northeast' 24915.04626]\n",
      "[39 'male' 26.41 0 'yes' 'northeast' 20149.3229]\n",
      "[56 'male' 33.66 4 'no' 'southeast' 12949.1554]\n",
      "[33 'male' 42.4 5 'no' 'southwest' 6666.243]\n",
      "[42 'male' 28.31 3 'yes' 'northwest' 32787.45859]\n",
      "[61 'male' 33.915 0 'no' 'northeast' 13143.86485]\n",
      "[23 'female' 34.96 3 'no' 'northwest' 4466.6214]\n",
      "[43 'male' 35.31 2 'no' 'southeast' 18806.14547]\n",
      "[48 'male' 30.78 3 'no' 'northeast' 10141.1362]\n",
      "[39 'male' 26.22 1 'no' 'northwest' 6123.5688]\n",
      "[40 'female' 23.37 3 'no' 'northeast' 8252.2843]\n",
      "[18 'male' 28.5 0 'no' 'northeast' 1712.227]\n",
      "[58 'female' 32.965 0 'no' 'northeast' 12430.95335]\n",
      "[49 'female' 42.68 2 'no' 'southeast' 9800.8882]\n",
      "[53 'female' 39.6 1 'no' 'southeast' 10579.711]\n",
      "[48 'female' 31.13 0 'no' 'southeast' 8280.6227]\n",
      "[45 'female' 36.3 2 'no' 'southeast' 8527.532]\n",
      "[59 'female' 35.2 0 'no' 'southeast' 12244.531]\n",
      "[52 'female' 25.3 2 'yes' 'southeast' 24667.419]\n",
      "[26 'female' 42.4 1 'no' 'southwest' 3410.324]\n",
      "[27 'male' 33.155 2 'no' 'northwest' 4058.71245]\n",
      "[48 'female' 35.91 1 'no' 'northeast' 26392.26029]\n",
      "[57 'female' 28.785 4 'no' 'northeast' 14394.39815]\n",
      "[37 'male' 46.53 3 'no' 'southeast' 6435.6237]\n",
      "[57 'female' 23.98 1 'no' 'southeast' 22192.43711]\n",
      "[32 'female' 31.54 1 'no' 'northeast' 5148.5526]\n",
      "[18 'male' 33.66 0 'no' 'southeast' 1136.3994]\n",
      "[64 'female' 22.99 0 'yes' 'southeast' 27037.9141]\n",
      "[43 'male' 38.06 2 'yes' 'southeast' 42560.4304]\n",
      "[49 'male' 28.7 1 'no' 'southwest' 8703.456]\n",
      "[40 'female' 32.775 2 'yes' 'northwest' 40003.33225]\n",
      "[62 'male' 32.015 0 'yes' 'northeast' 45710.20785]\n",
      "[40 'female' 29.81 1 'no' 'southeast' 6500.2359]\n",
      "[30 'male' 31.57 3 'no' 'southeast' 4837.5823]\n",
      "[29 'female' 31.16 0 'no' 'northeast' 3943.5954]\n",
      "[36 'male' 29.7 0 'no' 'southeast' 4399.731]\n",
      "[41 'female' 31.02 0 'no' 'southeast' 6185.3208]\n",
      "[44 'female' 43.89 2 'yes' 'southeast' 46200.9851]\n",
      "[45 'male' 21.375 0 'no' 'northwest' 7222.78625]\n",
      "[55 'female' 40.81 3 'no' 'southeast' 12485.8009]\n",
      "[60 'male' 31.35 3 'yes' 'northwest' 46130.5265]\n",
      "[56 'male' 36.1 3 'no' 'southwest' 12363.547]\n",
      "[49 'female' 23.18 2 'no' 'northwest' 10156.7832]\n",
      "[21 'female' 17.4 1 'no' 'southwest' 2585.269]\n",
      "[19 'male' 20.3 0 'no' 'southwest' 1242.26]\n",
      "[39 'male' 35.3 2 'yes' 'southwest' 40103.89]\n",
      "[53 'male' 24.32 0 'no' 'northwest' 9863.4718]\n",
      "[33 'female' 18.5 1 'no' 'southwest' 4766.022]\n",
      "[53 'male' 26.41 2 'no' 'northeast' 11244.3769]\n",
      "[42 'male' 26.125 2 'no' 'northeast' 7729.64575]\n",
      "[40 'male' 41.69 0 'no' 'southeast' 5438.7491]\n",
      "[47 'female' 24.1 1 'no' 'southwest' 26236.57997]\n",
      "[27 'male' 31.13 1 'yes' 'southeast' 34806.4677]\n",
      "[21 'male' 27.36 0 'no' 'northeast' 2104.1134]\n",
      "[47 'male' 36.2 1 'no' 'southwest' 8068.185]\n",
      "[20 'male' 32.395 1 'no' 'northwest' 2362.22905]\n",
      "[24 'male' 23.655 0 'no' 'northwest' 2352.96845]\n",
      "[27 'female' 34.8 1 'no' 'southwest' 3577.999]\n",
      "[26 'female' 40.185 0 'no' 'northwest' 3201.24515]\n",
      "[53 'female' 32.3 2 'no' 'northeast' 29186.48236]\n",
      "[41 'male' 35.75 1 'yes' 'southeast' 40273.6455]\n",
      "[56 'male' 33.725 0 'no' 'northwest' 10976.24575]\n",
      "[23 'female' 39.27 2 'no' 'southeast' 3500.6123]\n",
      "[21 'female' 34.87 0 'no' 'southeast' 2020.5523]\n",
      "[50 'female' 44.745 0 'no' 'northeast' 9541.69555]\n",
      "[53 'male' 41.47 0 'no' 'southeast' 9504.3103]\n",
      "[34 'female' 26.41 1 'no' 'northwest' 5385.3379]\n",
      "[47 'female' 29.545 1 'no' 'northwest' 8930.93455]\n",
      "[33 'female' 32.9 2 'no' 'southwest' 5375.038]\n",
      "[51 'female' 38.06 0 'yes' 'southeast' 44400.4064]\n",
      "[49 'male' 28.69 3 'no' 'northwest' 10264.4421]\n",
      "[31 'female' 30.495 3 'no' 'northeast' 6113.23105]\n",
      "[36 'female' 27.74 0 'no' 'northeast' 5469.0066]\n",
      "[18 'male' 35.2 1 'no' 'southeast' 1727.54]\n",
      "[50 'female' 23.54 2 'no' 'southeast' 10107.2206]\n",
      "[43 'female' 30.685 2 'no' 'northwest' 8310.83915]\n",
      "[20 'male' 40.47 0 'no' 'northeast' 1984.4533]\n",
      "[24 'female' 22.6 0 'no' 'southwest' 2457.502]\n",
      "[60 'male' 28.9 0 'no' 'southwest' 12146.971]\n",
      "[49 'female' 22.61 1 'no' 'northwest' 9566.9909]\n",
      "[60 'male' 24.32 1 'no' 'northwest' 13112.6048]\n",
      "[51 'female' 36.67 2 'no' 'northwest' 10848.1343]\n",
      "[58 'female' 33.44 0 'no' 'northwest' 12231.6136]\n",
      "[51 'female' 40.66 0 'no' 'northeast' 9875.6804]\n",
      "[53 'male' 36.6 3 'no' 'southwest' 11264.541]\n",
      "[62 'male' 37.4 0 'no' 'southwest' 12979.358]\n",
      "[19 'male' 35.4 0 'no' 'southwest' 1263.249]\n",
      "[50 'female' 27.075 1 'no' 'northeast' 10106.13425]\n",
      "[30 'female' 39.05 3 'yes' 'southeast' 40932.4295]\n",
      "[41 'male' 28.405 1 'no' 'northwest' 6664.68595]\n",
      "[29 'female' 21.755 1 'yes' 'northeast' 16657.71745]\n",
      "[18 'female' 40.28 0 'no' 'northeast' 2217.6012]\n",
      "[41 'female' 36.08 1 'no' 'southeast' 6781.3542]\n",
      "[35 'male' 24.42 3 'yes' 'southeast' 19361.9988]\n",
      "[53 'male' 21.4 1 'no' 'southwest' 10065.413]\n",
      "[24 'female' 30.1 3 'no' 'southwest' 4234.927]\n",
      "[48 'female' 27.265 1 'no' 'northeast' 9447.25035]\n",
      "[59 'female' 32.1 3 'no' 'southwest' 14007.222]\n",
      "[49 'female' 34.77 1 'no' 'northwest' 9583.8933]\n",
      "[37 'female' 38.39 0 'yes' 'southeast' 40419.0191]\n",
      "[26 'male' 23.7 2 'no' 'southwest' 3484.331]\n",
      "[23 'male' 31.73 3 'yes' 'northeast' 36189.1017]\n",
      "[29 'male' 35.5 2 'yes' 'southwest' 44585.45587]\n",
      "[45 'male' 24.035 2 'no' 'northeast' 8604.48365]\n",
      "[27 'male' 29.15 0 'yes' 'southeast' 18246.4955]\n",
      "[53 'male' 34.105 0 'yes' 'northeast' 43254.41795]\n",
      "[31 'female' 26.62 0 'no' 'southeast' 3757.8448]\n",
      "[50 'male' 26.41 0 'no' 'northwest' 8827.2099]\n",
      "[50 'female' 30.115 1 'no' 'northwest' 9910.35985]\n",
      "[34 'male' 27.0 2 'no' 'southwest' 11737.84884]\n",
      "[19 'male' 21.755 0 'no' 'northwest' 1627.28245]\n",
      "[47 'female' 36.0 1 'no' 'southwest' 8556.907]\n",
      "[28 'male' 30.875 0 'no' 'northwest' 3062.50825]\n",
      "[37 'female' 26.4 0 'yes' 'southeast' 19539.243]\n",
      "[21 'male' 28.975 0 'no' 'northwest' 1906.35825]\n",
      "[64 'male' 37.905 0 'no' 'northwest' 14210.53595]\n",
      "[58 'female' 22.77 0 'no' 'southeast' 11833.7823]\n",
      "[24 'male' 33.63 4 'no' 'northeast' 17128.42608]\n",
      "[31 'male' 27.645 2 'no' 'northeast' 5031.26955]\n",
      "[39 'female' 22.8 3 'no' 'northeast' 7985.815]\n",
      "[47 'female' 27.83 0 'yes' 'southeast' 23065.4207]\n",
      "[30 'male' 37.43 3 'no' 'northeast' 5428.7277]\n",
      "[18 'male' 38.17 0 'yes' 'southeast' 36307.7983]\n",
      "[22 'female' 34.58 2 'no' 'northeast' 3925.7582]\n",
      "[23 'male' 35.2 1 'no' 'southwest' 2416.955]\n",
      "[33 'male' 27.1 1 'yes' 'southwest' 19040.876]\n",
      "[27 'male' 26.03 0 'no' 'northeast' 3070.8087]\n",
      "[45 'female' 25.175 2 'no' 'northeast' 9095.06825]\n",
      "[57 'female' 31.825 0 'no' 'northwest' 11842.62375]\n",
      "[47 'male' 32.3 1 'no' 'southwest' 8062.764]\n",
      "[42 'female' 29.0 1 'no' 'southwest' 7050.642]\n",
      "[64 'female' 39.7 0 'no' 'southwest' 14319.031]\n",
      "[38 'female' 19.475 2 'no' 'northwest' 6933.24225]\n",
      "[61 'male' 36.1 3 'no' 'southwest' 27941.28758]\n",
      "[53 'female' 26.7 2 'no' 'southwest' 11150.78]\n",
      "[44 'female' 36.48 0 'no' 'northeast' 12797.20962]\n",
      "[19 'female' 28.88 0 'yes' 'northwest' 17748.5062]\n",
      "[41 'male' 34.2 2 'no' 'northwest' 7261.741]\n",
      "[51 'male' 33.33 3 'no' 'southeast' 10560.4917]\n",
      "[40 'male' 32.3 2 'no' 'northwest' 6986.697]\n",
      "[45 'male' 39.805 0 'no' 'northeast' 7448.40395]\n",
      "[35 'male' 34.32 3 'no' 'southeast' 5934.3798]\n",
      "[53 'male' 28.88 0 'no' 'northwest' 9869.8102]\n",
      "[30 'male' 24.4 3 'yes' 'southwest' 18259.216]\n",
      "[18 'male' 41.14 0 'no' 'southeast' 1146.7966]\n",
      "[51 'male' 35.97 1 'no' 'southeast' 9386.1613]\n",
      "[50 'female' 27.6 1 'yes' 'southwest' 24520.264]\n",
      "[31 'female' 29.26 1 'no' 'southeast' 4350.5144]\n",
      "[35 'female' 27.7 3 'no' 'southwest' 6414.178]\n",
      "[60 'male' 36.955 0 'no' 'northeast' 12741.16745]\n",
      "[21 'male' 36.86 0 'no' 'northwest' 1917.3184]\n",
      "[29 'male' 22.515 3 'no' 'northeast' 5209.57885]\n",
      "[62 'female' 29.92 0 'no' 'southeast' 13457.9608]\n",
      "[39 'female' 41.8 0 'no' 'southeast' 5662.225]\n",
      "[19 'male' 27.6 0 'no' 'southwest' 1252.407]\n",
      "[22 'female' 23.18 0 'no' 'northeast' 2731.9122]\n",
      "[53 'male' 20.9 0 'yes' 'southeast' 21195.818]\n",
      "[39 'female' 31.92 2 'no' 'northwest' 7209.4918]\n",
      "[27 'male' 28.5 0 'yes' 'northwest' 18310.742]\n",
      "[30 'male' 44.22 2 'no' 'southeast' 4266.1658]\n",
      "[30 'female' 22.895 1 'no' 'northeast' 4719.52405]\n",
      "[58 'female' 33.1 0 'no' 'southwest' 11848.141]\n",
      "[33 'male' 24.795 0 'yes' 'northeast' 17904.52705]\n",
      "[42 'female' 26.18 1 'no' 'southeast' 7046.7222]\n",
      "[64 'female' 35.97 0 'no' 'southeast' 14313.8463]\n",
      "[21 'male' 22.3 1 'no' 'southwest' 2103.08]\n",
      "[18 'female' 42.24 0 'yes' 'southeast' 38792.6856]\n",
      "[23 'male' 26.51 0 'no' 'southeast' 1815.8759]\n",
      "[45 'female' 35.815 0 'no' 'northwest' 7731.85785]\n",
      "[40 'female' 41.42 1 'no' 'northwest' 28476.73499]\n",
      "[19 'female' 36.575 0 'no' 'northwest' 2136.88225]\n",
      "[18 'male' 30.14 0 'no' 'southeast' 1131.5066]\n",
      "[25 'male' 25.84 1 'no' 'northeast' 3309.7926]\n",
      "[46 'female' 30.8 3 'no' 'southwest' 9414.92]\n",
      "[33 'female' 42.94 3 'no' 'northwest' 6360.9936]\n",
      "[54 'male' 21.01 2 'no' 'southeast' 11013.7119]\n",
      "[28 'male' 22.515 2 'no' 'northeast' 4428.88785]\n",
      "[36 'male' 34.43 2 'no' 'southeast' 5584.3057]\n",
      "[20 'female' 31.46 0 'no' 'southeast' 1877.9294]\n",
      "[24 'female' 24.225 0 'no' 'northwest' 2842.76075]\n",
      "[23 'male' 37.1 3 'no' 'southwest' 3597.596]\n",
      "[47 'female' 26.125 1 'yes' 'northeast' 23401.30575]\n",
      "[33 'female' 35.53 0 'yes' 'northwest' 55135.40209]\n",
      "[45 'male' 33.7 1 'no' 'southwest' 7445.918]\n",
      "[26 'male' 17.67 0 'no' 'northwest' 2680.9493]\n",
      "[18 'female' 31.13 0 'no' 'southeast' 1621.8827]\n",
      "[44 'female' 29.81 2 'no' 'southeast' 8219.2039]\n",
      "[60 'male' 24.32 0 'no' 'northwest' 12523.6048]\n",
      "[64 'female' 31.825 2 'no' 'northeast' 16069.08475]\n",
      "[56 'male' 31.79 2 'yes' 'southeast' 43813.8661]\n",
      "[36 'male' 28.025 1 'yes' 'northeast' 20773.62775]\n",
      "[41 'male' 30.78 3 'yes' 'northeast' 39597.4072]\n",
      "[39 'male' 21.85 1 'no' 'northwest' 6117.4945]\n",
      "[63 'male' 33.1 0 'no' 'southwest' 13393.756]\n",
      "[36 'female' 25.84 0 'no' 'northwest' 5266.3656]\n",
      "[28 'female' 23.845 2 'no' 'northwest' 4719.73655]\n",
      "[58 'male' 34.39 0 'no' 'northwest' 11743.9341]\n",
      "[36 'male' 33.82 1 'no' 'northwest' 5377.4578]\n",
      "[42 'male' 35.97 2 'no' 'southeast' 7160.3303]\n",
      "[36 'male' 31.5 0 'no' 'southwest' 4402.233]\n",
      "[56 'female' 28.31 0 'no' 'northeast' 11657.7189]\n",
      "[35 'female' 23.465 2 'no' 'northeast' 6402.29135]\n",
      "[59 'female' 31.35 0 'no' 'northwest' 12622.1795]\n",
      "[21 'male' 31.1 0 'no' 'southwest' 1526.312]\n",
      "[59 'male' 24.7 0 'no' 'northeast' 12323.936]\n",
      "[23 'female' 32.78 2 'yes' 'southeast' 36021.0112]\n",
      "[57 'female' 29.81 0 'yes' 'southeast' 27533.9129]\n",
      "[53 'male' 30.495 0 'no' 'northeast' 10072.05505]\n",
      "[60 'female' 32.45 0 'yes' 'southeast' 45008.9555]\n",
      "[51 'female' 34.2 1 'no' 'southwest' 9872.701]\n",
      "[23 'male' 50.38 1 'no' 'southeast' 2438.0552]\n",
      "[27 'female' 24.1 0 'no' 'southwest' 2974.126]\n",
      "[55 'male' 32.775 0 'no' 'northwest' 10601.63225]\n",
      "[37 'female' 30.78 0 'yes' 'northeast' 37270.1512]\n",
      "[61 'male' 32.3 2 'no' 'northwest' 14119.62]\n",
      "[46 'female' 35.53 0 'yes' 'northeast' 42111.6647]\n",
      "[53 'female' 23.75 2 'no' 'northeast' 11729.6795]\n",
      "[49 'female' 23.845 3 'yes' 'northeast' 24106.91255]\n",
      "[20 'female' 29.6 0 'no' 'southwest' 1875.344]\n",
      "[48 'female' 33.11 0 'yes' 'southeast' 40974.1649]\n",
      "[25 'male' 24.13 0 'yes' 'northwest' 15817.9857]\n",
      "[25 'female' 32.23 1 'no' 'southeast' 18218.16139]\n",
      "[57 'male' 28.1 0 'no' 'southwest' 10965.446]\n",
      "[37 'female' 47.6 2 'yes' 'southwest' 46113.511]\n",
      "[38 'female' 28.0 3 'no' 'southwest' 7151.092]\n",
      "[55 'female' 33.535 2 'no' 'northwest' 12269.68865]\n",
      "[36 'female' 19.855 0 'no' 'northeast' 5458.04645]\n",
      "[51 'male' 25.4 0 'no' 'southwest' 8782.469]\n",
      "[40 'male' 29.9 2 'no' 'southwest' 6600.361]\n",
      "[18 'male' 37.29 0 'no' 'southeast' 1141.4451]\n",
      "[57 'male' 43.7 1 'no' 'southwest' 11576.13]\n",
      "[61 'male' 23.655 0 'no' 'northeast' 13129.60345]\n",
      "[25 'female' 24.3 3 'no' 'southwest' 4391.652]\n",
      "[50 'male' 36.2 0 'no' 'southwest' 8457.818]\n",
      "[26 'female' 29.48 1 'no' 'southeast' 3392.3652]\n",
      "[42 'male' 24.86 0 'no' 'southeast' 5966.8874]\n",
      "[43 'male' 30.1 1 'no' 'southwest' 6849.026]\n",
      "[44 'male' 21.85 3 'no' 'northeast' 8891.1395]\n",
      "[23 'female' 28.12 0 'no' 'northwest' 2690.1138]\n",
      "[49 'female' 27.1 1 'no' 'southwest' 26140.3603]\n",
      "[33 'male' 33.44 5 'no' 'southeast' 6653.7886]\n",
      "[41 'male' 28.8 1 'no' 'southwest' 6282.235]\n",
      "[37 'female' 29.5 2 'no' 'southwest' 6311.952]\n",
      "[22 'male' 34.8 3 'no' 'southwest' 3443.064]\n",
      "[23 'male' 27.36 1 'no' 'northwest' 2789.0574]\n",
      "[21 'female' 22.135 0 'no' 'northeast' 2585.85065]\n",
      "[51 'female' 37.05 3 'yes' 'northeast' 46255.1125]\n",
      "[25 'male' 26.695 4 'no' 'northwest' 4877.98105]\n",
      "[32 'male' 28.93 1 'yes' 'southeast' 19719.6947]\n",
      "[57 'male' 28.975 0 'yes' 'northeast' 27218.43725]\n",
      "[36 'female' 30.02 0 'no' 'northwest' 5272.1758]\n",
      "[22 'male' 39.5 0 'no' 'southwest' 1682.597]\n",
      "[57 'male' 33.63 1 'no' 'northwest' 11945.1327]\n",
      "[64 'female' 26.885 0 'yes' 'northwest' 29330.98315]\n",
      "[36 'female' 29.04 4 'no' 'southeast' 7243.8136]\n",
      "[54 'male' 24.035 0 'no' 'northeast' 10422.91665]\n",
      "[47 'male' 38.94 2 'yes' 'southeast' 44202.6536]\n",
      "[62 'male' 32.11 0 'no' 'northeast' 13555.0049]\n",
      "[61 'female' 44.0 0 'no' 'southwest' 13063.883]\n",
      "[43 'female' 20.045 2 'yes' 'northeast' 19798.05455]\n",
      "[19 'male' 25.555 1 'no' 'northwest' 2221.56445]\n",
      "[18 'female' 40.26 0 'no' 'southeast' 1634.5734]\n",
      "[19 'female' 22.515 0 'no' 'northwest' 2117.33885]\n",
      "[49 'male' 22.515 0 'no' 'northeast' 8688.85885]\n",
      "[60 'male' 40.92 0 'yes' 'southeast' 48673.5588]\n",
      "[26 'male' 27.265 3 'no' 'northeast' 4661.28635]\n",
      "[49 'male' 36.85 0 'no' 'southeast' 8125.7845]\n",
      "[60 'female' 35.1 0 'no' 'southwest' 12644.589]\n",
      "[26 'female' 29.355 2 'no' 'northeast' 4564.19145]\n",
      "[27 'male' 32.585 3 'no' 'northeast' 4846.92015]\n",
      "[44 'female' 32.34 1 'no' 'southeast' 7633.7206]\n",
      "[63 'male' 39.8 3 'no' 'southwest' 15170.069]\n",
      "[32 'female' 24.6 0 'yes' 'southwest' 17496.306]\n",
      "[22 'male' 28.31 1 'no' 'northwest' 2639.0429]\n",
      "[18 'male' 31.73 0 'yes' 'northeast' 33732.6867]\n",
      "[59 'female' 26.695 3 'no' 'northwest' 14382.70905]\n",
      "[44 'female' 27.5 1 'no' 'southwest' 7626.993]\n",
      "[33 'male' 24.605 2 'no' 'northwest' 5257.50795]\n",
      "[24 'female' 33.99 0 'no' 'southeast' 2473.3341]\n",
      "[43 'female' 26.885 0 'yes' 'northwest' 21774.32215]\n",
      "[45 'male' 22.895 0 'yes' 'northeast' 35069.37452]\n",
      "[61 'female' 28.2 0 'no' 'southwest' 13041.921]\n",
      "[35 'female' 34.21 1 'no' 'southeast' 5245.2269]\n",
      "[62 'female' 25.0 0 'no' 'southwest' 13451.122]\n",
      "[62 'female' 33.2 0 'no' 'southwest' 13462.52]\n",
      "[38 'male' 31.0 1 'no' 'southwest' 5488.262]\n",
      "[34 'male' 35.815 0 'no' 'northwest' 4320.41085]\n",
      "[43 'male' 23.2 0 'no' 'southwest' 6250.435]\n",
      "[50 'male' 32.11 2 'no' 'northeast' 25333.33284]\n",
      "[19 'female' 23.4 2 'no' 'southwest' 2913.569]\n",
      "[57 'female' 20.1 1 'no' 'southwest' 12032.326]\n",
      "[62 'female' 39.16 0 'no' 'southeast' 13470.8044]\n",
      "[41 'male' 34.21 1 'no' 'southeast' 6289.7549]\n",
      "[26 'male' 46.53 1 'no' 'southeast' 2927.0647]\n",
      "[39 'female' 32.5 1 'no' 'southwest' 6238.298]\n",
      "[46 'male' 25.8 5 'no' 'southwest' 10096.97]\n",
      "[45 'female' 35.3 0 'no' 'southwest' 7348.142]\n",
      "[32 'male' 37.18 2 'no' 'southeast' 4673.3922]\n",
      "[59 'female' 27.5 0 'no' 'southwest' 12233.828]\n",
      "[44 'male' 29.735 2 'no' 'northeast' 32108.66282]\n",
      "[39 'female' 24.225 5 'no' 'northwest' 8965.79575]\n",
      "[18 'male' 26.18 2 'no' 'southeast' 2304.0022]\n",
      "[53 'male' 29.48 0 'no' 'southeast' 9487.6442]\n",
      "[18 'male' 23.21 0 'no' 'southeast' 1121.8739]\n",
      "[50 'female' 46.09 1 'no' 'southeast' 9549.5651]\n",
      "[18 'female' 40.185 0 'no' 'northeast' 2217.46915]\n",
      "[19 'male' 22.61 0 'no' 'northwest' 1628.4709]\n",
      "[62 'male' 39.93 0 'no' 'southeast' 12982.8747]\n",
      "[56 'female' 35.8 1 'no' 'southwest' 11674.13]\n",
      "[42 'male' 35.8 2 'no' 'southwest' 7160.094]\n",
      "[37 'male' 34.2 1 'yes' 'northeast' 39047.285]\n",
      "[42 'male' 31.255 0 'no' 'northwest' 6358.77645]\n",
      "[25 'male' 29.7 3 'yes' 'southwest' 19933.458]\n",
      "[57 'male' 18.335 0 'no' 'northeast' 11534.87265]\n",
      "[51 'male' 42.9 2 'yes' 'southeast' 47462.894]\n",
      "[30 'female' 28.405 1 'no' 'northwest' 4527.18295]\n",
      "[44 'male' 30.2 2 'yes' 'southwest' 38998.546]\n",
      "[34 'male' 27.835 1 'yes' 'northwest' 20009.63365]\n",
      "[31 'male' 39.49 1 'no' 'southeast' 3875.7341]\n",
      "[54 'male' 30.8 1 'yes' 'southeast' 41999.52]\n",
      "[24 'male' 26.79 1 'no' 'northwest' 12609.88702]\n",
      "[43 'male' 34.96 1 'yes' 'northeast' 41034.2214]\n",
      "[48 'male' 36.67 1 'no' 'northwest' 28468.91901]\n",
      "[19 'female' 39.615 1 'no' 'northwest' 2730.10785]\n",
      "[29 'female' 25.9 0 'no' 'southwest' 3353.284]\n",
      "[63 'female' 35.2 1 'no' 'southeast' 14474.675]\n",
      "[46 'male' 24.795 3 'no' 'northeast' 9500.57305]\n",
      "[52 'male' 36.765 2 'no' 'northwest' 26467.09737]\n",
      "[35 'male' 27.1 1 'no' 'southwest' 4746.344]\n",
      "[51 'male' 24.795 2 'yes' 'northwest' 23967.38305]\n",
      "[44 'male' 25.365 1 'no' 'northwest' 7518.02535]\n",
      "[21 'male' 25.745 2 'no' 'northeast' 3279.86855]\n",
      "[39 'female' 34.32 5 'no' 'southeast' 8596.8278]\n",
      "[50 'female' 28.16 3 'no' 'southeast' 10702.6424]\n",
      "[34 'female' 23.56 0 'no' 'northeast' 4992.3764]\n",
      "[22 'female' 20.235 0 'no' 'northwest' 2527.81865]\n",
      "[19 'female' 40.5 0 'no' 'southwest' 1759.338]\n",
      "[26 'male' 35.42 0 'no' 'southeast' 2322.6218]\n",
      "[29 'male' 22.895 0 'yes' 'northeast' 16138.76205]\n",
      "[48 'male' 40.15 0 'no' 'southeast' 7804.1605]\n",
      "[26 'male' 29.15 1 'no' 'southeast' 2902.9065]\n",
      "[45 'female' 39.995 3 'no' 'northeast' 9704.66805]\n",
      "[36 'female' 29.92 0 'no' 'southeast' 4889.0368]\n",
      "[54 'male' 25.46 1 'no' 'northeast' 25517.11363]\n",
      "[34 'male' 21.375 0 'no' 'northeast' 4500.33925]\n",
      "[31 'male' 25.9 3 'yes' 'southwest' 19199.944]\n",
      "[27 'female' 30.59 1 'no' 'northeast' 16796.41194]\n",
      "[20 'male' 30.115 5 'no' 'northeast' 4915.05985]\n",
      "[44 'female' 25.8 1 'no' 'southwest' 7624.63]\n",
      "[43 'male' 30.115 3 'no' 'northwest' 8410.04685]\n",
      "[45 'female' 27.645 1 'no' 'northwest' 28340.18885]\n",
      "[34 'male' 34.675 0 'no' 'northeast' 4518.82625]\n",
      "[24 'female' 20.52 0 'yes' 'northeast' 14571.8908]\n",
      "[26 'female' 19.8 1 'no' 'southwest' 3378.91]\n",
      "[38 'female' 27.835 2 'no' 'northeast' 7144.86265]\n",
      "[50 'female' 31.6 2 'no' 'southwest' 10118.424]\n",
      "[38 'male' 28.27 1 'no' 'southeast' 5484.4673]\n",
      "[27 'female' 20.045 3 'yes' 'northwest' 16420.49455]\n",
      "[39 'female' 23.275 3 'no' 'northeast' 7986.47525]\n",
      "[39 'female' 34.1 3 'no' 'southwest' 7418.522]\n",
      "[63 'female' 36.85 0 'no' 'southeast' 13887.9685]\n",
      "[33 'female' 36.29 3 'no' 'northeast' 6551.7501]\n",
      "[36 'female' 26.885 0 'no' 'northwest' 5267.81815]\n",
      "[30 'male' 22.99 2 'yes' 'northwest' 17361.7661]\n",
      "[24 'male' 32.7 0 'yes' 'southwest' 34472.841]\n",
      "[24 'male' 25.8 0 'no' 'southwest' 1972.95]\n",
      "[48 'male' 29.6 0 'no' 'southwest' 21232.18226]\n",
      "[47 'male' 19.19 1 'no' 'northeast' 8627.5411]\n",
      "[29 'male' 31.73 2 'no' 'northwest' 4433.3877]\n",
      "[28 'male' 29.26 2 'no' 'northeast' 4438.2634]\n",
      "[47 'male' 28.215 3 'yes' 'northwest' 24915.22085]\n",
      "[25 'male' 24.985 2 'no' 'northeast' 23241.47453]\n",
      "[51 'male' 27.74 1 'no' 'northeast' 9957.7216]\n",
      "[48 'female' 22.8 0 'no' 'southwest' 8269.044]\n",
      "[43 'male' 20.13 2 'yes' 'southeast' 18767.7377]\n",
      "[61 'female' 33.33 4 'no' 'southeast' 36580.28216]\n",
      "[48 'male' 32.3 1 'no' 'northwest' 8765.249]\n",
      "[38 'female' 27.6 0 'no' 'southwest' 5383.536]\n",
      "[59 'male' 25.46 0 'no' 'northwest' 12124.9924]\n",
      "[19 'female' 24.605 1 'no' 'northwest' 2709.24395]\n",
      "[26 'female' 34.2 2 'no' 'southwest' 3987.926]\n",
      "[54 'female' 35.815 3 'no' 'northwest' 12495.29085]\n",
      "[21 'female' 32.68 2 'no' 'northwest' 26018.95052]\n",
      "[51 'male' 37.0 0 'no' 'southwest' 8798.593]\n",
      "[22 'female' 31.02 3 'yes' 'southeast' 35595.5898]\n",
      "[47 'male' 36.08 1 'yes' 'southeast' 42211.1382]\n",
      "[18 'male' 23.32 1 'no' 'southeast' 1711.0268]\n",
      "[47 'female' 45.32 1 'no' 'southeast' 8569.8618]\n",
      "[21 'female' 34.6 0 'no' 'southwest' 2020.177]\n",
      "[19 'male' 26.03 1 'yes' 'northwest' 16450.8947]\n",
      "[23 'male' 18.715 0 'no' 'northwest' 21595.38229]\n",
      "[54 'male' 31.6 0 'no' 'southwest' 9850.432]\n",
      "[37 'female' 17.29 2 'no' 'northeast' 6877.9801]\n",
      "[46 'female' 23.655 1 'yes' 'northwest' 21677.28345]\n",
      "[55 'female' 35.2 0 'yes' 'southeast' 44423.803]\n",
      "[30 'female' 27.93 0 'no' 'northeast' 4137.5227]\n",
      "[18 'male' 21.565 0 'yes' 'northeast' 13747.87235]\n",
      "[61 'male' 38.38 0 'no' 'northwest' 12950.0712]\n",
      "[54 'female' 23.0 3 'no' 'southwest' 12094.478]\n",
      "[22 'male' 37.07 2 'yes' 'southeast' 37484.4493]\n",
      "[45 'female' 30.495 1 'yes' 'northwest' 39725.51805]\n",
      "[22 'male' 28.88 0 'no' 'northeast' 2250.8352]\n",
      "[19 'male' 27.265 2 'no' 'northwest' 22493.65964]\n",
      "[35 'female' 28.025 0 'yes' 'northwest' 20234.85475]\n",
      "[18 'male' 23.085 0 'no' 'northeast' 1704.70015]\n",
      "[20 'male' 30.685 0 'yes' 'northeast' 33475.81715]\n",
      "[28 'female' 25.8 0 'no' 'southwest' 3161.454]\n",
      "[55 'male' 35.245 1 'no' 'northeast' 11394.06555]\n",
      "[43 'female' 24.7 2 'yes' 'northwest' 21880.82]\n",
      "[43 'female' 25.08 0 'no' 'northeast' 7325.0482]\n",
      "[22 'male' 52.58 1 'yes' 'southeast' 44501.3982]\n",
      "[25 'female' 22.515 1 'no' 'northwest' 3594.17085]\n",
      "[49 'male' 30.9 0 'yes' 'southwest' 39727.614]\n",
      "[44 'female' 36.955 1 'no' 'northwest' 8023.13545]\n",
      "[64 'male' 26.41 0 'no' 'northeast' 14394.5579]\n",
      "[49 'male' 29.83 1 'no' 'northeast' 9288.0267]\n",
      "[47 'male' 29.8 3 'yes' 'southwest' 25309.489]\n",
      "[27 'female' 21.47 0 'no' 'northwest' 3353.4703]\n",
      "[55 'male' 27.645 0 'no' 'northwest' 10594.50155]\n",
      "[48 'female' 28.9 0 'no' 'southwest' 8277.523]\n",
      "[45 'female' 31.79 0 'no' 'southeast' 17929.30337]\n",
      "[24 'female' 39.49 0 'no' 'southeast' 2480.9791]\n",
      "[32 'male' 33.82 1 'no' 'northwest' 4462.7218]\n",
      "[24 'male' 32.01 0 'no' 'southeast' 1981.5819]\n",
      "[57 'male' 27.94 1 'no' 'southeast' 11554.2236]\n",
      "[59 'male' 41.14 1 'yes' 'southeast' 48970.2476]\n",
      "[36 'male' 28.595 3 'no' 'northwest' 6548.19505]\n",
      "[29 'female' 25.6 4 'no' 'southwest' 5708.867]\n",
      "[42 'female' 25.3 1 'no' 'southwest' 7045.499]\n",
      "[48 'male' 37.29 2 'no' 'southeast' 8978.1851]\n",
      "[39 'male' 42.655 0 'no' 'northeast' 5757.41345]\n",
      "[63 'male' 21.66 1 'no' 'northwest' 14349.8544]\n",
      "[54 'female' 31.9 1 'no' 'southeast' 10928.849]\n",
      "[37 'male' 37.07 1 'yes' 'southeast' 39871.7043]\n",
      "[63 'male' 31.445 0 'no' 'northeast' 13974.45555]\n",
      "[21 'male' 31.255 0 'no' 'northwest' 1909.52745]\n",
      "[54 'female' 28.88 2 'no' 'northeast' 12096.6512]\n",
      "[60 'female' 18.335 0 'no' 'northeast' 13204.28565]\n",
      "[32 'female' 29.59 1 'no' 'southeast' 4562.8421]\n",
      "[47 'female' 32.0 1 'no' 'southwest' 8551.347]\n",
      "[21 'male' 26.03 0 'no' 'northeast' 2102.2647]\n",
      "[28 'male' 31.68 0 'yes' 'southeast' 34672.1472]\n",
      "[63 'male' 33.66 3 'no' 'southeast' 15161.5344]\n",
      "[18 'male' 21.78 2 'no' 'southeast' 11884.04858]\n",
      "[32 'male' 27.835 1 'no' 'northwest' 4454.40265]\n",
      "[38 'male' 19.95 1 'no' 'northwest' 5855.9025]\n",
      "[32 'male' 31.5 1 'no' 'southwest' 4076.497]\n",
      "[62 'female' 30.495 2 'no' 'northwest' 15019.76005]\n",
      "[39 'female' 18.3 5 'yes' 'southwest' 19023.26]\n",
      "[55 'male' 28.975 0 'no' 'northeast' 10796.35025]\n",
      "[57 'male' 31.54 0 'no' 'northwest' 11353.2276]\n",
      "[52 'male' 47.74 1 'no' 'southeast' 9748.9106]\n",
      "[56 'male' 22.1 0 'no' 'southwest' 10577.087]\n",
      "[47 'male' 36.19 0 'yes' 'southeast' 41676.0811]\n",
      "[55 'female' 29.83 0 'no' 'northeast' 11286.5387]\n",
      "[23 'male' 32.7 3 'no' 'southwest' 3591.48]\n",
      "[22 'female' 30.4 0 'yes' 'northwest' 33907.548]\n",
      "[50 'female' 33.7 4 'no' 'southwest' 11299.343]\n",
      "[18 'female' 31.35 4 'no' 'northeast' 4561.1885]\n",
      "[51 'female' 34.96 2 'yes' 'northeast' 44641.1974]\n",
      "[22 'male' 33.77 0 'no' 'southeast' 1674.6323]\n",
      "[52 'female' 30.875 0 'no' 'northeast' 23045.56616]\n",
      "[25 'female' 33.99 1 'no' 'southeast' 3227.1211]\n",
      "[33 'female' 19.095 2 'yes' 'northeast' 16776.30405]\n",
      "[53 'male' 28.6 3 'no' 'southwest' 11253.421]\n",
      "[29 'male' 38.94 1 'no' 'southeast' 3471.4096]\n",
      "[58 'male' 36.08 0 'no' 'southeast' 11363.2832]\n",
      "[37 'male' 29.8 0 'no' 'southwest' 20420.60465]\n",
      "[54 'female' 31.24 0 'no' 'southeast' 10338.9316]\n",
      "[49 'female' 29.925 0 'no' 'northwest' 8988.15875]\n",
      "[50 'female' 26.22 2 'no' 'northwest' 10493.9458]\n",
      "[26 'male' 30.0 1 'no' 'southwest' 2904.088]\n",
      "[45 'male' 20.35 3 'no' 'southeast' 8605.3615]\n",
      "[54 'female' 32.3 1 'no' 'northeast' 11512.405]\n",
      "[38 'male' 38.39 3 'yes' 'southeast' 41949.2441]\n",
      "[48 'female' 25.85 3 'yes' 'southeast' 24180.9335]\n",
      "[28 'female' 26.315 3 'no' 'northwest' 5312.16985]\n",
      "[23 'male' 24.51 0 'no' 'northeast' 2396.0959]\n",
      "[55 'male' 32.67 1 'no' 'southeast' 10807.4863]\n",
      "[41 'male' 29.64 5 'no' 'northeast' 9222.4026]\n",
      "[25 'male' 33.33 2 'yes' 'southeast' 36124.5737]\n",
      "[33 'male' 35.75 1 'yes' 'southeast' 38282.7495]\n",
      "[30 'female' 19.95 3 'no' 'northwest' 5693.4305]\n",
      "[23 'female' 31.4 0 'yes' 'southwest' 34166.273]\n",
      "[46 'male' 38.17 2 'no' 'southeast' 8347.1643]\n",
      "[53 'female' 36.86 3 'yes' 'northwest' 46661.4424]\n",
      "[27 'female' 32.395 1 'no' 'northeast' 18903.49141]\n",
      "[23 'female' 42.75 1 'yes' 'northeast' 40904.1995]\n",
      "[63 'female' 25.08 0 'no' 'northwest' 14254.6082]\n",
      "[55 'male' 29.9 0 'no' 'southwest' 10214.636]\n",
      "[35 'female' 35.86 2 'no' 'southeast' 5836.5204]\n",
      "[34 'male' 32.8 1 'no' 'southwest' 14358.36437]\n",
      "[19 'female' 18.6 0 'no' 'southwest' 1728.897]\n",
      "[39 'female' 23.87 5 'no' 'southeast' 8582.3023]\n",
      "[27 'male' 45.9 2 'no' 'southwest' 3693.428]\n",
      "[57 'male' 40.28 0 'no' 'northeast' 20709.02034]\n",
      "[52 'female' 18.335 0 'no' 'northwest' 9991.03765]\n",
      "[28 'male' 33.82 0 'no' 'northwest' 19673.33573]\n",
      "[50 'female' 28.12 3 'no' 'northwest' 11085.5868]\n",
      "[44 'female' 25.0 1 'no' 'southwest' 7623.518]\n",
      "[26 'female' 22.23 0 'no' 'northwest' 3176.2877]\n",
      "[33 'male' 30.25 0 'no' 'southeast' 3704.3545]\n",
      "[19 'female' 32.49 0 'yes' 'northwest' 36898.73308]\n",
      "[50 'male' 37.07 1 'no' 'southeast' 9048.0273]\n",
      "[41 'female' 32.6 3 'no' 'southwest' 7954.517]\n",
      "[52 'female' 24.86 0 'no' 'southeast' 27117.99378]\n",
      "[39 'male' 32.34 2 'no' 'southeast' 6338.0756]\n",
      "[50 'male' 32.3 2 'no' 'southwest' 9630.397]\n",
      "[52 'male' 32.775 3 'no' 'northwest' 11289.10925]\n",
      "[60 'male' 32.8 0 'yes' 'southwest' 52590.82939]\n",
      "[20 'female' 31.92 0 'no' 'northwest' 2261.5688]\n",
      "[55 'male' 21.5 1 'no' 'southwest' 10791.96]\n",
      "[42 'male' 34.1 0 'no' 'southwest' 5979.731]\n",
      "[18 'female' 30.305 0 'no' 'northeast' 2203.73595]\n",
      "[58 'female' 36.48 0 'no' 'northwest' 12235.8392]\n",
      "[43 'female' 32.56 3 'yes' 'southeast' 40941.2854]\n",
      "[35 'female' 35.815 1 'no' 'northwest' 5630.45785]\n",
      "[48 'female' 27.93 4 'no' 'northwest' 11015.1747]\n",
      "[36 'female' 22.135 3 'no' 'northeast' 7228.21565]\n",
      "[19 'male' 44.88 0 'yes' 'southeast' 39722.7462]\n",
      "[23 'female' 23.18 2 'no' 'northwest' 14426.07385]\n",
      "[20 'female' 30.59 0 'no' 'northeast' 2459.7201]\n",
      "[32 'female' 41.1 0 'no' 'southwest' 3989.841]\n",
      "[43 'female' 34.58 1 'no' 'northwest' 7727.2532]\n",
      "[34 'male' 42.13 2 'no' 'southeast' 5124.1887]\n",
      "[30 'male' 38.83 1 'no' 'southeast' 18963.17192]\n",
      "[18 'female' 28.215 0 'no' 'northeast' 2200.83085]\n",
      "[41 'female' 28.31 1 'no' 'northwest' 7153.5539]\n",
      "[35 'female' 26.125 0 'no' 'northeast' 5227.98875]\n",
      "[57 'male' 40.37 0 'no' 'southeast' 10982.5013]\n",
      "[29 'female' 24.6 2 'no' 'southwest' 4529.477]\n",
      "[32 'male' 35.2 2 'no' 'southwest' 4670.64]\n",
      "[37 'female' 34.105 1 'no' 'northwest' 6112.35295]\n",
      "[18 'male' 27.36 1 'yes' 'northeast' 17178.6824]\n",
      "[43 'female' 26.7 2 'yes' 'southwest' 22478.6]\n",
      "[56 'female' 41.91 0 'no' 'southeast' 11093.6229]\n",
      "[38 'male' 29.26 2 'no' 'northwest' 6457.8434]\n",
      "[29 'male' 32.11 2 'no' 'northwest' 4433.9159]\n",
      "[22 'female' 27.1 0 'no' 'southwest' 2154.361]\n",
      "[52 'female' 24.13 1 'yes' 'northwest' 23887.6627]\n",
      "[40 'female' 27.4 1 'no' 'southwest' 6496.886]\n",
      "[23 'female' 34.865 0 'no' 'northeast' 2899.48935]\n",
      "[31 'male' 29.81 0 'yes' 'southeast' 19350.3689]\n",
      "[42 'female' 41.325 1 'no' 'northeast' 7650.77375]\n",
      "[24 'female' 29.925 0 'no' 'northwest' 2850.68375]\n",
      "[25 'female' 30.3 0 'no' 'southwest' 2632.992]\n",
      "[48 'female' 27.36 1 'no' 'northeast' 9447.3824]\n",
      "[23 'female' 28.49 1 'yes' 'southeast' 18328.2381]\n",
      "[45 'male' 23.56 2 'no' 'northeast' 8603.8234]\n",
      "[20 'male' 35.625 3 'yes' 'northwest' 37465.34375]\n",
      "[62 'female' 32.68 0 'no' 'northwest' 13844.7972]\n",
      "[43 'female' 25.27 1 'yes' 'northeast' 21771.3423]\n",
      "[23 'female' 28.0 0 'no' 'southwest' 13126.67745]\n",
      "[31 'female' 32.775 2 'no' 'northwest' 5327.40025]\n",
      "[41 'female' 21.755 1 'no' 'northeast' 13725.47184]\n",
      "[58 'female' 32.395 1 'no' 'northeast' 13019.16105]\n",
      "[48 'female' 36.575 0 'no' 'northwest' 8671.19125]\n",
      "[31 'female' 21.755 0 'no' 'northwest' 4134.08245]\n",
      "[19 'female' 27.93 3 'no' 'northwest' 18838.70366]\n",
      "[19 'female' 30.02 0 'yes' 'northwest' 33307.5508]\n",
      "[41 'male' 33.55 0 'no' 'southeast' 5699.8375]\n",
      "[40 'male' 29.355 1 'no' 'northwest' 6393.60345]\n",
      "[31 'female' 25.8 2 'no' 'southwest' 4934.705]\n",
      "[37 'male' 24.32 2 'no' 'northwest' 6198.7518]\n",
      "[46 'male' 40.375 2 'no' 'northwest' 8733.22925]\n",
      "[22 'male' 32.11 0 'no' 'northwest' 2055.3249]\n",
      "[51 'male' 32.3 1 'no' 'northeast' 9964.06]\n",
      "[18 'female' 27.28 3 'yes' 'southeast' 18223.4512]\n",
      "[35 'male' 17.86 1 'no' 'northwest' 5116.5004]\n",
      "[59 'female' 34.8 2 'no' 'southwest' 36910.60803]\n",
      "[36 'male' 33.4 2 'yes' 'southwest' 38415.474]\n",
      "[37 'female' 25.555 1 'yes' 'northeast' 20296.86345]\n",
      "[59 'male' 37.1 1 'no' 'southwest' 12347.172]\n",
      "[36 'male' 30.875 1 'no' 'northwest' 5373.36425]\n",
      "[39 'male' 34.1 2 'no' 'southeast' 23563.01618]\n",
      "[18 'male' 21.47 0 'no' 'northeast' 1702.4553]\n",
      "[52 'female' 33.3 2 'no' 'southwest' 10806.839]\n",
      "[27 'female' 31.255 1 'no' 'northwest' 3956.07145]\n",
      "[18 'male' 39.14 0 'no' 'northeast' 12890.05765]\n",
      "[40 'male' 25.08 0 'no' 'southeast' 5415.6612]\n",
      "[29 'male' 37.29 2 'no' 'southeast' 4058.1161]\n",
      "[46 'female' 34.6 1 'yes' 'southwest' 41661.602]\n",
      "[38 'female' 30.21 3 'no' 'northwest' 7537.1639]\n",
      "[30 'female' 21.945 1 'no' 'northeast' 4718.20355]\n",
      "[40 'male' 24.97 2 'no' 'southeast' 6593.5083]\n",
      "[50 'male' 25.3 0 'no' 'southeast' 8442.667]\n",
      "[20 'female' 24.42 0 'yes' 'southeast' 26125.67477]\n",
      "[41 'male' 23.94 1 'no' 'northeast' 6858.4796]\n",
      "[33 'female' 39.82 1 'no' 'southeast' 4795.6568]\n",
      "[38 'male' 16.815 2 'no' 'northeast' 6640.54485]\n",
      "[42 'male' 37.18 2 'no' 'southeast' 7162.0122]\n",
      "[56 'male' 34.43 0 'no' 'southeast' 10594.2257]\n",
      "[58 'male' 30.305 0 'no' 'northeast' 11938.25595]\n",
      "[52 'male' 34.485 3 'yes' 'northwest' 60021.39897]\n",
      "[20 'female' 21.8 0 'yes' 'southwest' 20167.33603]\n",
      "[54 'female' 24.605 3 'no' 'northwest' 12479.70895]\n",
      "[58 'male' 23.3 0 'no' 'southwest' 11345.519]\n",
      "[45 'female' 27.83 2 'no' 'southeast' 8515.7587]\n",
      "[26 'male' 31.065 0 'no' 'northwest' 2699.56835]\n",
      "[63 'female' 21.66 0 'no' 'northeast' 14449.8544]\n",
      "[58 'female' 28.215 0 'no' 'northwest' 12224.35085]\n",
      "[37 'male' 22.705 3 'no' 'northeast' 6985.50695]\n",
      "[25 'female' 42.13 1 'no' 'southeast' 3238.4357]\n",
      "[52 'male' 41.8 2 'yes' 'southeast' 47269.854]\n",
      "[64 'male' 36.96 2 'yes' 'southeast' 49577.6624]\n",
      "[22 'female' 21.28 3 'no' 'northwest' 4296.2712]\n",
      "[28 'female' 33.11 0 'no' 'southeast' 3171.6149]\n",
      "[18 'male' 33.33 0 'no' 'southeast' 1135.9407]\n",
      "[28 'male' 24.3 5 'no' 'southwest' 5615.369]\n",
      "[45 'female' 25.7 3 'no' 'southwest' 9101.798]\n",
      "[33 'male' 29.4 4 'no' 'southwest' 6059.173]\n",
      "[18 'female' 39.82 0 'no' 'southeast' 1633.9618]\n",
      "[32 'male' 33.63 1 'yes' 'northeast' 37607.5277]\n",
      "[24 'male' 29.83 0 'yes' 'northeast' 18648.4217]\n",
      "[19 'male' 19.8 0 'no' 'southwest' 1241.565]\n",
      "[20 'male' 27.3 0 'yes' 'southwest' 16232.847]\n",
      "[40 'female' 29.3 4 'no' 'southwest' 15828.82173]\n",
      "[34 'female' 27.72 0 'no' 'southeast' 4415.1588]\n",
      "[42 'female' 37.9 0 'no' 'southwest' 6474.013]\n",
      "[51 'female' 36.385 3 'no' 'northwest' 11436.73815]\n",
      "[54 'female' 27.645 1 'no' 'northwest' 11305.93455]\n",
      "[55 'male' 37.715 3 'no' 'northwest' 30063.58055]\n",
      "[52 'female' 23.18 0 'no' 'northeast' 10197.7722]\n",
      "[32 'female' 20.52 0 'no' 'northeast' 4544.2348]\n",
      "[28 'male' 37.1 1 'no' 'southwest' 3277.161]\n",
      "[41 'female' 28.05 1 'no' 'southeast' 6770.1925]\n",
      "[43 'female' 29.9 1 'no' 'southwest' 7337.748]\n",
      "[49 'female' 33.345 2 'no' 'northeast' 10370.91255]\n",
      "[64 'male' 23.76 0 'yes' 'southeast' 26926.5144]\n",
      "[55 'female' 30.5 0 'no' 'southwest' 10704.47]\n",
      "[24 'male' 31.065 0 'yes' 'northeast' 34254.05335]\n",
      "[20 'female' 33.3 0 'no' 'southwest' 1880.487]\n",
      "[45 'male' 27.5 3 'no' 'southwest' 8615.3]\n",
      "[26 'male' 33.915 1 'no' 'northwest' 3292.52985]\n",
      "[25 'female' 34.485 0 'no' 'northwest' 3021.80915]\n",
      "[43 'male' 25.52 5 'no' 'southeast' 14478.33015]\n",
      "[35 'male' 27.61 1 'no' 'southeast' 4747.0529]\n",
      "[26 'male' 27.06 0 'yes' 'southeast' 17043.3414]\n",
      "[57 'male' 23.7 0 'no' 'southwest' 10959.33]\n",
      "[22 'female' 30.4 0 'no' 'northeast' 2741.948]\n",
      "[32 'female' 29.735 0 'no' 'northwest' 4357.04365]\n",
      "[39 'male' 29.925 1 'yes' 'northeast' 22462.04375]\n",
      "[25 'female' 26.79 2 'no' 'northwest' 4189.1131]\n",
      "[48 'female' 33.33 0 'no' 'southeast' 8283.6807]\n",
      "[47 'female' 27.645 2 'yes' 'northwest' 24535.69855]\n",
      "[18 'female' 21.66 0 'yes' 'northeast' 14283.4594]\n",
      "[18 'male' 30.03 1 'no' 'southeast' 1720.3537]\n",
      "[61 'male' 36.3 1 'yes' 'southwest' 47403.88]\n",
      "[47 'female' 24.32 0 'no' 'northeast' 8534.6718]\n",
      "[28 'female' 17.29 0 'no' 'northeast' 3732.6251]\n",
      "[36 'female' 25.9 1 'no' 'southwest' 5472.449]\n",
      "[20 'male' 39.4 2 'yes' 'southwest' 38344.566]\n",
      "[44 'male' 34.32 1 'no' 'southeast' 7147.4728]\n",
      "[38 'female' 19.95 2 'no' 'northeast' 7133.9025]\n",
      "[19 'male' 34.9 0 'yes' 'southwest' 34828.654]\n",
      "[21 'male' 23.21 0 'no' 'southeast' 1515.3449]\n",
      "[46 'male' 25.745 3 'no' 'northwest' 9301.89355]\n",
      "[58 'male' 25.175 0 'no' 'northeast' 11931.12525]\n",
      "[20 'male' 22.0 1 'no' 'southwest' 1964.78]\n",
      "[18 'male' 26.125 0 'no' 'northeast' 1708.92575]\n",
      "[28 'female' 26.51 2 'no' 'southeast' 4340.4409]\n",
      "[33 'male' 27.455 2 'no' 'northwest' 5261.46945]\n",
      "[19 'female' 25.745 1 'no' 'northwest' 2710.82855]\n",
      "[45 'male' 30.36 0 'yes' 'southeast' 62592.87309]\n",
      "[62 'male' 30.875 3 'yes' 'northwest' 46718.16325]\n",
      "[25 'female' 20.8 1 'no' 'southwest' 3208.787]\n",
      "[43 'male' 27.8 0 'yes' 'southwest' 37829.7242]\n",
      "[42 'male' 24.605 2 'yes' 'northeast' 21259.37795]\n",
      "[24 'female' 27.72 0 'no' 'southeast' 2464.6188]\n",
      "[29 'female' 21.85 0 'yes' 'northeast' 16115.3045]\n",
      "[32 'male' 28.12 4 'yes' 'northwest' 21472.4788]\n",
      "[25 'female' 30.2 0 'yes' 'southwest' 33900.653]\n",
      "[41 'male' 32.2 2 'no' 'southwest' 6875.961]\n",
      "[42 'male' 26.315 1 'no' 'northwest' 6940.90985]\n",
      "[33 'female' 26.695 0 'no' 'northwest' 4571.41305]\n",
      "[34 'male' 42.9 1 'no' 'southwest' 4536.259]\n",
      "[19 'female' 34.7 2 'yes' 'southwest' 36397.576]\n",
      "[30 'female' 23.655 3 'yes' 'northwest' 18765.87545]\n",
      "[18 'male' 28.31 1 'no' 'northeast' 11272.33139]\n",
      "[19 'female' 20.6 0 'no' 'southwest' 1731.677]\n",
      "[18 'male' 53.13 0 'no' 'southeast' 1163.4627]\n",
      "[35 'male' 39.71 4 'no' 'northeast' 19496.71917]\n",
      "[39 'female' 26.315 2 'no' 'northwest' 7201.70085]\n",
      "[31 'male' 31.065 3 'no' 'northwest' 5425.02335]\n",
      "[62 'male' 26.695 0 'yes' 'northeast' 28101.33305]\n",
      "[62 'male' 38.83 0 'no' 'southeast' 12981.3457]\n",
      "[42 'female' 40.37 2 'yes' 'southeast' 43896.3763]\n",
      "[31 'male' 25.935 1 'no' 'northwest' 4239.89265]\n",
      "[61 'male' 33.535 0 'no' 'northeast' 13143.33665]\n",
      "[42 'female' 32.87 0 'no' 'northeast' 7050.0213]\n",
      "[51 'male' 30.03 1 'no' 'southeast' 9377.9047]\n",
      "[23 'female' 24.225 2 'no' 'northeast' 22395.74424]\n",
      "[52 'male' 38.6 2 'no' 'southwest' 10325.206]\n",
      "[57 'female' 25.74 2 'no' 'southeast' 12629.1656]\n",
      "[23 'female' 33.4 0 'no' 'southwest' 10795.93733]\n",
      "[52 'female' 44.7 3 'no' 'southwest' 11411.685]\n",
      "[50 'male' 30.97 3 'no' 'northwest' 10600.5483]\n",
      "[18 'female' 31.92 0 'no' 'northeast' 2205.9808]\n",
      "[18 'female' 36.85 0 'no' 'southeast' 1629.8335]\n",
      "[21 'female' 25.8 0 'no' 'southwest' 2007.945]\n",
      "[61 'female' 29.07 0 'yes' 'northwest' 29141.3603]\n"
     ]
    }
   ],
   "source": [
    "for i in df.values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9366\n"
     ]
    }
   ],
   "source": [
    "print(len(df) * len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 18 28 33 32 31 46 37 60 25 62 23 56 27 52 30 34 59 63 55 22 26 35 24\n",
      " 41 38 36 21 48 40 58 53 43 64 20 61 44 57 29 45 54 49 47 51 42 50 39]\n",
      "=============================================\n",
      "47\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "print(df['age'].unique())\n",
    "print(\"=============================================\")\n",
    "print(len(df['age'].unique()))\n",
    "print(\"====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338</td>\n",
       "      <td>1338</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>677</td>\n",
       "      <td>1064</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex smoker     region\n",
       "count   1338   1338       1316\n",
       "unique     2      2          4\n",
       "top     male     no  southeast\n",
       "freq     677   1064        357"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns are : age\n",
      "The number of uniques values from: age column 47\n",
      "The Data of uniques values from: age column [19 18 28 33 32 31 46 37 60 25 62 23 56 27 52 30 34 59 63 55 22 26 35 24\n",
      " 41 38 36 21 48 40 58 53 43 64 20 61 44 57 29 45 54 49 47 51 42 50 39]\n",
      "The columns are : sex\n",
      "The number of uniques values from: sex column 2\n",
      "The Data of uniques values from: sex column ['male' 'female']\n",
      "The columns are : bmi\n",
      "The number of uniques values from: bmi column 547\n",
      "The Data of uniques values from: bmi column [   nan 33.77  33.    22.705 28.88  25.74  33.44  27.74  29.83  25.84\n",
      " 26.22  26.29  34.4   39.82  42.13  24.6   30.78  23.845 40.3   35.3\n",
      " 36.005 32.4   34.1   31.92  28.025 27.72  23.085 32.775 17.385 36.3\n",
      " 35.6   26.315 28.6   28.31  36.4   20.425 32.965 20.8   36.67  39.9\n",
      " 26.6   36.63  21.78  30.8   37.05  37.3   38.665 34.77  24.53  35.2\n",
      " 35.625 33.63  28.    34.43  28.69  36.955 31.825 31.68  22.88  37.335\n",
      " 27.36  33.66  24.7   25.935 22.42  28.9   39.1   36.19  23.98  24.75\n",
      " 28.5   28.1   32.01  27.4   34.01  29.59  35.53  39.805 26.885 38.285\n",
      " 37.62  41.23  34.8   22.895 31.16  27.2   26.98  39.49  24.795 31.3\n",
      " 38.28  19.95  19.3   31.6   25.46  30.115 29.92  27.5   28.4   30.875\n",
      " 27.94  35.09  29.7   35.72  32.205 28.595 49.06  27.17  23.37  37.1\n",
      " 23.75  28.975 31.35  33.915 28.785 28.3   37.4   17.765 34.7   26.505\n",
      " 22.04  35.9   25.555 28.05  25.175 31.9   36.    32.49  25.3   29.735\n",
      " 38.83  30.495 37.73  37.43  24.13  37.145 39.52  24.42  27.83  36.85\n",
      " 39.6   29.8   29.64  28.215 37.    33.155 18.905 41.47  30.3   15.96\n",
      " 33.345 37.7   27.835 29.2   26.41  30.69  41.895 30.9   32.2   32.11\n",
      " 31.57  26.2   30.59  32.8   18.05  39.33  32.23  24.035 36.08  22.3\n",
      " 26.4   31.8   26.73  23.1   23.21  33.7   33.25  24.64  33.88  38.06\n",
      " 41.91  31.635 36.195 17.8   24.51  22.22  38.39  29.07  22.135 26.8\n",
      " 30.02  35.86  20.9   17.29  34.21  25.365 40.15  24.415 25.2   26.84\n",
      " 24.32  42.35  19.8   32.395 30.2   29.37  34.2   27.455 27.55  20.615\n",
      " 24.3   31.79  21.56  28.12  40.565 27.645 31.2   26.62  48.07  36.765\n",
      " 33.4   45.54  28.82  22.99  27.7   25.41  34.39  22.61  37.51  38.\n",
      " 33.33  34.865 33.06  35.97  31.4   25.27  40.945 34.105 36.48  33.8\n",
      " 36.7   36.385 34.5   32.3   27.6   29.26  35.75  23.18  25.6   35.245\n",
      " 43.89  20.79  30.5   21.7   21.89  24.985 32.015 30.4   21.09  22.23\n",
      " 32.9   24.89  31.46  17.955 30.685 43.34  39.05  30.21  31.445 19.855\n",
      " 31.02  38.17  20.6   47.52  20.4   38.38  24.31  23.6   21.12  30.03\n",
      " 17.48  20.235 17.195 23.9   35.15  35.64  22.6   39.16  27.265 29.165\n",
      " 16.815 33.1   26.9   33.11  31.73  46.75  29.45  32.68  33.5   43.01\n",
      " 36.52  26.695 25.65  29.6   38.6   23.4   46.53  30.14  30.    38.095\n",
      " 28.38  28.7   33.82  24.09  32.67  25.1   32.56  41.325 39.5   34.3\n",
      " 31.065 21.47  25.08  43.4   25.7   27.93  39.2   26.03  30.25  28.93\n",
      " 35.7   35.31  31.    44.22  26.07  25.8   39.425 40.48  38.9   47.41\n",
      " 35.435 46.7   46.2   21.4   23.8   44.77  32.12  29.1   37.29  43.12\n",
      " 36.86  34.295 23.465 45.43  23.65  20.7   28.27  35.91  29.    19.57\n",
      " 31.13  21.85  40.26  33.725 29.48  32.6   37.525 23.655 37.8   19.\n",
      " 21.3   33.535 42.46  38.95  36.1   29.3   39.7   38.19  42.4   34.96\n",
      " 42.68  31.54  29.81  21.375 40.81  17.4   20.3   18.5   26.125 41.69\n",
      " 24.1   36.2   40.185 39.27  34.87  44.745 29.545 23.54  40.47  40.66\n",
      " 36.6   35.4   27.075 28.405 21.755 40.28  30.1   32.1   23.7   35.5\n",
      " 29.15  27.    37.905 22.77  22.8   34.58  27.1   19.475 26.7   34.32\n",
      " 24.4   41.14  22.515 41.8   26.18  42.24  26.51  35.815 41.42  36.575\n",
      " 42.94  21.01  24.225 17.67  31.5   31.1   32.78  32.45  50.38  47.6\n",
      " 25.4   29.9   43.7   24.86  28.8   29.5   29.04  38.94  44.    20.045\n",
      " 40.92  35.1   29.355 32.585 32.34  39.8   24.605 33.99  28.2   25.\n",
      " 33.2   23.2   20.1   32.5   37.18  46.09  39.93  35.8   31.255 18.335\n",
      " 42.9   26.79  39.615 25.9   25.745 28.16  23.56  40.5   35.42  39.995\n",
      " 34.675 20.52  23.275 36.29  32.7   19.19  20.13  23.32  45.32  34.6\n",
      " 18.715 21.565 23.    37.07  52.58  42.655 21.66  32.    18.3   47.74\n",
      " 22.1   19.095 31.24  29.925 20.35  25.85  42.75  18.6   23.87  45.9\n",
      " 21.5   30.305 44.88  41.1   40.37  28.49  33.55  40.375 27.28  17.86\n",
      " 33.3   39.14  21.945 24.97  23.94  34.485 21.8   23.3   36.96  21.28\n",
      " 29.4   27.3   37.9   37.715 23.76  25.52  27.61  27.06  39.4   34.9\n",
      " 22.    30.36  27.8   53.13  39.71  32.87  44.7   30.97 ]\n",
      "The columns are : children\n",
      "The number of uniques values from: children column 6\n",
      "The Data of uniques values from: children column [0 1 3 2 5 4]\n",
      "The columns are : smoker\n",
      "The number of uniques values from: smoker column 2\n",
      "The Data of uniques values from: smoker column ['yes' 'no']\n",
      "The columns are : region\n",
      "The number of uniques values from: region column 4\n",
      "The Data of uniques values from: region column [nan 'southeast' 'northeast' 'northwest' 'southwest']\n",
      "The columns are : charges\n",
      "The number of uniques values from: charges column 1337\n",
      "The Data of uniques values from: charges column [16884.924   1725.5523  4449.462  ...  1629.8335  2007.945  29141.3603]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(\"The columns are :\",col)\n",
    "    print(\"The number of uniques values from:\",col,\"column\",(df[col].nunique()))\n",
    "    print(\"The Data of uniques values from:\",col,\"column\",(df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"region\"].value_counts().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([357, 321, 319])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"region\"].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69, 68, 29, 28, 27, 26, 25, 23, 22])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "southeast    0.271277\n",
       "northwest    0.243921\n",
       "northeast    0.242401\n",
       "southwest    0.242401\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "southeast    357\n",
       "northwest    321\n",
       "northeast    319\n",
       "southwest    319\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "southeast    357\n",
       "northwest    321\n",
       "northeast    319\n",
       "southwest    319\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].value_counts(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Series in module pandas.core.series object:\n",
      "\n",
      "class Series(pandas.core.base.IndexOpsMixin, pandas.core.generic.NDFrame)\n",
      " |  Series(data=None, index=None, dtype: 'Dtype | None' = None, name=None, copy: 'bool | None' = None, fastpath: 'bool | lib.NoDefault' = <no_default>) -> 'None'\n",
      " |\n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |\n",
      " |  Labels need not be unique but must be a hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN).\n",
      " |\n",
      " |  Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, Iterable, dict, or scalar value\n",
      " |      Contains data stored in Series. If data is a dict, argument order is\n",
      " |      maintained.\n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be hashable and have the same length as `data`.\n",
      " |      Non-unique index values are allowed. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
      " |      and index is None, then the keys in the data are used as the index. If the\n",
      " |      index is not None, the resulting Series is reindexed with the index values.\n",
      " |  dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
      " |      Data type for the output Series. If not specified, this will be\n",
      " |      inferred from `data`.\n",
      " |      See the :ref:`user guide <basics.dtypes>` for more usages.\n",
      " |  name : Hashable, default None\n",
      " |      The name to give to the Series.\n",
      " |  copy : bool, default False\n",
      " |      Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  Please reference the :ref:`User Guide <basics.series>` for more information.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing Series from a dictionary with an Index specified\n",
      " |\n",
      " |  >>> d = {'a': 1, 'b': 2, 'c': 3}\n",
      " |  >>> ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
      " |  >>> ser\n",
      " |  a   1\n",
      " |  b   2\n",
      " |  c   3\n",
      " |  dtype: int64\n",
      " |\n",
      " |  The keys of the dictionary match with the Index values, hence the Index\n",
      " |  values have no effect.\n",
      " |\n",
      " |  >>> d = {'a': 1, 'b': 2, 'c': 3}\n",
      " |  >>> ser = pd.Series(data=d, index=['x', 'y', 'z'])\n",
      " |  >>> ser\n",
      " |  x   NaN\n",
      " |  y   NaN\n",
      " |  z   NaN\n",
      " |  dtype: float64\n",
      " |\n",
      " |  Note that the Index is first build with the keys from the dictionary.\n",
      " |  After this the Series is reindexed with the given Index values, hence we\n",
      " |  get all NaN as a result.\n",
      " |\n",
      " |  Constructing Series from a list with `copy=False`.\n",
      " |\n",
      " |  >>> r = [1, 2]\n",
      " |  >>> ser = pd.Series(r, copy=False)\n",
      " |  >>> ser.iloc[0] = 999\n",
      " |  >>> r\n",
      " |  [1, 2]\n",
      " |  >>> ser\n",
      " |  0    999\n",
      " |  1      2\n",
      " |  dtype: int64\n",
      " |\n",
      " |  Due to input data type the Series has a `copy` of\n",
      " |  the original data even though `copy=False`, so\n",
      " |  the data is unchanged.\n",
      " |\n",
      " |  Constructing Series from a 1d ndarray with `copy=False`.\n",
      " |\n",
      " |  >>> r = np.array([1, 2])\n",
      " |  >>> ser = pd.Series(r, copy=False)\n",
      " |  >>> ser.iloc[0] = 999\n",
      " |  >>> r\n",
      " |  array([999,   2])\n",
      " |  >>> ser\n",
      " |  0    999\n",
      " |  1      2\n",
      " |  dtype: int64\n",
      " |\n",
      " |  Due to input data type the Series has a `view` on\n",
      " |  the original data, so\n",
      " |  the data is changed as well.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __array__(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool | None' = None) -> 'np.ndarray'\n",
      " |      Return the values as a NumPy array.\n",
      " |\n",
      " |      Users should not call this directly. Rather, it is invoked by\n",
      " |      :func:`numpy.array` and :func:`numpy.asarray`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to use for the resulting NumPy array. By default,\n",
      " |          the dtype is inferred from the data.\n",
      " |\n",
      " |      copy : bool or None, optional\n",
      " |          Unused.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values in the series converted to a :class:`numpy.ndarray`\n",
      " |          with the specified `dtype`.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      array : Create a new array from data.\n",
      " |      Series.array : Zero-copy view to the array backing the Series.\n",
      " |      Series.to_numpy : Series method for similar behavior.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> np.asarray(ser)\n",
      " |      array([1, 2, 3])\n",
      " |\n",
      " |      For timezone-aware data, the timezones may be retained with\n",
      " |      ``dtype='object'``\n",
      " |\n",
      " |      >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> np.asarray(tzser, dtype=\"object\")\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\n",
      " |            dtype=object)\n",
      " |\n",
      " |      Or the values may be localized to UTC and the tzinfo discarded with\n",
      " |      ``dtype='datetime64[ns]'``\n",
      " |\n",
      " |      >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', ...],\n",
      " |            dtype='datetime64[ns]')\n",
      " |\n",
      " |  __column_consortium_standard__(self, *, api_version: 'str | None' = None) -> 'Any'\n",
      " |      Provide entry point to the Consortium DataFrame Standard API.\n",
      " |\n",
      " |      This is developed and maintained outside of pandas.\n",
      " |      Please report any issues to https://github.com/data-apis/dataframe-api-compat.\n",
      " |\n",
      " |  __float__(self) from pandas.core.series._coerce_method.<locals>\n",
      " |\n",
      " |  __getitem__(self, key)\n",
      " |\n",
      " |  __init__(self, data=None, index=None, dtype: 'Dtype | None' = None, name=None, copy: 'bool | None' = None, fastpath: 'bool | lib.NoDefault' = <no_default>) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __int__(self) from pandas.core.series._coerce_method.<locals>\n",
      " |\n",
      " |  __len__(self) -> 'int'\n",
      " |      Return the length of the Series.\n",
      " |\n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator.\n",
      " |\n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular Series.\n",
      " |\n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator.\n",
      " |\n",
      " |  __setitem__(self, key, value) -> 'None'\n",
      " |\n",
      " |  add(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Addition of series and other, element-wise (binary operator `add`).\n",
      " |\n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.radd : Reverse of the Addition operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  agg = aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |\n",
      " |  aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply.\n",
      " |\n",
      " |          Accepted combinations are:\n",
      " |\n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index'}\n",
      " |              Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |\n",
      " |          The return can be:\n",
      " |\n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : Invoke function on a Series.\n",
      " |      Series.transform : Transform function producing a Series with like indexes.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |\n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.agg('min')\n",
      " |      1\n",
      " |\n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   1\n",
      " |      max   4\n",
      " |      dtype: int64\n",
      " |\n",
      " |  all(self, axis: 'Axis' = 0, bool_only: 'bool' = False, skipna: 'bool' = True, **kwargs) -> 'bool'\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |\n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |\n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |\n",
      " |      bool_only : bool, default False\n",
      " |          Include only boolean columns. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          If level is specified, then, Series is returned; otherwise, scalar\n",
      " |          is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |\n",
      " |      **DataFrames**\n",
      " |\n",
      " |      Create a dataframe from a dictionary.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |\n",
      " |      Default behaviour checks if values in each column all return True.\n",
      " |\n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Specify ``axis='columns'`` to check if values in each row all return True.\n",
      " |\n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |\n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |\n",
      " |  any(self, *, axis: 'Axis' = 0, bool_only: 'bool' = False, skipna: 'bool' = True, **kwargs) -> 'bool'\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |\n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |\n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |\n",
      " |      bool_only : bool, default False\n",
      " |          Include only boolean columns. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          If level is specified, then, Series is returned; otherwise, scalar\n",
      " |          is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |\n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |\n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Aggregating over the columns.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |\n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |\n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |\n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |\n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |\n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |\n",
      " |  apply(self, func: 'AggFuncType', convert_dtype: 'bool | lib.NoDefault' = <no_default>, args: 'tuple[Any, ...]' = (), *, by_row: \"Literal[False, 'compat']\" = 'compat', **kwargs) -> 'DataFrame | Series'\n",
      " |      Invoke function on values of Series.\n",
      " |\n",
      " |      Can be ufunc (a NumPy function that applies to the entire Series)\n",
      " |      or a Python function that only works on single values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Python function or NumPy ufunc to apply.\n",
      " |      convert_dtype : bool, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object. Note that the dtype is always\n",
      " |          preserved for some extension array dtypes, such as Categorical.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |              ``convert_dtype`` has been deprecated. Do ``ser.astype(object).apply()``\n",
      " |              instead if you want ``convert_dtype=False``.\n",
      " |      args : tuple\n",
      " |          Positional arguments passed to func after the series value.\n",
      " |      by_row : False or \"compat\", default \"compat\"\n",
      " |          If ``\"compat\"`` and func is a callable, func will be passed each element of\n",
      " |          the Series, like ``Series.map``. If func is a list or dict of\n",
      " |          callables, will first try to translate each func into pandas methods. If\n",
      " |          that doesn't work, will try call to apply again with ``by_row=\"compat\"``\n",
      " |          and if that fails, will call apply again with ``by_row=False``\n",
      " |          (backward compatible).\n",
      " |          If False, the func will be passed the whole Series at once.\n",
      " |\n",
      " |          ``by_row`` has no effect when ``func`` is a string.\n",
      " |\n",
      " |          .. versionadded:: 2.1.0\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments passed to func.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If func returns a Series object the result will be a DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations.\n",
      " |      Series.agg: Only perform aggregating type operations.\n",
      " |      Series.transform: Only perform transforming type operations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |\n",
      " |      >>> s = pd.Series([20, 21, 12],\n",
      " |      ...               index=['London', 'New York', 'Helsinki'])\n",
      " |      >>> s\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |\n",
      " |      >>> def square(x):\n",
      " |      ...     return x ** 2\n",
      " |      >>> s.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |\n",
      " |      >>> s.apply(lambda x: x ** 2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |\n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x - custom_value\n",
      " |\n",
      " |      >>> s.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |\n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x += kwargs[month]\n",
      " |      ...     return x\n",
      " |\n",
      " |      >>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Use a function from the Numpy library.\n",
      " |\n",
      " |      >>> s.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |\n",
      " |  argsort(self, axis: 'Axis' = 0, kind: 'SortKind' = 'quicksort', order: 'None' = None, stable: 'None' = None) -> 'Series'\n",
      " |      Return the integer indices that would sort the Series values.\n",
      " |\n",
      " |      Override ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' and 'stable' are the only stable algorithms.\n",
      " |      order : None\n",
      " |          Has no effect but is accepted for compatibility with numpy.\n",
      " |      stable : None\n",
      " |          Has no effect but is accepted for compatibility with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series[np.intp]\n",
      " |          Positions of values within the sort order with -1 indicating\n",
      " |          nan values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort : Returns the indices that would sort this array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([3, 2, 1])\n",
      " |      >>> s.argsort()\n",
      " |      0    2\n",
      " |      1    1\n",
      " |      2    0\n",
      " |      dtype: int64\n",
      " |\n",
      " |  autocorr(self, lag: 'int' = 1) -> 'float'\n",
      " |      Compute the lag-N autocorrelation.\n",
      " |\n",
      " |      This method computes the Pearson correlation between\n",
      " |      the Series and its shifted self.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The Pearson correlation between self and self.shift(lag).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      Series.shift : Shift index by desired number of periods.\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      DataFrame.corrwith : Compute pairwise correlation between rows or\n",
      " |          columns of two DataFrame objects.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the Pearson correlation is not well defined return 'NaN'.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.25, 0.5, 0.2, -0.05])\n",
      " |      >>> s.autocorr()  # doctest: +ELLIPSIS\n",
      " |      0.10355...\n",
      " |      >>> s.autocorr(lag=2)  # doctest: +ELLIPSIS\n",
      " |      -0.99999...\n",
      " |\n",
      " |      If the Pearson correlation is not well defined, then 'NaN' is returned.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 0, 0, 0])\n",
      " |      >>> s.autocorr()\n",
      " |      nan\n",
      " |\n",
      " |  between(self, left, right, inclusive: \"Literal['both', 'neither', 'left', 'right']\" = 'both') -> 'Series'\n",
      " |      Return boolean Series equivalent to left <= series <= right.\n",
      " |\n",
      " |      This function returns a boolean vector containing `True` wherever the\n",
      " |      corresponding Series element is between the boundary values `left` and\n",
      " |      `right`. NA values are treated as `False`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar or list-like\n",
      " |          Left boundary.\n",
      " |      right : scalar or list-like\n",
      " |          Right boundary.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}\n",
      " |          Include boundaries. Whether to set each bound as closed or open.\n",
      " |\n",
      " |          .. versionchanged:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series representing whether each element is between left and\n",
      " |          right (inclusive).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.gt : Greater than of series and other.\n",
      " |      Series.lt : Less than of series and other.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is equivalent to ``(left <= ser) & (ser <= right)``\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 0, 4, 8, np.nan])\n",
      " |\n",
      " |      Boundary values are included by default:\n",
      " |\n",
      " |      >>> s.between(1, 4)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      With `inclusive` set to ``\"neither\"`` boundary values are excluded:\n",
      " |\n",
      " |      >>> s.between(1, 4, inclusive=\"neither\")\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      `left` and `right` can be any scalar value:\n",
      " |\n",
      " |      >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
      " |      >>> s.between('Anna', 'Daniel')\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  case_when(self, caselist: 'list[tuple[ArrayLike | Callable[[Series], Series | np.ndarray | Sequence[bool]], ArrayLike | Scalar | Callable[[Series], Series | np.ndarray]],]') -> 'Series'\n",
      " |      Replace values where the conditions are True.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      caselist : A list of tuples of conditions and expected replacements\n",
      " |          Takes the form:  ``(condition0, replacement0)``,\n",
      " |          ``(condition1, replacement1)``, ... .\n",
      " |          ``condition`` should be a 1-D boolean array-like object\n",
      " |          or a callable. If ``condition`` is a callable,\n",
      " |          it is computed on the Series\n",
      " |          and should return a boolean Series or array.\n",
      " |          The callable must not change the input Series\n",
      " |          (though pandas doesn`t check it). ``replacement`` should be a\n",
      " |          1-D array-like object, a scalar or a callable.\n",
      " |          If ``replacement`` is a callable, it is computed on the Series\n",
      " |          and should return a scalar or Series. The callable\n",
      " |          must not change the input Series\n",
      " |          (though pandas doesn`t check it).\n",
      " |\n",
      " |          .. versionadded:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mask : Replace values where the condition is True.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> c = pd.Series([6, 7, 8, 9], name='c')\n",
      " |      >>> a = pd.Series([0, 0, 1, 2])\n",
      " |      >>> b = pd.Series([0, 3, 4, 5])\n",
      " |\n",
      " |      >>> c.case_when(caselist=[(a.gt(0), a),  # condition, replacement\n",
      " |      ...                       (b.gt(0), b)])\n",
      " |      0    6\n",
      " |      1    3\n",
      " |      2    1\n",
      " |      3    2\n",
      " |      Name: c, dtype: int64\n",
      " |\n",
      " |  combine(self, other: 'Series | Hashable', func: 'Callable[[Hashable, Hashable], Hashable]', fill_value: 'Hashable | None' = None) -> 'Series'\n",
      " |      Combine the Series with a Series or scalar according to `func`.\n",
      " |\n",
      " |      Combine the Series and `other` using `func` to perform elementwise\n",
      " |      selection for combined Series.\n",
      " |      `fill_value` is assumed when value is missing at some index\n",
      " |      from one of the two objects being combined.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar\n",
      " |          The value(s) to be combined with the `Series`.\n",
      " |      func : function\n",
      " |          Function that takes two scalars as inputs and returns an element.\n",
      " |      fill_value : scalar, optional\n",
      " |          The value to assume when an index is missing from\n",
      " |          one Series or the other. The default specifies to use the\n",
      " |          appropriate NaN value for the underlying dtype of the Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of combining the Series with the other object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine_first : Combine Series values, choosing the calling\n",
      " |          Series' values first.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider 2 Datasets ``s1`` and ``s2`` containing\n",
      " |      highest clocked speeds of different birds.\n",
      " |\n",
      " |      >>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n",
      " |      >>> s1\n",
      " |      falcon    330.0\n",
      " |      eagle     160.0\n",
      " |      dtype: float64\n",
      " |      >>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n",
      " |      >>> s2\n",
      " |      falcon    345.0\n",
      " |      eagle     200.0\n",
      " |      duck       30.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Now, to combine the two datasets and view the highest speeds\n",
      " |      of the birds across the two datasets\n",
      " |\n",
      " |      >>> s1.combine(s2, max)\n",
      " |      duck        NaN\n",
      " |      eagle     200.0\n",
      " |      falcon    345.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      In the previous example, the resulting value for duck is missing,\n",
      " |      because the maximum of a NaN and a float is a NaN.\n",
      " |      So, in the example, we set ``fill_value=0``,\n",
      " |      so the maximum value returned will be the value from some dataset.\n",
      " |\n",
      " |      >>> s1.combine(s2, max, fill_value=0)\n",
      " |      duck       30.0\n",
      " |      eagle     200.0\n",
      " |      falcon    345.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  combine_first(self, other) -> 'Series'\n",
      " |      Update null elements with value in the same location in 'other'.\n",
      " |\n",
      " |      Combine two Series objects by filling null values in one Series with\n",
      " |      non-null values from the other Series. Result index will be the union\n",
      " |      of the two indexes.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          The value(s) to be used for filling null values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of combining the provided Series with the other object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine : Perform element-wise operation on two Series\n",
      " |          using a given function.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, np.nan])\n",
      " |      >>> s2 = pd.Series([3, 4, 5])\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      0    1.0\n",
      " |      1    4.0\n",
      " |      2    5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |\n",
      " |      >>> s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})\n",
      " |      >>> s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      duck       30.0\n",
      " |      eagle     160.0\n",
      " |      falcon      NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  compare(self, other: 'Series', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False, result_names: 'Suffixes' = ('self', 'other')) -> 'DataFrame | Series'\n",
      " |      Compare to another Series and show the differences.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Object to compare with.\n",
      " |\n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |\n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |\n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |\n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |\n",
      " |      result_names : tuple, default ('self', 'other')\n",
      " |          Set the dataframes names in the comparison.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If axis is 0 or 'index' the result will be a Series.\n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |\n",
      " |          If axis is 1 or 'columns' the result will be a DataFrame.\n",
      " |          It will have two columns namely 'self' and 'other'.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.compare : Compare with another DataFrame and show differences.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
      " |      >>> s2 = pd.Series([\"a\", \"a\", \"c\", \"b\", \"e\"])\n",
      " |\n",
      " |      Align the differences on columns\n",
      " |\n",
      " |      >>> s1.compare(s2)\n",
      " |        self other\n",
      " |      1    b     a\n",
      " |      3    d     b\n",
      " |\n",
      " |      Stack the differences on indices\n",
      " |\n",
      " |      >>> s1.compare(s2, align_axis=0)\n",
      " |      1  self     b\n",
      " |         other    a\n",
      " |      3  self     d\n",
      " |         other    b\n",
      " |      dtype: object\n",
      " |\n",
      " |      Keep all original rows\n",
      " |\n",
      " |      >>> s1.compare(s2, keep_shape=True)\n",
      " |        self other\n",
      " |      0  NaN   NaN\n",
      " |      1    b     a\n",
      " |      2  NaN   NaN\n",
      " |      3    d     b\n",
      " |      4  NaN   NaN\n",
      " |\n",
      " |      Keep all original rows and also all original values\n",
      " |\n",
      " |      >>> s1.compare(s2, keep_shape=True, keep_equal=True)\n",
      " |        self other\n",
      " |      0    a     a\n",
      " |      1    b     a\n",
      " |      2    c     c\n",
      " |      3    d     b\n",
      " |      4    e     e\n",
      " |\n",
      " |  corr(self, other: 'Series', method: 'CorrelationMethod' = 'pearson', min_periods: 'int | None' = None) -> 'float'\n",
      " |      Compute correlation with `other` Series, excluding missing values.\n",
      " |\n",
      " |      The two `Series` objects are not required to be the same length and will be\n",
      " |      aligned internally before the correlation function is applied.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the correlation.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method used to compute correlation:\n",
      " |\n",
      " |          - pearson : Standard correlation coefficient\n",
      " |          - kendall : Kendall Tau correlation coefficient\n",
      " |          - spearman : Spearman rank correlation\n",
      " |          - callable: Callable with input two 1d ndarrays and returning a float.\n",
      " |\n",
      " |          .. warning::\n",
      " |              Note that the returned matrix from corr will have 1 along the\n",
      " |              diagonals and will be symmetric regardless of the callable's\n",
      " |              behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Correlation with other.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation between columns.\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
      " |\n",
      " |      * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\n",
      " |      * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\n",
      " |      * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\n",
      " |\n",
      " |      Automatic data alignment: as with all pandas operations, automatic data alignment is performed for this method.\n",
      " |      ``corr()`` automatically considers values with matching indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> s1 = pd.Series([.2, .0, .6, .2])\n",
      " |      >>> s2 = pd.Series([.3, .6, .0, .1])\n",
      " |      >>> s1.corr(s2, method=histogram_intersection)\n",
      " |      0.3\n",
      " |\n",
      " |      Pandas auto-aligns the values with matching indices\n",
      " |\n",
      " |      >>> s1 = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
      " |      >>> s2 = pd.Series([1, 2, 3], index=[2, 1, 0])\n",
      " |      >>> s1.corr(s2)\n",
      " |      -1.0\n",
      " |\n",
      " |  count(self) -> 'int'\n",
      " |      Return number of non-NA/null observations in the Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Number of non-null values in the Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count : Count non-NA cells for each column or row.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.0, 1.0, np.nan])\n",
      " |      >>> s.count()\n",
      " |      2\n",
      " |\n",
      " |  cov(self, other: 'Series', min_periods: 'int | None' = None, ddof: 'int | None' = 1) -> 'float'\n",
      " |      Compute covariance with Series, excluding missing values.\n",
      " |\n",
      " |      The two `Series` objects are not required to be the same length and\n",
      " |      will be aligned internally before the covariance is calculated.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the covariance.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Covariance between Series and other normalized by N-1\n",
      " |          (unbiased estimator).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.cov : Compute pairwise covariance of columns.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n",
      " |      >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n",
      " |      >>> s1.cov(s2)\n",
      " |      -0.01685762652715874\n",
      " |\n",
      " |  cummax(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative maximum of scalar or Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.max : Return the maximum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |\n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |\n",
      " |  cummin(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative minimum of scalar or Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.min : Return the minimum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |  cumprod(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative product of scalar or Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.prod : Return the product over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |\n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |  cumsum(self, axis: 'Axis | None' = None, skipna: 'bool' = True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |\n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative sum of scalar or Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.sum : Return the sum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      By default, NA values are ignored.\n",
      " |\n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |\n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |\n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |\n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |\n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |\n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |\n",
      " |  diff(self, periods: 'int' = 1) -> 'Series'\n",
      " |      First discrete difference of element.\n",
      " |\n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          First differences of the Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in Series,\n",
      " |      however dtype of the result is always float64.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      Difference with previous row\n",
      " |\n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Difference with 3rd previous row\n",
      " |\n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Difference with following row\n",
      " |\n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Overflow in input dtype\n",
      " |\n",
      " |      >>> s = pd.Series([1, 0], dtype=np.uint8)\n",
      " |      >>> s.diff()\n",
      " |      0      NaN\n",
      " |      1    255.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |\n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |\n",
      " |  divmod(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Integer division and modulo of series and other, element-wise (binary operator `divmod`).\n",
      " |\n",
      " |      Equivalent to ``divmod(series, other)``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      2-Tuple of Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rdivmod : Reverse of the Integer division and modulo operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divmod(b, fill_value=0)\n",
      " |      (a    1.0\n",
      " |       b    inf\n",
      " |       c    inf\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64,\n",
      " |       a    0.0\n",
      " |       b    NaN\n",
      " |       c    NaN\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64)\n",
      " |\n",
      " |  dot(self, other: 'AnyArrayLike') -> 'Series | np.ndarray'\n",
      " |      Compute the dot product between the Series and the columns of other.\n",
      " |\n",
      " |      This method computes the dot product between the Series and another\n",
      " |      one, or the Series and each columns of a DataFrame, or the Series and\n",
      " |      each columns of an array.\n",
      " |\n",
      " |      It can also be called using `self @ other`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the dot product with its columns.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or numpy.ndarray\n",
      " |          Return the dot product of the Series and other if other is a\n",
      " |          Series, the Series of the dot product of Series and each rows of\n",
      " |          other if other is a DataFrame or a numpy.ndarray between the Series\n",
      " |          and each columns of the numpy array.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dot: Compute the matrix product with the DataFrame.\n",
      " |      Series.mul: Multiplication of series and other, element-wise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The Series and other has to share the same index if other is a Series\n",
      " |      or a DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 1, 2, 3])\n",
      " |      >>> other = pd.Series([-1, 2, -3, 4])\n",
      " |      >>> s.dot(other)\n",
      " |      8\n",
      " |      >>> s @ other\n",
      " |      8\n",
      " |      >>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
      " |      >>> s.dot(df)\n",
      " |      0    24\n",
      " |      1    14\n",
      " |      dtype: int64\n",
      " |      >>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
      " |      >>> s.dot(arr)\n",
      " |      array([24, 14])\n",
      " |\n",
      " |  drop(self, labels: 'IndexLabel | None' = None, *, axis: 'Axis' = 0, index: 'IndexLabel | None' = None, columns: 'IndexLabel | None' = None, level: 'Level | None' = None, inplace: 'bool' = False, errors: 'IgnoreRaise' = 'raise') -> 'Series | None'\n",
      " |      Return Series with specified index labels removed.\n",
      " |\n",
      " |      Remove elements of a Series based on specifying the index labels.\n",
      " |      When using a multi-index, labels on different levels can be removed\n",
      " |      by specifying the level.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index labels to drop.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      index : single label or list-like\n",
      " |          Redundant for application on Series, but 'index' can be used instead\n",
      " |          of 'labels'.\n",
      " |      columns : single label or list-like\n",
      " |          No change is made to the Series; use 'index' or 'labels' instead.\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level for which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are dropped.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with specified index labels removed or None if ``inplace=True``.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Return only specified index labels of Series.\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      DataFrame.drop : Drop specified labels from rows or columns.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n",
      " |      >>> s\n",
      " |      A  0\n",
      " |      B  1\n",
      " |      C  2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Drop labels B en C\n",
      " |\n",
      " |      >>> s.drop(labels=['B', 'C'])\n",
      " |      A  0\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Drop 2nd level label in MultiIndex Series\n",
      " |\n",
      " |      >>> midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
      " |      ...               index=midx)\n",
      " |      >>> s\n",
      " |      llama   speed      45.0\n",
      " |              weight    200.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              weight    250.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              weight      1.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.drop(labels='weight', level=1)\n",
      " |      llama   speed      45.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |\n",
      " |  drop_duplicates(self, *, keep: 'DropKeep' = 'first', inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'Series | None'\n",
      " |      Return Series with duplicate values removed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          Method to handle dropping duplicates:\n",
      " |\n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |\n",
      " |      inplace : bool, default ``False``\n",
      " |          If ``True``, performs operation inplace and returns None.\n",
      " |\n",
      " |      ignore_index : bool, default ``False``\n",
      " |          If ``True``, the resulting axis will be labeled 0, 1, â€¦, n - 1.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with duplicates dropped or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.drop_duplicates : Equivalent method on Index.\n",
      " |      DataFrame.drop_duplicates : Equivalent method on DataFrame.\n",
      " |      Series.duplicated : Related method on Series, indicating duplicate\n",
      " |          Series values.\n",
      " |      Series.unique : Return unique values as an array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate a Series with duplicated entries.\n",
      " |\n",
      " |      >>> s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama', 'hippo'],\n",
      " |      ...               name='animal')\n",
      " |      >>> s\n",
      " |      0     llama\n",
      " |      1       cow\n",
      " |      2     llama\n",
      " |      3    beetle\n",
      " |      4     llama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |\n",
      " |      With the 'keep' parameter, the selection behaviour of duplicated values\n",
      " |      can be changed. The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |\n",
      " |      >>> s.drop_duplicates()\n",
      " |      0     llama\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |\n",
      " |      The value 'last' for parameter 'keep' keeps the last occurrence for\n",
      " |      each set of duplicated entries.\n",
      " |\n",
      " |      >>> s.drop_duplicates(keep='last')\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      4     llama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |\n",
      " |      The value ``False`` for parameter 'keep' discards all sets of\n",
      " |      duplicated entries.\n",
      " |\n",
      " |      >>> s.drop_duplicates(keep=False)\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |\n",
      " |  dropna(self, *, axis: 'Axis' = 0, inplace: 'bool' = False, how: 'AnyAll | None' = None, ignore_index: 'bool' = False) -> 'Series | None'\n",
      " |      Return a new Series with missing values removed.\n",
      " |\n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      how : str, optional\n",
      " |          Not in use. Kept for compatibility.\n",
      " |      ignore_index : bool, default ``False``\n",
      " |          If ``True``, the resulting axis will be labeled 0, 1, â€¦, n - 1.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with NA entries dropped from it or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isna: Indicate missing values.\n",
      " |      Series.notna : Indicate existing (non-missing) values.\n",
      " |      Series.fillna : Replace missing values.\n",
      " |      DataFrame.dropna : Drop rows or columns which contain NA values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1., 2., np.nan])\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Drop NA values from a Series.\n",
      " |\n",
      " |      >>> ser.dropna()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Empty strings are not considered NA values. ``None`` is considered an\n",
      " |      NA value.\n",
      " |\n",
      " |      >>> ser = pd.Series([np.nan, 2, pd.NaT, '', None, 'I stay'])\n",
      " |      >>> ser\n",
      " |      0       NaN\n",
      " |      1         2\n",
      " |      2       NaT\n",
      " |      3\n",
      " |      4      None\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |      >>> ser.dropna()\n",
      " |      1         2\n",
      " |      3\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |\n",
      " |  duplicated(self, keep: 'DropKeep' = 'first') -> 'Series'\n",
      " |      Indicate duplicate Series values.\n",
      " |\n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      Series. Either all duplicates, all except the first or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Method to handle dropping duplicates:\n",
      " |\n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series[bool]\n",
      " |          Series indicating whether each value has occurred in the\n",
      " |          preceding values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on pandas.Index.\n",
      " |      DataFrame.duplicated : Equivalent method on pandas.DataFrame.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set on False and all others on True:\n",
      " |\n",
      " |      >>> animals = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama'])\n",
      " |      >>> animals.duplicated()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |      which is equivalent to\n",
      " |\n",
      " |      >>> animals.duplicated(keep='first')\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |\n",
      " |      >>> animals.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |\n",
      " |      >>> animals.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  eq(self, other, level: 'Level | None' = None, fill_value: 'float | None' = None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |\n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.eq(b, fill_value=0)\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      c    False\n",
      " |      d    False\n",
      " |      e    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  explode(self, ignore_index: 'bool' = False) -> 'Series'\n",
      " |      Transform each element of a list-like to a row.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, â€¦, n - 1.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Exploded lists to rows; index will be duplicated for these rows.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.str.split : Split string values on specified separator.\n",
      " |      Series.unstack : Unstack, a.k.a. pivot, Series with MultiIndex\n",
      " |          to produce DataFrame.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |          columns to long format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of elements in\n",
      " |      the output will be non-deterministic when exploding sets.\n",
      " |\n",
      " |      Reference :ref:`the user guide <reshaping.explode>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])\n",
      " |      >>> s\n",
      " |      0    [1, 2, 3]\n",
      " |      1          foo\n",
      " |      2           []\n",
      " |      3       [3, 4]\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s.explode()\n",
      " |      0      1\n",
      " |      0      2\n",
      " |      0      3\n",
      " |      1    foo\n",
      " |      2    NaN\n",
      " |      3      3\n",
      " |      3      4\n",
      " |      dtype: object\n",
      " |\n",
      " |  floordiv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |\n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rfloordiv : Reverse of the Integer division operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.floordiv(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  ge(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |\n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.ge(b, fill_value=0)\n",
      " |      a     True\n",
      " |      b     True\n",
      " |      c    False\n",
      " |      d    False\n",
      " |      e     True\n",
      " |      f    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  groupby(self, by=None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool | lib.NoDefault' = <no_default>, dropna: 'bool' = True) -> 'SeriesGroupBy'\n",
      " |      Group Series using a mapper or by a Series of columns.\n",
      " |\n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, pd.Grouper or list of such\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If a list or ndarray of length\n",
      " |          equal to the selected axis is passed (see the `groupby user guide\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups>`_),\n",
      " |          the values are used as-is to determine the groups. A label or list\n",
      " |          of labels may be passed to group by the columns in ``self``.\n",
      " |          Notice that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1). For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |              Will be removed and behave like axis=0 in a future version.\n",
      " |              For ``axis=1``, do ``frame.T.groupby(...)`` instead.\n",
      " |\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels. Do not specify both ``by`` and ``level``.\n",
      " |      as_index : bool, default True\n",
      " |          Return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output. This argument has no effect\n",
      " |          on filtrations (see the `filtrations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#filtration>`_),\n",
      " |          such as ``head()``, ``tail()``, ``nth()`` and in transformations\n",
      " |          (see the `transformations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#transformation>`_).\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group. If False,\n",
      " |          the groups will appear in the same order as they did in the original DataFrame.\n",
      " |          This argument has no effect on filtrations (see the `filtrations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#filtration>`_),\n",
      " |          such as ``head()``, ``tail()``, ``nth()`` and in transformations\n",
      " |          (see the `transformations in the user guide\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/groupby.html#transformation>`_).\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              Specifying ``sort=False`` with an ordered categorical grouper will no\n",
      " |              longer sort the values.\n",
      " |\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply and the ``by`` argument produces a like-indexed\n",
      " |          (i.e. :ref:`a transform <groupby.transform>`) result, add group keys to\n",
      " |          index to identify pieces. By default group keys are not included\n",
      " |          when the result's index (and column) labels match the inputs, and\n",
      " |          are included otherwise.\n",
      " |\n",
      " |          .. versionchanged:: 1.5.0\n",
      " |\n",
      " |             Warns that ``group_keys`` will no longer be ignored when the\n",
      " |             result from ``apply`` is a like-indexed Series or DataFrame.\n",
      " |             Specify ``group_keys`` explicitly to include the group keys or\n",
      " |             not.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |             ``group_keys`` now defaults to ``True``.\n",
      " |\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |              The default value will change to True in a future version of pandas.\n",
      " |\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.SeriesGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more\n",
      " |      detailed usage and examples, including splitting an object into groups,\n",
      " |      iterating through groups, selecting a group, aggregation, and more.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.],\n",
      " |      ...                 index=['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...                 name=\"Max Speed\")\n",
      " |      >>> ser\n",
      " |      Falcon    390.0\n",
      " |      Falcon    350.0\n",
      " |      Parrot     30.0\n",
      " |      Parrot     20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", \"b\"]).mean()\n",
      " |      a    210.0\n",
      " |      b    185.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=0).mean()\n",
      " |      Falcon    370.0\n",
      " |      Parrot     25.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(ser > 100).mean()\n",
      " |      Max Speed\n",
      " |      False     25.0\n",
      " |      True     370.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |\n",
      " |      **Grouping by Indexes**\n",
      " |\n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |\n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.], index=index, name=\"Max Speed\")\n",
      " |      >>> ser\n",
      " |      Animal  Type\n",
      " |      Falcon  Captive    390.0\n",
      " |              Wild       350.0\n",
      " |      Parrot  Captive     30.0\n",
      " |              Wild        20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=0).mean()\n",
      " |      Animal\n",
      " |      Falcon    370.0\n",
      " |      Parrot     25.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=\"Type\").mean()\n",
      " |      Type\n",
      " |      Captive    210.0\n",
      " |      Wild       185.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |\n",
      " |      We can also choose to include `NA` in group keys or not by defining\n",
      " |      `dropna` parameter, the default setting is `True`.\n",
      " |\n",
      " |      >>> ser = pd.Series([1, 2, 3, 3], index=[\"a\", 'a', 'b', np.nan])\n",
      " |      >>> ser.groupby(level=0).sum()\n",
      " |      a    3\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> ser.groupby(level=0, dropna=False).sum()\n",
      " |      a    3\n",
      " |      b    3\n",
      " |      NaN  3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> arrays = ['Falcon', 'Falcon', 'Parrot', 'Parrot']\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.], index=arrays, name=\"Max Speed\")\n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", np.nan]).mean()\n",
      " |      a    210.0\n",
      " |      b    350.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |\n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", np.nan], dropna=False).mean()\n",
      " |      a    210.0\n",
      " |      b    350.0\n",
      " |      NaN   20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |\n",
      " |  gt(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |\n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.gt(b, fill_value=0)\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      c    False\n",
      " |      d    False\n",
      " |      e     True\n",
      " |      f    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  hist = hist_series(self: 'Series', by=None, ax=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, figsize: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs) from pandas.plotting._core\n",
      " |      Draw histogram of the input series using matplotlib.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca().\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels.\n",
      " |      figsize : tuple, default None\n",
      " |          Figure size in inches by default.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |\n",
      " |      **kwargs\n",
      " |          To be passed to the actual plotting function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot\n",
      " |          A histogram plot.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |          >>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n",
      " |          >>> hist = ser.hist()\n",
      " |\n",
      " |      For Groupby:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']\n",
      " |          >>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n",
      " |          >>> hist = ser.groupby(level=0).hist()\n",
      " |\n",
      " |  idxmax(self, axis: 'Axis' = 0, skipna: 'bool' = True, *args, **kwargs) -> 'Hashable'\n",
      " |      Return the row label of the maximum value.\n",
      " |\n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the maximum value.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |\n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |\n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |\n",
      " |  idxmin(self, axis: 'Axis' = 0, skipna: 'bool' = True, *args, **kwargs) -> 'Hashable'\n",
      " |      Return the row label of the minimum value.\n",
      " |\n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the minimum value.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A', 'B', 'C', 'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |\n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |\n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |\n",
      " |  info(self, verbose: 'bool | None' = None, buf: 'IO[str] | None' = None, max_cols: 'int | None' = None, memory_usage: 'bool | str | None' = None, show_counts: 'bool' = True) -> 'None'\n",
      " |      Print a concise summary of a Series.\n",
      " |\n",
      " |      This method prints information about a Series including\n",
      " |      the index dtype, non-null values and memory usage.\n",
      " |\n",
      " |      .. versionadded:: 1.4.0\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the Series\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |\n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources. See the\n",
      " |          :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |          details.\n",
      " |      show_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a Series and returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.describe: Generate descriptive statistics of Series.\n",
      " |      Series.memory_usage: Memory usage of Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> s = pd.Series(text_values, index=int_values)\n",
      " |      >>> s.info()\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      Index: 5 entries, 1 to 5\n",
      " |      Series name: None\n",
      " |      Non-Null Count  Dtype\n",
      " |      --------------  -----\n",
      " |      5 non-null      object\n",
      " |      dtypes: object(1)\n",
      " |      memory usage: 80.0+ bytes\n",
      " |\n",
      " |      Prints a summary excluding information about its values:\n",
      " |\n",
      " |      >>> s.info(verbose=False)\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      Index: 5 entries, 1 to 5\n",
      " |      dtypes: object(1)\n",
      " |      memory usage: 80.0+ bytes\n",
      " |\n",
      " |      Pipe output of Series.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |\n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> s.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\",\n",
      " |      ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |\n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big Series and fine-tune memory optimization:\n",
      " |\n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> s = pd.Series(np.random.choice(['a', 'b', 'c'], 10 ** 6))\n",
      " |      >>> s.info()\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Series name: None\n",
      " |      Non-Null Count    Dtype\n",
      " |      --------------    -----\n",
      " |      1000000 non-null  object\n",
      " |      dtypes: object(1)\n",
      " |      memory usage: 7.6+ MB\n",
      " |\n",
      " |      >>> s.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Series name: None\n",
      " |      Non-Null Count    Dtype\n",
      " |      --------------    -----\n",
      " |      1000000 non-null  object\n",
      " |      dtypes: object(1)\n",
      " |      memory usage: 55.3 MB\n",
      " |\n",
      " |  isin(self, values) -> 'Series'\n",
      " |      Whether elements in Series are contained in `values`.\n",
      " |\n",
      " |      Return a boolean Series showing whether each element in the Series\n",
      " |      matches an element in the passed sequence of `values` exactly.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          list of one element.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series of booleans indicating if each element is in values.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If `values` is a string\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isin : Equivalent method on DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama',\n",
      " |      ...                'hippo'], name='animal')\n",
      " |      >>> s.isin(['cow', 'llama'])\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |\n",
      " |      To invert the boolean values, use the ``~`` operator:\n",
      " |\n",
      " |      >>> ~s.isin(['cow', 'llama'])\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4    False\n",
      " |      5     True\n",
      " |      Name: animal, dtype: bool\n",
      " |\n",
      " |      Passing a single string as ``s.isin('llama')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |\n",
      " |      >>> s.isin(['llama'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |\n",
      " |      Strings and integers are distinct and are therefore not comparable:\n",
      " |\n",
      " |      >>> pd.Series([1]).isin(['1'])\n",
      " |      0    False\n",
      " |      dtype: bool\n",
      " |      >>> pd.Series([1.1]).isin(['1.1'])\n",
      " |      0    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  isna(self) -> 'Series'\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : Alias of isna.\n",
      " |      Series.notna : Boolean inverse of isna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |\n",
      " |      Show which entries in a Series are NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  isnull(self) -> 'Series'\n",
      " |      Series.isnull is an alias for Series.isna.\n",
      " |\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : Alias of isna.\n",
      " |      Series.notna : Boolean inverse of isna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |\n",
      " |      Show which entries in a Series are NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Any]]'\n",
      " |      Lazily iterate over (index, value) tuples.\n",
      " |\n",
      " |      This method returns an iterable tuple (index, value). This is\n",
      " |      convenient if you want to create a lazy iterator.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable\n",
      " |          Iterable of tuples containing the (index, value) pairs from a\n",
      " |          Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['A', 'B', 'C'])\n",
      " |      >>> for index, value in s.items():\n",
      " |      ...     print(f\"Index : {index}, Value : {value}\")\n",
      " |      Index : 0, Value : A\n",
      " |      Index : 1, Value : B\n",
      " |      Index : 2, Value : C\n",
      " |\n",
      " |  keys(self) -> 'Index'\n",
      " |      Return alias for index.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of the Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
      " |      >>> s.keys()\n",
      " |      Index([0, 1, 2], dtype='int64')\n",
      " |\n",
      " |  kurt(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |\n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n",
      " |                  >>> s\n",
      " |                  cat    1\n",
      " |                  dog    2\n",
      " |                  dog    2\n",
      " |                  mouse  3\n",
      " |                  dtype: int64\n",
      " |                  >>> s.kurt()\n",
      " |                  1.5\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},\n",
      " |                  ...                   index=['cat', 'dog', 'dog', 'mouse'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                    cat  1   3\n",
      " |                    dog  2   4\n",
      " |                    dog  2   4\n",
      " |                  mouse  3   4\n",
      " |                  >>> df.kurt()\n",
      " |                  a   1.5\n",
      " |                  b   4.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  With axis=None\n",
      " |\n",
      " |                  >>> df.kurt(axis=None).round(6)\n",
      " |                  -0.988693\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},\n",
      " |                  ...                   index=['cat', 'dog'])\n",
      " |                  >>> df.kurt(axis=1)\n",
      " |                  cat   -6.0\n",
      " |                  dog   -6.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  kurtosis = kurt(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |\n",
      " |  le(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |\n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.le(b, fill_value=0)\n",
      " |      a    False\n",
      " |      b     True\n",
      " |      c     True\n",
      " |      d    False\n",
      " |      e    False\n",
      " |      f     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  lt(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Less than of series and other, element-wise (binary operator `lt`).\n",
      " |\n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.lt(b, fill_value=0)\n",
      " |      a    False\n",
      " |      b    False\n",
      " |      c     True\n",
      " |      d    False\n",
      " |      e    False\n",
      " |      f     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  map(self, arg: 'Callable | Mapping | Series', na_action: \"Literal['ignore'] | None\" = None) -> 'Series'\n",
      " |      Map values of Series according to an input mapping or function.\n",
      " |\n",
      " |      Used for substituting each value in a Series with another value,\n",
      " |      that may be derived from a function, a ``dict`` or\n",
      " |      a :class:`Series`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, collections.abc.Mapping subclass or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Same index as caller.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : For applying more complex functions on a Series.\n",
      " |      Series.replace: Replace values given in `to_replace` with `value`.\n",
      " |      DataFrame.apply : Apply a function row-/column-wise.\n",
      " |      DataFrame.map : Apply a function elementwise on a whole DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``arg`` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
      " |      >>> s\n",
      " |      0      cat\n",
      " |      1      dog\n",
      " |      2      NaN\n",
      " |      3   rabbit\n",
      " |      dtype: object\n",
      " |\n",
      " |      ``map`` accepts a ``dict`` or a ``Series``. Values that are not found\n",
      " |      in the ``dict`` are converted to ``NaN``, unless the dict has a default\n",
      " |      value (e.g. ``defaultdict``):\n",
      " |\n",
      " |      >>> s.map({'cat': 'kitten', 'dog': 'puppy'})\n",
      " |      0   kitten\n",
      " |      1    puppy\n",
      " |      2      NaN\n",
      " |      3      NaN\n",
      " |      dtype: object\n",
      " |\n",
      " |      It also accepts a function:\n",
      " |\n",
      " |      >>> s.map('I am a {}'.format)\n",
      " |      0       I am a cat\n",
      " |      1       I am a dog\n",
      " |      2       I am a nan\n",
      " |      3    I am a rabbit\n",
      " |      dtype: object\n",
      " |\n",
      " |      To avoid applying the function to missing values (and keep them as\n",
      " |      ``NaN``) ``na_action='ignore'`` can be used:\n",
      " |\n",
      " |      >>> s.map('I am a {}'.format, na_action='ignore')\n",
      " |      0     I am a cat\n",
      " |      1     I am a dog\n",
      " |      2            NaN\n",
      " |      3  I am a rabbit\n",
      " |      dtype: object\n",
      " |\n",
      " |  max(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |\n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |\n",
      " |  mean(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.mean()\n",
      " |                  2.0\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                  tiger  1   2\n",
      " |                  zebra  2   3\n",
      " |                  >>> df.mean()\n",
      " |                  a   1.5\n",
      " |                  b   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.mean(axis=1)\n",
      " |                  tiger   1.5\n",
      " |                  zebra   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True` to avoid\n",
      " |                  getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
      " |                  ...                   index=['tiger', 'zebra'])\n",
      " |                  >>> df.mean(numeric_only=True)\n",
      " |                  a   1.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  median(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.median()\n",
      " |                  2.0\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                  tiger  1   2\n",
      " |                  zebra  2   3\n",
      " |                  >>> df.median()\n",
      " |                  a   1.5\n",
      " |                  b   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.median(axis=1)\n",
      " |                  tiger   1.5\n",
      " |                  zebra   2.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True`\n",
      " |                  to avoid getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
      " |                  ...                   index=['tiger', 'zebra'])\n",
      " |                  >>> df.median(numeric_only=True)\n",
      " |                  a   1.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'int'\n",
      " |      Return the memory usage of the Series.\n",
      " |\n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and of elements of `object` dtype.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the Series index.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned value.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Bytes of memory consumed.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n",
      " |          array.\n",
      " |      DataFrame.memory_usage : Bytes consumed by a DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s.memory_usage()\n",
      " |      152\n",
      " |\n",
      " |      Not including the index gives the size of the rest of the data, which\n",
      " |      is necessarily smaller:\n",
      " |\n",
      " |      >>> s.memory_usage(index=False)\n",
      " |      24\n",
      " |\n",
      " |      The memory footprint of `object` values is ignored by default:\n",
      " |\n",
      " |      >>> s = pd.Series([\"a\", \"b\"])\n",
      " |      >>> s.values\n",
      " |      array(['a', 'b'], dtype=object)\n",
      " |      >>> s.memory_usage()\n",
      " |      144\n",
      " |      >>> s.memory_usage(deep=True)\n",
      " |      244\n",
      " |\n",
      " |  min(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |\n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |\n",
      " |  mod(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |\n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rmod : Reverse of the Modulo operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.mod(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  mode(self, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return the mode(s) of the Series.\n",
      " |\n",
      " |      The mode is the value that appears most often. There can be multiple modes.\n",
      " |\n",
      " |      Always returns Series even if only one value is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Modes of the Series in sorted order.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 4, 2, 2, 4, None])\n",
      " |      >>> s.mode()\n",
      " |      0    2.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      More than one mode:\n",
      " |\n",
      " |      >>> s = pd.Series([2, 4, 8, 2, 4, None])\n",
      " |      >>> s.mode()\n",
      " |      0    2.0\n",
      " |      1    4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      With and without considering null value:\n",
      " |\n",
      " |      >>> s = pd.Series([2, 4, None, None, 4, None])\n",
      " |      >>> s.mode(dropna=False)\n",
      " |      0   NaN\n",
      " |      dtype: float64\n",
      " |      >>> s = pd.Series([2, 4, None, None, 4, None])\n",
      " |      >>> s.mode()\n",
      " |      0    4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  mul(self, other, level: 'Level | None' = None, fill_value: 'float | None' = None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |\n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rmul : Reverse of the Multiplication operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.multiply(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    0.0\n",
      " |      c    0.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  multiply = mul(self, other, level: 'Level | None' = None, fill_value: 'float | None' = None, axis: 'Axis' = 0) -> 'Series'\n",
      " |\n",
      " |  ne(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |\n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.ne(b, fill_value=0)\n",
      " |      a    False\n",
      " |      b     True\n",
      " |      c     True\n",
      " |      d     True\n",
      " |      e     True\n",
      " |      dtype: bool\n",
      " |\n",
      " |  nlargest(self, n: 'int' = 5, keep: \"Literal['first', 'last', 'all']\" = 'first') -> 'Series'\n",
      " |      Return the largest `n` elements.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many descending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |\n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |            of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |            order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |            size larger than `n`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` largest values in the Series, sorted in decreasing order.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest: Get the `n` smallest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Malta\": 434000, \"Maldives\": 434000,\n",
      " |      ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Montserrat      5200\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` largest elements where ``n=5`` by default.\n",
      " |\n",
      " |      >>> s.nlargest()\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n",
      " |      so Malta will be kept.\n",
      " |\n",
      " |      >>> s.nlargest(3)\n",
      " |      France    65000000\n",
      " |      Italy     59000000\n",
      " |      Malta       434000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` largest elements where ``n=3`` and keeping the last duplicates.\n",
      " |      Brunei will be kept since it is the last with value 434000 based on\n",
      " |      the index order.\n",
      " |\n",
      " |      >>> s.nlargest(3, keep='last')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` largest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has five elements due to the three duplicates.\n",
      " |\n",
      " |      >>> s.nlargest(3, keep='all')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |\n",
      " |  notna(self) -> 'Series'\n",
      " |      Detect existing (non-missing) values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : Alias of notna.\n",
      " |      Series.isna : Boolean inverse of notna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |\n",
      " |      Show which entries in a Series are not NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  notnull(self) -> 'Series'\n",
      " |      Series.notnull is an alias for Series.notna.\n",
      " |\n",
      " |      Detect existing (non-missing) values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : Alias of notna.\n",
      " |      Series.isna : Boolean inverse of notna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.nan],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |\n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |\n",
      " |      Show which entries in a Series are not NA.\n",
      " |\n",
      " |      >>> ser = pd.Series([5, 6, np.nan])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |\n",
      " |  nsmallest(self, n: 'int' = 5, keep: \"Literal['first', 'last', 'all']\" = 'first') -> 'Series'\n",
      " |      Return the smallest `n` elements.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many ascending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |\n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |            of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |            order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |            size larger than `n`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` smallest values in the Series, sorted in increasing order.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest: Get the `n` largest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Brunei\": 434000, \"Malta\": 434000,\n",
      " |      ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Brunei        434000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Montserrat      5200\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` smallest elements where ``n=5`` by default.\n",
      " |\n",
      " |      >>> s.nsmallest()\n",
      " |      Montserrat    5200\n",
      " |      Nauru        11300\n",
      " |      Tuvalu       11300\n",
      " |      Anguilla     11300\n",
      " |      Iceland     337000\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` smallest elements where ``n=3``. Default `keep` value is\n",
      " |      'first' so Nauru and Tuvalu will be kept.\n",
      " |\n",
      " |      >>> s.nsmallest(3)\n",
      " |      Montserrat   5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` smallest elements where ``n=3`` and keeping the last\n",
      " |      duplicates. Anguilla and Tuvalu will be kept since they are the last\n",
      " |      with value 11300 based on the index order.\n",
      " |\n",
      " |      >>> s.nsmallest(3, keep='last')\n",
      " |      Montserrat   5200\n",
      " |      Anguilla    11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |\n",
      " |      The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has four elements due to the three duplicates.\n",
      " |\n",
      " |      >>> s.nsmallest(3, keep='all')\n",
      " |      Montserrat   5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      Anguilla    11300\n",
      " |      dtype: int64\n",
      " |\n",
      " |  pop(self, item: 'Hashable') -> 'Any'\n",
      " |      Return item and drops from series. Raise KeyError if not found.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Index of the element that needs to be removed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Value that is popped from series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |\n",
      " |      >>> ser.pop(0)\n",
      " |      1\n",
      " |\n",
      " |      >>> ser\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |  pow(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |\n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rpow : Reverse of the Exponential power operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.pow(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  prod(self, axis: 'Axis | None' = None, skipna: 'bool' = True, numeric_only: 'bool' = False, min_count: 'int' = 0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.prod with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |\n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |  product = prod(self, axis: 'Axis | None' = None, skipna: 'bool' = True, numeric_only: 'bool' = False, min_count: 'int' = 0, **kwargs)\n",
      " |\n",
      " |  quantile(self, q: 'float | Sequence[float] | AnyArrayLike' = 0.5, interpolation: 'QuantileInterpolation' = 'linear') -> 'float | Series'\n",
      " |      Return value at the given quantile.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |\n",
      " |              * linear: `i + (j - i) * (x-i)/(j-i)`, where `(x-i)/(j-i)` is\n",
      " |                the fractional part of the index surrounded by `i > j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      float or Series\n",
      " |          If ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles, otherwise\n",
      " |          a float will be returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile : Calculate the rolling quantile.\n",
      " |      numpy.percentile : Returns the q-th percentile(s) of the array elements.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |\n",
      " |  radd(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Addition of series and other, element-wise (binary operator `radd`).\n",
      " |\n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add : Element-wise Addition, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  ravel(self, order: 'str' = 'C') -> 'ArrayLike'\n",
      " |      Return the flattened underlying data as an ndarray or ExtensionArray.\n",
      " |\n",
      " |      .. deprecated:: 2.2.0\n",
      " |          Series.ravel is deprecated. The underlying array is already 1D, so\n",
      " |          ravel is not necessary.  Use :meth:`to_numpy` for conversion to a numpy\n",
      " |          array instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray or ExtensionArray\n",
      " |          Flattened data of the Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel : Return a flattened array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.ravel()  # doctest: +SKIP\n",
      " |      array([1, 2, 3])\n",
      " |\n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |\n",
      " |  rdivmod(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Integer division and modulo of series and other, element-wise (binary operator `rdivmod`).\n",
      " |\n",
      " |      Equivalent to ``other divmod series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      2-Tuple of Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.divmod : Element-wise Integer division and modulo, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divmod(b, fill_value=0)\n",
      " |      (a    1.0\n",
      " |       b    inf\n",
      " |       c    inf\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64,\n",
      " |       a    0.0\n",
      " |       b    NaN\n",
      " |       c    NaN\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64)\n",
      " |\n",
      " |  reindex(self, index=None, *, axis: 'Axis | None' = None, method: 'ReindexMethod | None' = None, copy: 'bool | None' = None, level: 'Level | None' = None, fill_value: 'Scalar | None' = None, limit: 'int | None' = None, tolerance=None) -> 'Series'\n",
      " |      Conform Series to new index with optional filling logic.\n",
      " |\n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |\n",
      " |      index : array-like, optional\n",
      " |          New labels for the index. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      axis : int or str, optional\n",
      " |          Unused.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |\n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.nan\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series with changed index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |\n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |\n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |\n",
      " |      Create a dataframe with some fictional data.\n",
      " |\n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |\n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |\n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |\n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |\n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |\n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |\n",
      " |      We can also reindex the columns.\n",
      " |\n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |\n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |\n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |\n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |\n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |\n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |\n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |\n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |\n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |\n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |\n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |\n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |\n",
      " |  rename(self, index: 'Renamer | Hashable | None' = None, *, axis: 'Axis | None' = None, copy: 'bool | None' = None, inplace: 'bool' = False, level: 'Level | None' = None, errors: 'IgnoreRaise' = 'ignore') -> 'Series | None'\n",
      " |      Alter Series index labels or name.\n",
      " |\n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |\n",
      " |      Alternatively, change ``Series.name`` with a scalar value.\n",
      " |\n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : scalar, hashable sequence, dict-like or function optional\n",
      " |          Functions or dict-like are transformations to apply to\n",
      " |          the index.\n",
      " |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      " |          attribute.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new Series. If True the value of copy is ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of MultiIndex, only rename labels in the specified level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise `KeyError` when a `dict-like mapper` or\n",
      " |          `index` contains labels that are not present in the index being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be ignored.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with index labels or name altered or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename : Corresponding DataFrame method.\n",
      " |      Series.rename_axis : Set the name of the axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\")  # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |  rename_axis(self, mapper: 'IndexLabel | lib.NoDefault' = <no_default>, *, index=<no_default>, axis: 'Axis' = 0, copy: 'bool' = True, inplace: 'bool' = False) -> 'Self | None'\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |\n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename. For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default None\n",
      " |          Also copy underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |\n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |\n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |\n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |\n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |\n",
      " |      **MultiIndex**\n",
      " |\n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |\n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |\n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |\n",
      " |  reorder_levels(self, order: 'Sequence[Level]') -> 'Series'\n",
      " |      Rearrange index levels using input order.\n",
      " |\n",
      " |      May not drop or duplicate levels.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order\n",
      " |          Reference level by number or key.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> arrays = [np.array([\"dog\", \"dog\", \"cat\", \"cat\", \"bird\", \"bird\"]),\n",
      " |      ...           np.array([\"white\", \"black\", \"white\", \"black\", \"white\", \"black\"])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 3, 5, 2], index=arrays)\n",
      " |      >>> s\n",
      " |      dog   white    1\n",
      " |            black    2\n",
      " |      cat   white    3\n",
      " |            black    3\n",
      " |      bird  white    5\n",
      " |            black    2\n",
      " |      dtype: int64\n",
      " |      >>> s.reorder_levels([1, 0])\n",
      " |      white  dog     1\n",
      " |      black  dog     2\n",
      " |      white  cat     3\n",
      " |      black  cat     3\n",
      " |      white  bird    5\n",
      " |      black  bird    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |  repeat(self, repeats: 'int | Sequence[int]', axis: 'None' = None) -> 'Series'\n",
      " |      Repeat elements of a Series.\n",
      " |\n",
      " |      Returns a new Series where each element of the current Series\n",
      " |      is repeated consecutively a given number of times.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      repeats : int or array of ints\n",
      " |          The number of repetitions for each element. This should be a\n",
      " |          non-negative integer. Repeating 0 times will return an empty\n",
      " |          Series.\n",
      " |      axis : None\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Newly created Series with repeated elements.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.repeat : Equivalent function for Index.\n",
      " |      numpy.repeat : Similar method for :class:`numpy.ndarray`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |      >>> s.repeat(2)\n",
      " |      0    a\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |      >>> s.repeat([1, 2, 3])\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |\n",
      " |  reset_index(self, level: 'IndexLabel | None' = None, *, drop: 'bool' = False, name: 'Level' = <no_default>, inplace: 'bool' = False, allow_duplicates: 'bool' = False) -> 'DataFrame | Series | None'\n",
      " |      Generate a new DataFrame or Series with the index reset.\n",
      " |\n",
      " |      This is useful when the index needs to be treated as a column, or\n",
      " |      when the index is meaningless and needs to be reset to the default\n",
      " |      before another operation.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default optional\n",
      " |          For a Series with a MultiIndex, only remove the specified levels\n",
      " |          from the index. Removes all levels by default.\n",
      " |      drop : bool, default False\n",
      " |          Just reset the index, without inserting it as a column in\n",
      " |          the new DataFrame.\n",
      " |      name : object, optional\n",
      " |          The name to use for the column containing the original Series\n",
      " |          values. Uses ``self.name`` by default. This argument is ignored\n",
      " |          when `drop` is True.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the Series in place (do not create a new object).\n",
      " |      allow_duplicates : bool, default False\n",
      " |          Allow duplicate column labels to be created.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          When `drop` is False (the default), a DataFrame is returned.\n",
      " |          The newly created columns will come first in the DataFrame,\n",
      " |          followed by the original Series values.\n",
      " |          When `drop` is True, a `Series` is returned.\n",
      " |          In either case, if ``inplace=True``, no value is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index: Analogous function for DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4], name='foo',\n",
      " |      ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
      " |\n",
      " |      Generate a DataFrame with default index.\n",
      " |\n",
      " |      >>> s.reset_index()\n",
      " |        idx  foo\n",
      " |      0   a    1\n",
      " |      1   b    2\n",
      " |      2   c    3\n",
      " |      3   d    4\n",
      " |\n",
      " |      To specify the name of the new column use `name`.\n",
      " |\n",
      " |      >>> s.reset_index(name='values')\n",
      " |        idx  values\n",
      " |      0   a       1\n",
      " |      1   b       2\n",
      " |      2   c       3\n",
      " |      3   d       4\n",
      " |\n",
      " |      To generate a new Series with the default set `drop` to True.\n",
      " |\n",
      " |      >>> s.reset_index(drop=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |\n",
      " |      The `level` parameter is interesting for Series with a multi-level\n",
      " |      index.\n",
      " |\n",
      " |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
      " |      ...           np.array(['one', 'two', 'one', 'two'])]\n",
      " |      >>> s2 = pd.Series(\n",
      " |      ...     range(4), name='foo',\n",
      " |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      " |      ...                                     names=['a', 'b']))\n",
      " |\n",
      " |      To remove a specific level from the Index, use `level`.\n",
      " |\n",
      " |      >>> s2.reset_index(level='a')\n",
      " |             a  foo\n",
      " |      b\n",
      " |      one  bar    0\n",
      " |      two  bar    1\n",
      " |      one  baz    2\n",
      " |      two  baz    3\n",
      " |\n",
      " |      If `level` is not set, all levels are removed from the Index.\n",
      " |\n",
      " |      >>> s2.reset_index()\n",
      " |           a    b  foo\n",
      " |      0  bar  one    0\n",
      " |      1  bar  two    1\n",
      " |      2  baz  one    2\n",
      " |      3  baz  two    3\n",
      " |\n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |\n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.floordiv : Element-wise Integer division, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.floordiv(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  rmod(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |\n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mod : Element-wise Modulo, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.mod(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  rmul(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |\n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mul : Element-wise Multiplication, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.multiply(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    0.0\n",
      " |      c    0.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  round(self, decimals: 'int' = 0, *args, **kwargs) -> 'Series'\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, default 0\n",
      " |          Number of decimal places to round to. If decimals is negative,\n",
      " |          it specifies the number of positions to the left of the decimal point.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Rounded values of the Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round values of an np.array.\n",
      " |      DataFrame.round : Round values of a DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.1, 1.3, 2.7])\n",
      " |      >>> s.round()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  rpow(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |\n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pow : Element-wise Exponential power, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.pow(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  rsub(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |\n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sub : Element-wise Subtraction, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.subtract(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d   -1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |\n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.truediv : Element-wise Floating division, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divide(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  searchsorted(self, value: 'NumpyValueArrayLike | ExtensionArray', side: \"Literal['left', 'right']\" = 'left', sorter: 'NumpySorter | None' = None) -> 'npt.NDArray[np.intp] | np.intp'\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |\n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |\n",
      " |      .. note::\n",
      " |\n",
      " |          The Series *must* be monotonically sorted, otherwise\n",
      " |          wrong locations will likely be returned. Pandas does *not*\n",
      " |          check this for you.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array-like or scalar\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array-like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or array of int\n",
      " |          A scalar or array of insertion points with the\n",
      " |          same shape as `value`.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      sort_values : Sort by the values along either axis.\n",
      " |      numpy.searchsorted : Similar method from NumPy.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> ser.searchsorted(4)\n",
      " |      3\n",
      " |\n",
      " |      >>> ser.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |\n",
      " |      >>> ser.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |\n",
      " |      >>> ser.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |\n",
      " |      >>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))\n",
      " |      >>> ser\n",
      " |      0   2000-03-11\n",
      " |      1   2000-03-12\n",
      " |      2   2000-03-13\n",
      " |      dtype: datetime64[ns]\n",
      " |\n",
      " |      >>> ser.searchsorted('3/14/2000')\n",
      " |      3\n",
      " |\n",
      " |      >>> ser = pd.Categorical(\n",
      " |      ...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True\n",
      " |      ... )\n",
      " |      >>> ser\n",
      " |      ['apple', 'bread', 'bread', 'cheese', 'milk']\n",
      " |      Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']\n",
      " |\n",
      " |      >>> ser.searchsorted('bread')\n",
      " |      1\n",
      " |\n",
      " |      >>> ser.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |\n",
      " |      If the values are not monotonically sorted, wrong locations\n",
      " |      may be returned:\n",
      " |\n",
      " |      >>> ser = pd.Series([2, 1, 3])\n",
      " |      >>> ser\n",
      " |      0    2\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> ser.searchsorted(1)  # doctest: +SKIP\n",
      " |      0  # wrong result, correct would be 1\n",
      " |\n",
      " |  sem(self, axis: 'Axis | None' = None, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |\n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.sem with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.sem().round(6)\n",
      " |                  0.57735\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                  tiger  1   2\n",
      " |                  zebra  2   3\n",
      " |                  >>> df.sem()\n",
      " |                  a   0.5\n",
      " |                  b   0.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.sem(axis=1)\n",
      " |                  tiger   0.5\n",
      " |                  zebra   0.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True`\n",
      " |                  to avoid getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
      " |                  ...                   index=['tiger', 'zebra'])\n",
      " |                  >>> df.sem(numeric_only=True)\n",
      " |                  a   0.5\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  set_axis(self, labels, *, axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'Series'\n",
      " |      Assign desired index to given axis.\n",
      " |\n",
      " |      Indexes for row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy of the underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          An object of type Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename_axis : Alter the name of the index.\n",
      " |\n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> s = pd.Series([1, 2, 3])\n",
      " |              >>> s\n",
      " |              0    1\n",
      " |              1    2\n",
      " |              2    3\n",
      " |              dtype: int64\n",
      " |\n",
      " |              >>> s.set_axis(['a', 'b', 'c'], axis=0)\n",
      " |              a    1\n",
      " |              b    2\n",
      " |              c    3\n",
      " |              dtype: int64\n",
      " |\n",
      " |  skew(self, axis: 'Axis | None' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |\n",
      " |      Normalized by N-1.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 3])\n",
      " |                  >>> s.skew()\n",
      " |                  0.0\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [1, 3, 5]},\n",
      " |                  ...                   index=['tiger', 'zebra', 'cow'])\n",
      " |                  >>> df\n",
      " |                          a   b   c\n",
      " |                  tiger   1   2   1\n",
      " |                  zebra   2   3   3\n",
      " |                  cow     3   4   5\n",
      " |                  >>> df.skew()\n",
      " |                  a   0.0\n",
      " |                  b   0.0\n",
      " |                  c   0.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df.skew(axis=1)\n",
      " |                  tiger   1.732051\n",
      " |                  zebra  -1.732051\n",
      " |                  cow     0.000000\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  In this case, `numeric_only` should be set to `True` to avoid\n",
      " |                  getting an error.\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 3], 'b': ['T', 'Z', 'X']},\n",
      " |                  ...                   index=['tiger', 'zebra', 'cow'])\n",
      " |                  >>> df.skew(numeric_only=True)\n",
      " |                  a   0.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |  sort_index(self, *, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, ascending: 'bool | Sequence[bool]' = True, inplace: 'bool' = False, kind: 'SortKind' = 'quicksort', na_position: 'NaPosition' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc | None' = None) -> 'Series | None'\n",
      " |      Sort Series by index labels.\n",
      " |\n",
      " |      Returns a new Series sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original series and returns None.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      level : int, optional\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' and 'stable' are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, â€¦, n - 1.\n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          The original Series sorted by the labels or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index: Sort DataFrame by the index.\n",
      " |      DataFrame.sort_values: Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n",
      " |      >>> s.sort_index()\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |\n",
      " |      Sort Descending\n",
      " |\n",
      " |      >>> s.sort_index(ascending=False)\n",
      " |      4    d\n",
      " |      3    a\n",
      " |      2    b\n",
      " |      1    c\n",
      " |      dtype: object\n",
      " |\n",
      " |      By default NaNs are put at the end, but use `na_position` to place\n",
      " |      them at the beginning\n",
      " |\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n",
      " |      >>> s.sort_index(na_position='first')\n",
      " |      NaN     d\n",
      " |       1.0    c\n",
      " |       2.0    b\n",
      " |       3.0    a\n",
      " |      dtype: object\n",
      " |\n",
      " |      Specify index level to sort\n",
      " |\n",
      " |      >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n",
      " |      ...                     'baz', 'baz', 'bar', 'bar']),\n",
      " |      ...           np.array(['two', 'one', 'two', 'one',\n",
      " |      ...                     'two', 'one', 'two', 'one'])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n",
      " |      >>> s.sort_index(level=1)\n",
      " |      bar  one    8\n",
      " |      baz  one    6\n",
      " |      foo  one    4\n",
      " |      qux  one    2\n",
      " |      bar  two    7\n",
      " |      baz  two    5\n",
      " |      foo  two    3\n",
      " |      qux  two    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Does not sort by remaining levels when sorting by levels\n",
      " |\n",
      " |      >>> s.sort_index(level=1, sort_remaining=False)\n",
      " |      qux  one    2\n",
      " |      foo  one    4\n",
      " |      baz  one    6\n",
      " |      bar  one    8\n",
      " |      qux  two    1\n",
      " |      foo  two    3\n",
      " |      baz  two    5\n",
      " |      bar  two    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Apply a key function before sorting\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 4], index=['A', 'b', 'C', 'd'])\n",
      " |      >>> s.sort_index(key=lambda x : x.str.lower())\n",
      " |      A    1\n",
      " |      b    2\n",
      " |      C    3\n",
      " |      d    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |  sort_values(self, *, axis: 'Axis' = 0, ascending: 'bool | Sequence[bool]' = True, inplace: 'bool' = False, kind: 'SortKind' = 'quicksort', na_position: 'NaPosition' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc | None' = None) -> 'Series | None'\n",
      " |      Sort by the values.\n",
      " |\n",
      " |      Sort a Series in ascending or descending order by some\n",
      " |      criterion.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      ascending : bool or list of bools, default True\n",
      " |          If True, sort values in ascending order, otherwise descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' and 'stable' are the only stable  algorithms.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, â€¦, n - 1.\n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the series values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return an array-like.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series ordered by values or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort by the Series indices.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values along either axis.\n",
      " |      DataFrame.sort_index : Sort DataFrame by indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n",
      " |      >>> s\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      3     10.0\n",
      " |      4     5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Sort values ascending order (default behaviour)\n",
      " |\n",
      " |      >>> s.sort_values(ascending=True)\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Sort values descending order\n",
      " |\n",
      " |      >>> s.sort_values(ascending=False)\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Sort values putting NAs first\n",
      " |\n",
      " |      >>> s.sort_values(na_position='first')\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Sort a series of strings\n",
      " |\n",
      " |      >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n",
      " |      >>> s\n",
      " |      0    z\n",
      " |      1    b\n",
      " |      2    d\n",
      " |      3    a\n",
      " |      4    c\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s.sort_values()\n",
      " |      3    a\n",
      " |      1    b\n",
      " |      4    c\n",
      " |      2    d\n",
      " |      0    z\n",
      " |      dtype: object\n",
      " |\n",
      " |      Sort using a key function. Your `key` function will be\n",
      " |      given the ``Series`` of values and should return an array-like.\n",
      " |\n",
      " |      >>> s = pd.Series(['a', 'B', 'c', 'D', 'e'])\n",
      " |      >>> s.sort_values()\n",
      " |      1    B\n",
      " |      3    D\n",
      " |      0    a\n",
      " |      2    c\n",
      " |      4    e\n",
      " |      dtype: object\n",
      " |      >>> s.sort_values(key=lambda x: x.str.lower())\n",
      " |      0    a\n",
      " |      1    B\n",
      " |      2    c\n",
      " |      3    D\n",
      " |      4    e\n",
      " |      dtype: object\n",
      " |\n",
      " |      NumPy ufuncs work well here. For example, we can\n",
      " |      sort by the ``sin`` of the value\n",
      " |\n",
      " |      >>> s = pd.Series([-4, -2, 0, 2, 4])\n",
      " |      >>> s.sort_values(key=np.sin)\n",
      " |      1   -2\n",
      " |      4    4\n",
      " |      2    0\n",
      " |      0   -4\n",
      " |      3    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      More complicated user-defined functions can be used,\n",
      " |      as long as they expect a Series and return an array-like\n",
      " |\n",
      " |      >>> s.sort_values(key=lambda x: (np.tan(x.cumsum())))\n",
      " |      0   -4\n",
      " |      3    2\n",
      " |      4    4\n",
      " |      1   -2\n",
      " |      2    0\n",
      " |      dtype: int64\n",
      " |\n",
      " |  std(self, axis: 'Axis | None' = None, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |\n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.std with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                    'age': [21, 25, 62, 43],\n",
      " |      ...                    'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                   ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |\n",
      " |      The standard deviation of the columns can be found as follows:\n",
      " |\n",
      " |      >>> df.std()\n",
      " |      age       18.786076\n",
      " |      height     0.237417\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Alternatively, `ddof=0` can be set to normalize by N instead of N-1:\n",
      " |\n",
      " |      >>> df.std(ddof=0)\n",
      " |      age       16.269219\n",
      " |      height     0.205609\n",
      " |      dtype: float64\n",
      " |\n",
      " |  sub(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |\n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rsub : Reverse of the Subtraction operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.subtract(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d   -1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |\n",
      " |  sum(self, axis: 'Axis | None' = None, skipna: 'bool' = True, numeric_only: 'bool' = False, min_count: 'int' = 0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |\n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.sum with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |\n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |  swaplevel(self, i: 'Level' = -2, j: 'Level' = -1, copy: 'bool | None' = None) -> 'Series'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |\n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      copy : bool, default True\n",
      " |                  Whether to copy underlying data.\n",
      " |\n",
      " |                  .. note::\n",
      " |                      The `copy` keyword will change behavior in pandas 3.0.\n",
      " |                      `Copy-on-Write\n",
      " |                      <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |                      will be enabled by default, which means that all methods with a\n",
      " |                      `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |                      ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |                      future version of pandas.\n",
      " |\n",
      " |                      You can already get the future behavior and improvements through\n",
      " |                      enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with levels swapped in MultiIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [\"A\", \"B\", \"A\", \"C\"],\n",
      " |      ...     index=[\n",
      " |      ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |      ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |      ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |      ...     ],\n",
      " |      ... )\n",
      " |      >>> s\n",
      " |      Final exam  History     January      A\n",
      " |                  Geography   February     B\n",
      " |      Coursework  History     March        A\n",
      " |                  Geography   April        C\n",
      " |      dtype: object\n",
      " |\n",
      " |      In the following example, we will swap the levels of the indices.\n",
      " |      Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |      in a similar manner. Note that column-wise is the default behaviour.\n",
      " |      By not supplying any arguments for i and j, we swap the last and second to\n",
      " |      last indices.\n",
      " |\n",
      " |      >>> s.swaplevel()\n",
      " |      Final exam  January     History         A\n",
      " |                  February    Geography       B\n",
      " |      Coursework  March       History         A\n",
      " |                  April       Geography       C\n",
      " |      dtype: object\n",
      " |\n",
      " |      By supplying one argument, we can choose which index to swap the last\n",
      " |      index with. We can for example swap the first index with the last one as\n",
      " |      follows.\n",
      " |\n",
      " |      >>> s.swaplevel(0)\n",
      " |      January     History     Final exam      A\n",
      " |      February    Geography   Final exam      B\n",
      " |      March       History     Coursework      A\n",
      " |      April       Geography   Coursework      C\n",
      " |      dtype: object\n",
      " |\n",
      " |      We can also define explicitly which indices we want to swap by supplying values\n",
      " |      for both i and j. Here, we for example swap the first and second indices.\n",
      " |\n",
      " |      >>> s.swaplevel(0, 1)\n",
      " |      History     Final exam  January         A\n",
      " |      Geography   Final exam  February        B\n",
      " |      History     Coursework  March           A\n",
      " |      Geography   Coursework  April           C\n",
      " |      dtype: object\n",
      " |\n",
      " |  to_dict(self, *, into: 'type[MutableMappingT] | MutableMappingT' = <class 'dict'>) -> 'MutableMappingT'\n",
      " |      Convert Series to {label -> value} dict or dict-like object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      into : class, default dict\n",
      " |          The collections.abc.MutableMapping subclass to use as the return\n",
      " |          object. Can be the actual class or an empty instance of the mapping\n",
      " |          type you want.  If you want a collections.defaultdict, you must\n",
      " |          pass it initialized.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      collections.abc.MutableMapping\n",
      " |          Key-value representation of Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_dict()\n",
      " |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> s.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> s.to_dict(into=dd)\n",
      " |      defaultdict(<class 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      " |\n",
      " |  to_frame(self, name: 'Hashable' = <no_default>) -> 'DataFrame'\n",
      " |      Convert Series to DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, optional\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame representation of Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"a\", \"b\", \"c\"],\n",
      " |      ...               name=\"vals\")\n",
      " |      >>> s.to_frame()\n",
      " |        vals\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    c\n",
      " |\n",
      " |  to_markdown(self, buf: 'IO[str] | None' = None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions | None' = None, **kwargs) -> 'str | None'\n",
      " |      Print Series in Markdown-friendly format.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Series in Markdown-friendly format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |\n",
      " |      Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([\"elk\", \"pig\", \"dog\", \"quetzal\"], name=\"animal\")\n",
      " |                  >>> print(s.to_markdown())\n",
      " |                  |    | animal   |\n",
      " |                  |---:|:---------|\n",
      " |                  |  0 | elk      |\n",
      " |                  |  1 | pig      |\n",
      " |                  |  2 | dog      |\n",
      " |                  |  3 | quetzal  |\n",
      " |\n",
      " |                  Output markdown with a tabulate option.\n",
      " |\n",
      " |                  >>> print(s.to_markdown(tablefmt=\"grid\"))\n",
      " |                  +----+----------+\n",
      " |                  |    | animal   |\n",
      " |                  +====+==========+\n",
      " |                  |  0 | elk      |\n",
      " |                  +----+----------+\n",
      " |                  |  1 | pig      |\n",
      " |                  +----+----------+\n",
      " |                  |  2 | dog      |\n",
      " |                  +----+----------+\n",
      " |                  |  3 | quetzal  |\n",
      " |                  +----+----------+\n",
      " |\n",
      " |  to_period(self, freq: 'str | None' = None, copy: 'bool | None' = None) -> 'Series'\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default None\n",
      " |          Frequency associated with the PeriodIndex.\n",
      " |      copy : bool, default True\n",
      " |          Whether or not to return a copy.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with index converted to PeriodIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.DatetimeIndex(['2023', '2024', '2025'])\n",
      " |      >>> s = pd.Series([1, 2, 3], index=idx)\n",
      " |      >>> s = s.to_period()\n",
      " |      >>> s\n",
      " |      2023    1\n",
      " |      2024    2\n",
      " |      2025    3\n",
      " |      Freq: Y-DEC, dtype: int64\n",
      " |\n",
      " |      Viewing the index\n",
      " |\n",
      " |      >>> s.index\n",
      " |      PeriodIndex(['2023', '2024', '2025'], dtype='period[Y-DEC]')\n",
      " |\n",
      " |  to_string(self, buf: 'FilePath | WriteBuffer[str] | None' = None, na_rep: 'str' = 'NaN', float_format: 'str | None' = None, header: 'bool' = True, index: 'bool' = True, length: 'bool' = False, dtype: 'bool' = False, name: 'bool' = False, max_rows: 'int | None' = None, min_rows: 'int | None' = None) -> 'str | None'\n",
      " |      Render a string representation of the Series.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          Buffer to write to.\n",
      " |      na_rep : str, optional\n",
      " |          String representation of NaN to use, default 'NaN'.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats, default None.\n",
      " |      header : bool, default True\n",
      " |          Add the Series header (index name).\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True.\n",
      " |      length : bool, default False\n",
      " |          Add the Series length.\n",
      " |      dtype : bool, default False\n",
      " |          Add the Series dtype.\n",
      " |      name : bool, default False\n",
      " |          Add the Series name if not None.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in a truncated repr (when number\n",
      " |          of rows is above `max_rows`).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          String representation of Series if ``buf=None``, otherwise None.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3]).to_string()\n",
      " |      >>> ser\n",
      " |      '0    1\\n1    2\\n2    3'\n",
      " |\n",
      " |  to_timestamp(self, freq: 'Frequency | None' = None, how: \"Literal['s', 'e', 'start', 'end']\" = 'start', copy: 'bool | None' = None) -> 'Series'\n",
      " |      Cast to DatetimeIndex of Timestamps, at *beginning* of period.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      copy : bool, default True\n",
      " |          Whether or not to return a copy.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series with DatetimeIndex\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.PeriodIndex(['2023', '2024', '2025'], freq='Y')\n",
      " |      >>> s1 = pd.Series([1, 2, 3], index=idx)\n",
      " |      >>> s1\n",
      " |      2023    1\n",
      " |      2024    2\n",
      " |      2025    3\n",
      " |      Freq: Y-DEC, dtype: int64\n",
      " |\n",
      " |      The resulting frequency of the Timestamps is `YearBegin`\n",
      " |\n",
      " |      >>> s1 = s1.to_timestamp()\n",
      " |      >>> s1\n",
      " |      2023-01-01    1\n",
      " |      2024-01-01    2\n",
      " |      2025-01-01    3\n",
      " |      Freq: YS-JAN, dtype: int64\n",
      " |\n",
      " |      Using `freq` which is the offset that the Timestamps will have\n",
      " |\n",
      " |      >>> s2 = pd.Series([1, 2, 3], index=idx)\n",
      " |      >>> s2 = s2.to_timestamp(freq='M')\n",
      " |      >>> s2\n",
      " |      2023-01-31    1\n",
      " |      2024-01-31    2\n",
      " |      2025-01-31    3\n",
      " |      Freq: YE-JAN, dtype: int64\n",
      " |\n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'DataFrame | Series'\n",
      " |      Call ``func`` on self producing a Series with the same axis shape as self.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |\n",
      " |          Accepted combinations are:\n",
      " |\n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index'}\n",
      " |              Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series that must have the same length as self.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned Series has a different length than self.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.agg : Only perform aggregating type operations.\n",
      " |      Series.apply : Invoke function on a Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |\n",
      " |      Even though the resulting Series must have the same length as the\n",
      " |      input Series, it is possible to provide several input functions:\n",
      " |\n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |\n",
      " |      You can call transform on a GroupBy object:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |\n",
      " |  truediv(self, other, level=None, fill_value=None, axis: 'Axis' = 0) -> 'Series'\n",
      " |      Return Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |\n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rtruediv : Reverse of the Floating division operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divide(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |  unique(self) -> 'ArrayLike'\n",
      " |      Return unique values of Series object.\n",
      " |\n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or ExtensionArray\n",
      " |          The unique values returned as a NumPy array. See Notes.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      unique : Top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : Return Index with unique values from an Index object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the unique values as a NumPy array. In case of an\n",
      " |      extension-array backed Series, a new\n",
      " |      :class:`~api.extensions.ExtensionArray` of that type with just\n",
      " |      the unique values is returned. This includes\n",
      " |\n",
      " |          * Categorical\n",
      " |          * Period\n",
      " |          * Datetime with Timezone\n",
      " |          * Datetime without Timezone\n",
      " |          * Timedelta\n",
      " |          * Interval\n",
      " |          * Sparse\n",
      " |          * IntegerNA\n",
      " |\n",
      " |      See Examples section.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |\n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      <DatetimeArray>\n",
      " |      ['2016-01-01 00:00:00']\n",
      " |      Length: 1, dtype: datetime64[ns]\n",
      " |\n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      <DatetimeArray>\n",
      " |      ['2016-01-01 00:00:00-05:00']\n",
      " |      Length: 1, dtype: datetime64[ns, US/Eastern]\n",
      " |\n",
      " |      An Categorical will return categories in the order of\n",
      " |      appearance and with the same dtype.\n",
      " |\n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      ['b', 'a', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      ['b', 'a', 'c']\n",
      " |      Categories (3, object): ['a' < 'b' < 'c']\n",
      " |\n",
      " |  unstack(self, level: 'IndexLabel' = -1, fill_value: 'Hashable | None' = None, sort: 'bool' = True) -> 'DataFrame'\n",
      " |      Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name.\n",
      " |      fill_value : scalar value, default None\n",
      " |          Value to use when replacing NaN values.\n",
      " |      sort : bool, default True\n",
      " |          Sort the level(s) in the resulting MultiIndex columns.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unstacked Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...               index=pd.MultiIndex.from_product([['one', 'two'],\n",
      " |      ...                                                 ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |\n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |\n",
      " |  update(self, other: 'Series | Sequence | Mapping') -> 'None'\n",
      " |      Modify Series in place using values from passed Series.\n",
      " |\n",
      " |      Uses non-NA values from passed Series to make updates. Aligns\n",
      " |      on index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, or object coercible into Series\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      " |      >>> s\n",
      " |      0    d\n",
      " |      1    b\n",
      " |      2    e\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |\n",
      " |      If ``other`` contains NaNs the corresponding values are not updated\n",
      " |      in the original Series.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |\n",
      " |      ``other`` can also be a non-Series object type\n",
      " |      that is coercible into a Series\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update([4, np.nan, 6])\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update({1: 9})\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    9\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |  var(self, axis: 'Axis | None' = None, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only: 'bool' = False, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |\n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.var with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                    'age': [21, 25, 62, 43],\n",
      " |      ...                    'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                   ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |\n",
      " |      >>> df.var()\n",
      " |      age       352.916667\n",
      " |      height      0.056367\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:\n",
      " |\n",
      " |      >>> df.var(ddof=0)\n",
      " |      age       264.687500\n",
      " |      height      0.042275\n",
      " |      dtype: float64\n",
      " |\n",
      " |  view(self, dtype: 'Dtype | None' = None) -> 'Series'\n",
      " |      Create a new view of the Series.\n",
      " |\n",
      " |      .. deprecated:: 2.2.0\n",
      " |          ``Series.view`` is deprecated and will be removed in a future version.\n",
      " |          Use :meth:`Series.astype` as an alternative to change the dtype.\n",
      " |\n",
      " |      This function will return a new Series with a view of the same\n",
      " |      underlying values in memory, optionally reinterpreted with a new data\n",
      " |      type. The new data type must preserve the same size in bytes as to not\n",
      " |      cause index misalignment.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type\n",
      " |          Data type object or one of their string representations.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A new Series object as a view of the same data in memory.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.view : Equivalent numpy function to create a new view of\n",
      " |          the same data in memory.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series are instantiated with ``dtype=float64`` by default. While\n",
      " |      ``numpy.ndarray.view()`` will return a view with the same data type as\n",
      " |      the original array, ``Series.view()`` (without specified dtype)\n",
      " |      will try using ``float64`` and may fail if the original data type size\n",
      " |      in bytes is not the same.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Use ``astype`` to change the dtype instead.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  array\n",
      " |      The ExtensionArray of the data backing this Series or Index.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ExtensionArray\n",
      " |          An ExtensionArray of the values stored within. For extension\n",
      " |          types, this is the actual array. For NumPy native types, this\n",
      " |          is a thin (no copy) wrapper around :class:`numpy.ndarray`.\n",
      " |\n",
      " |          ``.array`` differs from ``.values``, which may require converting\n",
      " |          the data to a different form.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.to_numpy : Similar method that always returns a NumPy array.\n",
      " |      Series.to_numpy : Similar method that always returns a NumPy array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This table lays out the different array types for each extension\n",
      " |      dtype within pandas.\n",
      " |\n",
      " |      ================== =============================\n",
      " |      dtype              array type\n",
      " |      ================== =============================\n",
      " |      category           Categorical\n",
      " |      period             PeriodArray\n",
      " |      interval           IntervalArray\n",
      " |      IntegerNA          IntegerArray\n",
      " |      string             StringArray\n",
      " |      boolean            BooleanArray\n",
      " |      datetime64[ns, tz] DatetimeArray\n",
      " |      ================== =============================\n",
      " |\n",
      " |      For any 3rd-party extension types, the array type will be an\n",
      " |      ExtensionArray.\n",
      " |\n",
      " |      For all remaining dtypes ``.array`` will be a\n",
      " |      :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\n",
      " |      stored within. If you absolutely need a NumPy array (possibly with\n",
      " |      copying / coercing data), then use :meth:`Series.to_numpy` instead.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For regular NumPy types like int, and float, a NumpyExtensionArray\n",
      " |      is returned.\n",
      " |\n",
      " |      >>> pd.Series([1, 2, 3]).array\n",
      " |      <NumpyExtensionArray>\n",
      " |      [1, 2, 3]\n",
      " |      Length: 3, dtype: int64\n",
      " |\n",
      " |      For extension types, like Categorical, the actual ExtensionArray\n",
      " |      is returned\n",
      " |\n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.array\n",
      " |      ['a', 'b', 'a']\n",
      " |      Categories (2, object): ['a', 'b']\n",
      " |\n",
      " |  axes\n",
      " |      Return a list of the row axis labels.\n",
      " |\n",
      " |  dtype\n",
      " |      Return the dtype object of the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.dtype\n",
      " |      dtype('int64')\n",
      " |\n",
      " |  dtypes\n",
      " |      Return the dtype object of the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.dtypes\n",
      " |      dtype('int64')\n",
      " |\n",
      " |  hasnans\n",
      " |      Return True if there are any NaNs.\n",
      " |\n",
      " |      Enables various performance speedups.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, None])\n",
      " |      >>> s\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    3.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |      >>> s.hasnans\n",
      " |      True\n",
      " |\n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like depending on the dtype.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         We recommend using :attr:`Series.array` or\n",
      " |         :meth:`Series.to_numpy`, depending on whether you need\n",
      " |         a reference to the underlying data or a NumPy array.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray or ndarray-like\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Reference to the underlying data.\n",
      " |      Series.to_numpy : A NumPy array representing the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |\n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |\n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      ['a', 'a', 'b', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |\n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |\n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  index\n",
      " |      The index (axis labels) of the Series.\n",
      " |\n",
      " |      The index of a Series is used to label and identify each element of the\n",
      " |      underlying data. The index can be thought of as an immutable ordered set\n",
      " |      (technically a multi-set, as it may contain duplicate labels), and is\n",
      " |      used to index and align data in pandas.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          The index labels of the Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Conform Series to new index.\n",
      " |      Index : The base pandas index type.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more information on pandas indexing, see the `indexing user guide\n",
      " |      <https://pandas.pydata.org/docs/user_guide/indexing.html>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      To create a Series with a custom index and view the index labels:\n",
      " |\n",
      " |      >>> cities = ['Kolkata', 'Chicago', 'Toronto', 'Lisbon']\n",
      " |      >>> populations = [14.85, 2.71, 2.93, 0.51]\n",
      " |      >>> city_series = pd.Series(populations, index=cities)\n",
      " |      >>> city_series.index\n",
      " |      Index(['Kolkata', 'Chicago', 'Toronto', 'Lisbon'], dtype='object')\n",
      " |\n",
      " |      To change the index labels of an existing Series:\n",
      " |\n",
      " |      >>> city_series.index = ['KOL', 'CHI', 'TOR', 'LIS']\n",
      " |      >>> city_series.index\n",
      " |      Index(['KOL', 'CHI', 'TOR', 'LIS'], dtype='object')\n",
      " |\n",
      " |  name\n",
      " |      Return the name of the Series.\n",
      " |\n",
      " |      The name of a Series becomes its index or column name if it is used\n",
      " |      to form a DataFrame. It is also used whenever displaying the Series\n",
      " |      using the interpreter.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      label (hashable object)\n",
      " |          The name of the Series, also the column name if part of a DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Sets the Series name when given a scalar input.\n",
      " |      Index.name : Corresponding Index property.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      The Series name can be set initially when calling the constructor.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: Numbers, dtype: int64\n",
      " |      >>> s.name = \"Integers\"\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: Integers, dtype: int64\n",
      " |\n",
      " |      The name of a Series within a DataFrame is its column name.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],\n",
      " |      ...                   columns=[\"Odd Numbers\", \"Even Numbers\"])\n",
      " |      >>> df\n",
      " |         Odd Numbers  Even Numbers\n",
      " |      0            1             2\n",
      " |      1            3             4\n",
      " |      2            5             6\n",
      " |      >>> df[\"Even Numbers\"].name\n",
      " |      'Even Numbers'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_AXIS_ORDERS': \"list[Literal['index', 'columns']]\"...\n",
      " |\n",
      " |  __pandas_priority__ = 3000\n",
      " |\n",
      " |  cat = <class 'pandas.core.arrays.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or CategoricalIndex\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(list(\"abbccc\")).astype(\"category\")\n",
      " |      >>> s\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |\n",
      " |      >>> s.cat.categories\n",
      " |      Index(['a', 'b', 'c'], dtype='object')\n",
      " |\n",
      " |      >>> s.cat.rename_categories(list(\"cba\"))\n",
      " |      0    c\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    a\n",
      " |      5    a\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['c', 'b', 'a']\n",
      " |\n",
      " |      >>> s.cat.reorder_categories(list(\"cba\"))\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['c', 'b', 'a']\n",
      " |\n",
      " |      >>> s.cat.add_categories([\"d\", \"e\"])\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (5, object): ['a', 'b', 'c', 'd', 'e']\n",
      " |\n",
      " |      >>> s.cat.remove_categories([\"a\", \"c\"])\n",
      " |      0    NaN\n",
      " |      1      b\n",
      " |      2      b\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      5    NaN\n",
      " |      dtype: category\n",
      " |      Categories (1, object): ['b']\n",
      " |\n",
      " |      >>> s1 = s.cat.add_categories([\"d\", \"e\"])\n",
      " |      >>> s1.cat.remove_unused_categories()\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |\n",
      " |      >>> s.cat.set_categories(list(\"abcde\"))\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (5, object): ['a', 'b', 'c', 'd', 'e']\n",
      " |\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a' < 'b' < 'c']\n",
      " |\n",
      " |      >>> s.cat.as_unordered()\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |\n",
      " |\n",
      " |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      " |\n",
      " |  list = <class 'pandas.core.arrays.arrow.accessors.ListAccessor'>\n",
      " |      Accessor object for list data properties of the Series values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series\n",
      " |          Series containing Arrow list data.\n",
      " |\n",
      " |\n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |\n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |\n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool or sequence of iterables, default False\n",
      " |          Whether to group columns into subplots:\n",
      " |\n",
      " |          - ``False`` : No subplots will be used\n",
      " |          - ``True`` : Make separate subplots for each column.\n",
      " |          - sequence of iterables of column labels: Create a subplot for each\n",
      " |            group of columns. For example `[('a', 'c'), ('b', 'd')]` will\n",
      " |            create 2 subplots: one with columns 'a' and 'c', and one\n",
      " |            with columns 'b' and 'd'. Remaining columns that aren't specified\n",
      " |            will be plotted in additional subplots (one per column).\n",
      " |\n",
      " |            .. versionadded:: 1.5.0\n",
      " |\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |\n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |\n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |\n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              Now applicable to histograms.\n",
      " |\n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              Now applicable to histograms.\n",
      " |\n",
      " |      rot : float, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : float, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> ser = pd.Series([1, 2, 3, 3])\n",
      " |          >>> plot = ser.plot(kind='hist', title=\"My plot\")\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> df = pd.DataFrame({'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...                   'width': [0.7, 0.2, 0.15, 0.2, 1.1]},\n",
      " |          ...                   index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> plot = df.plot(title=\"DataFrame Plot\")\n",
      " |\n",
      " |      For SeriesGroupBy:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> lst = [-1, -2, -3, 1, 2, 3]\n",
      " |          >>> ser = pd.Series([1, 2, 2, 4, 6, 6], index=lst)\n",
      " |          >>> plot = ser.groupby(lambda x: x > 0).plot(title=\"SeriesGroupBy Plot\")\n",
      " |\n",
      " |      For DataFrameGroupBy:\n",
      " |\n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |\n",
      " |          >>> df = pd.DataFrame({\"col1\" : [1, 2, 3, 4],\n",
      " |          ...                   \"col2\" : [\"A\", \"B\", \"A\", \"B\"]})\n",
      " |          >>> plot = df.groupby(\"col2\").plot(kind=\"bar\", title=\"DataFrameGroupBy Plot\")\n",
      " |\n",
      " |\n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseAccessor'>\n",
      " |      Accessor for SparseSparse from other sparse matrix data types.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([0, 0, 2, 2, 2], dtype=\"Sparse[int]\")\n",
      " |      >>> ser.sparse.density\n",
      " |      0.6\n",
      " |      >>> ser.sparse.sp_values\n",
      " |      array([2, 2, 2])\n",
      " |\n",
      " |\n",
      " |  str = <class 'pandas.core.strings.accessor.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index.\n",
      " |\n",
      " |      NAs stay NA unless handled otherwise by a particular method.\n",
      " |      Patterned after Python's string methods, with some inspiration from\n",
      " |      R's stringr package.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"A_Str_Series\"])\n",
      " |      >>> s\n",
      " |      0    A_Str_Series\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s.str.split(\"_\")\n",
      " |      0    [A, Str, Series]\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s.str.replace(\"_\", \"\")\n",
      " |      0    AStrSeries\n",
      " |      dtype: object\n",
      " |\n",
      " |\n",
      " |  struct = <class 'pandas.core.arrays.arrow.accessors.StructAccessor'>\n",
      " |      Accessor object for structured data properties of the Series values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series\n",
      " |          Series containing Arrow struct data.\n",
      " |\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |\n",
      " |  __iter__(self) -> 'Iterator'\n",
      " |      Return an iterator of the values.\n",
      " |\n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> for x in s:\n",
      " |      ...     print(x)\n",
      " |      1\n",
      " |      2\n",
      " |      3\n",
      " |\n",
      " |  argmax(self, axis: 'AxisInt | None' = None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      Return int position of the largest value in the Series.\n",
      " |\n",
      " |      If the maximum is achieved in multiple locations,\n",
      " |      the first row position is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when showing the result.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Row position of the maximum value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.argmax : Return position of the maximum value.\n",
      " |      Series.argmin : Return position of the minimum value.\n",
      " |      numpy.ndarray.argmax : Equivalent method for numpy arrays.\n",
      " |      Series.idxmax : Return index label of the maximum values.\n",
      " |      Series.idxmin : Return index label of the minimum values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing cereal calories\n",
      " |\n",
      " |      >>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n",
      " |      ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n",
      " |      >>> s\n",
      " |      Corn Flakes              100.0\n",
      " |      Almond Delight           110.0\n",
      " |      Cinnamon Toast Crunch    120.0\n",
      " |      Cocoa Puff               110.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.argmax()\n",
      " |      2\n",
      " |      >>> s.argmin()\n",
      " |      0\n",
      " |\n",
      " |      The maximum cereal calories is the third element and\n",
      " |      the minimum cereal calories is the first element,\n",
      " |      since series is zero-indexed.\n",
      " |\n",
      " |  argmin(self, axis: 'AxisInt | None' = None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      Return int position of the smallest value in the Series.\n",
      " |\n",
      " |      If the minimum is achieved in multiple locations,\n",
      " |      the first row position is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when showing the result.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Row position of the minimum value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.argmin : Return position of the minimum value.\n",
      " |      Series.argmax : Return position of the maximum value.\n",
      " |      numpy.ndarray.argmin : Equivalent method for numpy arrays.\n",
      " |      Series.idxmax : Return index label of the maximum values.\n",
      " |      Series.idxmin : Return index label of the minimum values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing cereal calories\n",
      " |\n",
      " |      >>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n",
      " |      ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n",
      " |      >>> s\n",
      " |      Corn Flakes              100.0\n",
      " |      Almond Delight           110.0\n",
      " |      Cinnamon Toast Crunch    120.0\n",
      " |      Cocoa Puff               110.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.argmax()\n",
      " |      2\n",
      " |      >>> s.argmin()\n",
      " |      0\n",
      " |\n",
      " |      The maximum cereal calories is the third element and\n",
      " |      the minimum cereal calories is the first element,\n",
      " |      since series is zero-indexed.\n",
      " |\n",
      " |  factorize(self, sort: 'bool' = False, use_na_sentinel: 'bool' = True) -> 'tuple[npt.NDArray[np.intp], Index]'\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |\n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : bool, default False\n",
      " |          Sort `uniques` and shuffle `codes` to maintain the\n",
      " |          relationship.\n",
      " |\n",
      " |      use_na_sentinel : bool, default True\n",
      " |          If True, the sentinel -1 will be used for NaN values. If False,\n",
      " |          NaN values will be encoded as non-negative integers and will not drop the\n",
      " |          NaN from the uniques of the values.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      codes : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(codes)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |\n",
      " |          .. note::\n",
      " |\n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      cut : Discretize continuous-valued array.\n",
      " |      unique : Find the unique value in an array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.factorize>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"))\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1, 2, 0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |\n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `codes` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"),\n",
      " |      ...                               sort=True)\n",
      " |      >>> codes\n",
      " |      array([1, 1, 0, 2, 1])\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |\n",
      " |      When ``use_na_sentinel=True`` (the default), missing values are indicated in\n",
      " |      the `codes` with the sentinel value ``-1`` and missing values are not\n",
      " |      included in `uniques`.\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(np.array(['b', None, 'a', 'c', 'b'], dtype=\"O\"))\n",
      " |      >>> codes\n",
      " |      array([ 0, -1,  1,  2,  0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |\n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |\n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      ['a', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |\n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, despite not being\n",
      " |      present in ``cat.values``.\n",
      " |\n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |\n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |\n",
      " |      If NaN is in the values, and we want to include NaN in the uniques of the\n",
      " |      values, it can be achieved by setting ``use_na_sentinel=False``.\n",
      " |\n",
      " |      >>> values = np.array([1, 2, 1, np.nan])\n",
      " |      >>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True\n",
      " |      >>> codes\n",
      " |      array([ 0,  1,  0, -1])\n",
      " |      >>> uniques\n",
      " |      array([1., 2.])\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(values, use_na_sentinel=False)\n",
      " |      >>> codes\n",
      " |      array([0, 1, 0, 2])\n",
      " |      >>> uniques\n",
      " |      array([ 1.,  2., nan])\n",
      " |\n",
      " |  item(self)\n",
      " |      Return the first element of the underlying data as a Python scalar.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar\n",
      " |          The first element of Series or Index.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the data is not length = 1.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1])\n",
      " |      >>> s.item()\n",
      " |      1\n",
      " |\n",
      " |      For an index:\n",
      " |\n",
      " |      >>> s = pd.Series([1], index=['a'])\n",
      " |      >>> s.index.item()\n",
      " |      'a'\n",
      " |\n",
      " |  nunique(self, dropna: 'bool' = True) -> 'int'\n",
      " |      Return number of unique elements in the object.\n",
      " |\n",
      " |      Excludes NA values by default.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the count.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nunique: Method nunique for DataFrame.\n",
      " |      Series.count: Count non-NA/null observations in the Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 3, 5, 7, 7])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      4    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.nunique()\n",
      " |      4\n",
      " |\n",
      " |  to_list = tolist(self)\n",
      " |\n",
      " |  to_numpy(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool' = False, na_value: 'object' = <no_default>, **kwargs) -> 'np.ndarray'\n",
      " |      A NumPy ndarray representing the values in this Series or Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the type of the array.\n",
      " |      **kwargs\n",
      " |          Additional keywords passed through to the ``to_numpy`` method\n",
      " |          of the underlying array (for extension arrays).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Get the actual data stored within.\n",
      " |      Index.array : Get the actual data stored within.\n",
      " |      DataFrame.to_numpy : Similar method for DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned array will be the same up to equality (values equal\n",
      " |      in `self` will be equal in the returned array; likewise for values\n",
      " |      that are not equal). When `self` contains an ExtensionArray, the\n",
      " |      dtype may be different. For example, for a category-dtype Series,\n",
      " |      ``to_numpy()`` will return a NumPy array and the categorical dtype\n",
      " |      will be lost.\n",
      " |\n",
      " |      For NumPy dtypes, this will be a reference to the actual data stored\n",
      " |      in this Series or Index (assuming ``copy=False``). Modifying the result\n",
      " |      in place will modify the data stored in the Series or Index (not that\n",
      " |      we recommend doing that).\n",
      " |\n",
      " |      For extension types, ``to_numpy()`` *may* require copying data and\n",
      " |      coercing the result to a NumPy type (possibly object), which may be\n",
      " |      expensive. When you need a no-copy reference to the underlying data,\n",
      " |      :attr:`Series.array` should be used instead.\n",
      " |\n",
      " |      This table lays out the different dtypes and default return types of\n",
      " |      ``to_numpy()`` for various dtypes within pandas.\n",
      " |\n",
      " |      ================== ================================\n",
      " |      dtype              array type\n",
      " |      ================== ================================\n",
      " |      category[T]        ndarray[T] (same dtype as input)\n",
      " |      period             ndarray[object] (Periods)\n",
      " |      interval           ndarray[object] (Intervals)\n",
      " |      IntegerNA          ndarray[object]\n",
      " |      datetime64[ns]     datetime64[ns]\n",
      " |      datetime64[ns, tz] ndarray[object] (Timestamps)\n",
      " |      ================== ================================\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.to_numpy()\n",
      " |      array(['a', 'b', 'a'], dtype=object)\n",
      " |\n",
      " |      Specify the `dtype` to control how datetime-aware data is represented.\n",
      " |      Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\n",
      " |      objects, each with the correct ``tz``.\n",
      " |\n",
      " |      >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> ser.to_numpy(dtype=object)\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\n",
      " |            dtype=object)\n",
      " |\n",
      " |      Or ``dtype='datetime64[ns]'`` to return an ndarray of native\n",
      " |      datetime64 values. The values are converted to UTC and the timezone\n",
      " |      info is dropped.\n",
      " |\n",
      " |      >>> ser.to_numpy(dtype=\"datetime64[ns]\")\n",
      " |      ... # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\n",
      " |            dtype='datetime64[ns]')\n",
      " |\n",
      " |  tolist(self)\n",
      " |      Return a list of the values.\n",
      " |\n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      list\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\n",
      " |          nested list of Python scalars.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.to_list()\n",
      " |      [1, 2, 3]\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |      >>> idx.to_list()\n",
      " |      [1, 2, 3]\n",
      " |\n",
      " |  transpose(self, *args, **kwargs) -> 'Self'\n",
      " |      Return the transpose, which is by definition self.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s\n",
      " |\n",
      " |  value_counts(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return a Series containing counts of unique values.\n",
      " |\n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : bool, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies when True. Preserve the order of the data when False.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      bins : int, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for ``pd.cut``, only works with numeric data.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of NaN.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.count: Number of non-NA elements in a DataFrame.\n",
      " |      DataFrame.value_counts: Equivalent method on DataFrames.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> index.value_counts()\n",
      " |      3.0    2\n",
      " |      1.0    1\n",
      " |      2.0    1\n",
      " |      4.0    1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      With `normalize` set to `True`, returns the relative frequency by\n",
      " |      dividing all values by the sum of values.\n",
      " |\n",
      " |      >>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> s.value_counts(normalize=True)\n",
      " |      3.0    0.4\n",
      " |      1.0    0.2\n",
      " |      2.0    0.2\n",
      " |      4.0    0.2\n",
      " |      Name: proportion, dtype: float64\n",
      " |\n",
      " |      **bins**\n",
      " |\n",
      " |      Bins can be useful for going from a continuous variable to a\n",
      " |      categorical variable; instead of counting unique\n",
      " |      apparitions of values, divide the index in the specified\n",
      " |      number of half-open bins.\n",
      " |\n",
      " |      >>> s.value_counts(bins=3)\n",
      " |      (0.996, 2.0]    2\n",
      " |      (2.0, 3.0]      2\n",
      " |      (3.0, 4.0]      1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      **dropna**\n",
      " |\n",
      " |      With `dropna` set to `False` we can also see NaN index values.\n",
      " |\n",
      " |      >>> s.value_counts(dropna=False)\n",
      " |      3.0    2\n",
      " |      1.0    1\n",
      " |      2.0    1\n",
      " |      4.0    1\n",
      " |      NaN    1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.base.IndexOpsMixin:\n",
      " |\n",
      " |  T\n",
      " |      Return the transpose, which is by definition self.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.T\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx.T\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |  empty\n",
      " |\n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are monotonically decreasing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([3, 2, 2, 1])\n",
      " |      >>> s.is_monotonic_decreasing\n",
      " |      True\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.is_monotonic_decreasing\n",
      " |      False\n",
      " |\n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are monotonically increasing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 2])\n",
      " |      >>> s.is_monotonic_increasing\n",
      " |      True\n",
      " |\n",
      " |      >>> s = pd.Series([3, 2, 1])\n",
      " |      >>> s.is_monotonic_increasing\n",
      " |      False\n",
      " |\n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.is_unique\n",
      " |      True\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 1])\n",
      " |      >>> s.is_unique\n",
      " |      False\n",
      " |\n",
      " |  nbytes\n",
      " |      Return the number of bytes in the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.nbytes\n",
      " |      24\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.nbytes\n",
      " |      24\n",
      " |\n",
      " |  ndim\n",
      " |      Number of dimensions of the underlying data, by definition 1.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.ndim\n",
      " |      1\n",
      " |\n",
      " |  shape\n",
      " |      Return a tuple of the shape of the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.shape\n",
      " |      (3,)\n",
      " |\n",
      " |  size\n",
      " |      Return the number of elements in the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.size\n",
      " |      3\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |\n",
      " |  __array_priority__ = 1000\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __add__(self, other)\n",
      " |      Get Addition of DataFrame and other, column-wise.\n",
      " |\n",
      " |      Equivalent to ``DataFrame.add(other)``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Object to be added to the DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of adding ``other`` to DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add a DataFrame and another object, with option for index-\n",
      " |          or column-oriented addition.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},\n",
      " |      ...                   index=['elk', 'moose'])\n",
      " |      >>> df\n",
      " |             height  weight\n",
      " |      elk       1.5     500\n",
      " |      moose     2.6     800\n",
      " |\n",
      " |      Adding a scalar affects all rows and columns.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + 1.5\n",
      " |             height  weight\n",
      " |      elk       3.0   501.5\n",
      " |      moose     4.1   801.5\n",
      " |\n",
      " |      Each element of a list is added to a column of the DataFrame, in order.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + [0.5, 1.5]\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |\n",
      " |      Keys of a dictionary are aligned to the DataFrame, based on column names;\n",
      " |      each value in the dictionary is added to the corresponding column.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + {'height': 0.5, 'weight': 1.5}\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the index of `other` is aligned with the\n",
      " |      columns of the DataFrame.\n",
      " |\n",
      " |      >>> s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])\n",
      " |      >>> df[['height', 'weight']] + s1\n",
      " |             height  weight\n",
      " |      elk       3.0   500.5\n",
      " |      moose     4.1   800.5\n",
      " |\n",
      " |      Even when the index of `other` is the same as the index of the DataFrame,\n",
      " |      the :class:`Series` will not be reoriented. If index-wise alignment is desired,\n",
      " |      :meth:`DataFrame.add` should be used with `axis='index'`.\n",
      " |\n",
      " |      >>> s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])\n",
      " |      >>> df[['height', 'weight']] + s2\n",
      " |             elk  height  moose  weight\n",
      " |      elk    NaN     NaN    NaN     NaN\n",
      " |      moose  NaN     NaN    NaN     NaN\n",
      " |\n",
      " |      >>> df[['height', 'weight']].add(s2, axis='index')\n",
      " |             height  weight\n",
      " |      elk       2.0   500.5\n",
      " |      moose     4.1   801.5\n",
      " |\n",
      " |      When `other` is a :class:`DataFrame`, both columns names and the\n",
      " |      index are aligned.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},\n",
      " |      ...                      index=['elk', 'moose', 'deer'])\n",
      " |      >>> df[['height', 'weight']] + other\n",
      " |             height  weight\n",
      " |      deer      NaN     NaN\n",
      " |      elk       1.7     NaN\n",
      " |      moose     3.0     NaN\n",
      " |\n",
      " |  __and__(self, other)\n",
      " |\n",
      " |  __divmod__(self, other)\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __floordiv__(self, other)\n",
      " |\n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __mod__(self, other)\n",
      " |\n",
      " |  __mul__(self, other)\n",
      " |\n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |\n",
      " |  __or__(self, other)\n",
      " |      Return self|value.\n",
      " |\n",
      " |  __pow__(self, other)\n",
      " |\n",
      " |  __radd__(self, other)\n",
      " |\n",
      " |  __rand__(self, other)\n",
      " |\n",
      " |  __rdivmod__(self, other)\n",
      " |\n",
      " |  __rfloordiv__(self, other)\n",
      " |\n",
      " |  __rmod__(self, other)\n",
      " |\n",
      " |  __rmul__(self, other)\n",
      " |\n",
      " |  __ror__(self, other)\n",
      " |      Return value|self.\n",
      " |\n",
      " |  __rpow__(self, other)\n",
      " |\n",
      " |  __rsub__(self, other)\n",
      " |\n",
      " |  __rtruediv__(self, other)\n",
      " |\n",
      " |  __rxor__(self, other)\n",
      " |\n",
      " |  __sub__(self, other)\n",
      " |\n",
      " |  __truediv__(self, other)\n",
      " |\n",
      " |  __xor__(self, other)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  __abs__(self) -> 'Self'\n",
      " |\n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |\n",
      " |  __bool__ = __nonzero__(self) -> 'NoReturn'\n",
      " |\n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |\n",
      " |  __copy__(self, deep: 'bool_t' = True) -> 'Self'\n",
      " |\n",
      " |  __deepcopy__(self, memo=None) -> 'Self'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |\n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |\n",
      " |  __finalize__(self, other, method: 'str | None' = None, **kwargs) -> 'Self'\n",
      " |      Propagate metadata from other to self.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |\n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |\n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __iadd__(self, other) -> 'Self'\n",
      " |\n",
      " |  __iand__(self, other) -> 'Self'\n",
      " |\n",
      " |  __ifloordiv__(self, other) -> 'Self'\n",
      " |\n",
      " |  __imod__(self, other) -> 'Self'\n",
      " |\n",
      " |  __imul__(self, other) -> 'Self'\n",
      " |\n",
      " |  __invert__(self) -> 'Self'\n",
      " |\n",
      " |  __ior__(self, other) -> 'Self'\n",
      " |\n",
      " |  __ipow__(self, other) -> 'Self'\n",
      " |\n",
      " |  __isub__(self, other) -> 'Self'\n",
      " |\n",
      " |  __itruediv__(self, other) -> 'Self'\n",
      " |\n",
      " |  __ixor__(self, other) -> 'Self'\n",
      " |\n",
      " |  __neg__(self) -> 'Self'\n",
      " |\n",
      " |  __nonzero__(self) -> 'NoReturn'\n",
      " |\n",
      " |  __pos__(self) -> 'Self'\n",
      " |\n",
      " |  __round__(self, decimals: 'int' = 0) -> 'Self'\n",
      " |\n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |\n",
      " |  __setstate__(self, state) -> 'None'\n",
      " |\n",
      " |  abs(self) -> 'Self'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |\n",
      " |      This function only applies to elements that are all numeric.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |\n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |\n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |\n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |\n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |\n",
      " |  add_prefix(self, prefix: 'str', axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |\n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to add prefix on\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |\n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |\n",
      " |  add_suffix(self, suffix: 'str', axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |\n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to add suffix on\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |\n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |\n",
      " |  align(self, other: 'NDFrameT', join: 'AlignJoin' = 'outer', axis: 'Axis | None' = None, level: 'Level | None' = None, copy: 'bool_t | None' = None, fill_value: 'Hashable | None' = None, method: 'FillnaOptions | None | lib.NoDefault' = <no_default>, limit: 'int | None | lib.NoDefault' = <no_default>, fill_axis: 'Axis | lib.NoDefault' = <no_default>, broadcast_axis: 'Axis | None | lib.NoDefault' = <no_default>) -> 'tuple[Self, NDFrameT]'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |\n",
      " |      Join method is specified for each axis Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |          Type of alignment to be performed.\n",
      " |\n",
      " |          * left: use only keys from left frame, preserve key order.\n",
      " |          * right: use only keys from right frame, preserve key order.\n",
      " |          * outer: use union of keys from both frames, sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames,\n",
      " |            preserve the order of the left keys.\n",
      " |\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      fill_value : scalar, default np.nan\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |\n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      fill_axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      broadcast_axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple of (Series/DataFrame, type of other)\n",
      " |          Aligned objects.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n",
      " |      ... )\n",
      " |      >>> other = pd.DataFrame(\n",
      " |      ...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n",
      " |      ...     columns=[\"A\", \"B\", \"C\", \"D\"],\n",
      " |      ...     index=[2, 3, 4],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         D  B  E  A\n",
      " |      1  1  2  3  4\n",
      " |      2  6  7  8  9\n",
      " |      >>> other\n",
      " |          A    B    C    D\n",
      " |      2   10   20   30   40\n",
      " |      3   60   70   80   90\n",
      " |      4  600  700  800  900\n",
      " |\n",
      " |      Align on columns:\n",
      " |\n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=1)\n",
      " |      >>> left\n",
      " |         A  B   C  D  E\n",
      " |      1  4  2 NaN  1  3\n",
      " |      2  9  7 NaN  6  8\n",
      " |      >>> right\n",
      " |          A    B    C    D   E\n",
      " |      2   10   20   30   40 NaN\n",
      " |      3   60   70   80   90 NaN\n",
      " |      4  600  700  800  900 NaN\n",
      " |\n",
      " |      We can also align on the index:\n",
      " |\n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=0)\n",
      " |      >>> left\n",
      " |          D    B    E    A\n",
      " |      1  1.0  2.0  3.0  4.0\n",
      " |      2  6.0  7.0  8.0  9.0\n",
      " |      3  NaN  NaN  NaN  NaN\n",
      " |      4  NaN  NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |          A      B      C      D\n",
      " |      1    NaN    NaN    NaN    NaN\n",
      " |      2   10.0   20.0   30.0   40.0\n",
      " |      3   60.0   70.0   80.0   90.0\n",
      " |      4  600.0  700.0  800.0  900.0\n",
      " |\n",
      " |      Finally, the default `axis=None` will align on both index and columns:\n",
      " |\n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=None)\n",
      " |      >>> left\n",
      " |           A    B   C    D    E\n",
      " |      1  4.0  2.0 NaN  1.0  3.0\n",
      " |      2  9.0  7.0 NaN  6.0  8.0\n",
      " |      3  NaN  NaN NaN  NaN  NaN\n",
      " |      4  NaN  NaN NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |             A      B      C      D   E\n",
      " |      1    NaN    NaN    NaN    NaN NaN\n",
      " |      2   10.0   20.0   30.0   40.0 NaN\n",
      " |      3   60.0   70.0   80.0   90.0 NaN\n",
      " |      4  600.0  700.0  800.0  900.0 NaN\n",
      " |\n",
      " |  asfreq(self, freq: 'Frequency', method: 'FillnaOptions | None' = None, how: \"Literal['start', 'end'] | None\" = None, normalize: 'bool_t' = False, fill_value: 'Hashable | None' = None) -> 'Self'\n",
      " |      Convert time series to specified frequency.\n",
      " |\n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |\n",
      " |      If the index of this Series/DataFrame is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |\n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |\n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |\n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame object reindexed to the specified frequency.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |\n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='min')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |      Upsample the series into 30 second bins.\n",
      " |\n",
      " |      >>> df.asfreq(freq='30s')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |\n",
      " |      >>> df.asfreq(freq='30s', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |      Upsample again, providing a ``method``.\n",
      " |\n",
      " |      >>> df.asfreq(freq='30s', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |\n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |\n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |\n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |\n",
      " |          The return can be:\n",
      " |\n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |\n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |\n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |\n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |\n",
      " |      Take all columns into consideration\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'a': [10., 20., 30., 40., 50.],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |\n",
      " |      Take a single column into consideration\n",
      " |\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                              a   b\n",
      " |      2018-02-27 09:03:30  30.0 NaN\n",
      " |      2018-02-27 09:04:30  40.0 NaN\n",
      " |\n",
      " |  astype(self, dtype, copy: 'bool_t | None' = None, errors: 'IgnoreRaise' = 'raise') -> 'Self'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str, data type, Series or Mapping of column name -> data type\n",
      " |          Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\n",
      " |          cast entire pandas object to the same type. Alternatively, use a\n",
      " |          mapping, e.g. {col: dtype, ...}, where col is a column label and dtype is\n",
      " |          a numpy.dtype or Python type to cast one or more of the DataFrame's\n",
      " |          columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. versionchanged:: 2.0.0\n",
      " |\n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype will raise an exception.\n",
      " |          Use :meth:`Series.dt.tz_localize` instead.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |\n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Cast all columns to int32:\n",
      " |\n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |\n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |\n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Create a series:\n",
      " |\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Convert to categorical type:\n",
      " |\n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int32): [1, 2]\n",
      " |\n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |\n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |\n",
      " |      Create a series of dates:\n",
      " |\n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |\n",
      " |  at_time(self, time, asof: 'bool_t' = False, axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |          The values to select.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12h')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |\n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |\n",
      " |  backfill(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by using the next valid observation to fill the gap.\n",
      " |\n",
      " |      .. deprecated:: 2.0\n",
      " |\n",
      " |          Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Please see examples for :meth:`DataFrame.bfill` or :meth:`Series.bfill`.\n",
      " |\n",
      " |  between_time(self, start_time, end_time, inclusive: 'IntervalClosedType' = 'both', axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |\n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}, default \"both\"\n",
      " |          Include boundaries; whether to set each bound as closed or open.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |\n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |\n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |\n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |\n",
      " |  bfill(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, limit_area: \"Literal['inside', 'outside'] | None\" = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by using the next valid observation to fill the gap.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      limit_area : {`None`, 'inside', 'outside'}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |          .. versionadded:: 2.2.0\n",
      " |\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series([1, None, None, 2])\n",
      " |      >>> s.bfill()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    2.0\n",
      " |      3    2.0\n",
      " |      dtype: float64\n",
      " |      >>> s.bfill(limit=1)\n",
      " |      0    1.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3    2.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      With DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, None, None, 4], 'B': [None, 5, None, 7]})\n",
      " |      >>> df\n",
      " |            A     B\n",
      " |      0   1.0   NaN\n",
      " |      1   NaN   5.0\n",
      " |      2   NaN   NaN\n",
      " |      3   4.0   7.0\n",
      " |      >>> df.bfill()\n",
      " |            A     B\n",
      " |      0   1.0   5.0\n",
      " |      1   4.0   5.0\n",
      " |      2   4.0   7.0\n",
      " |      3   4.0   7.0\n",
      " |      >>> df.bfill(limit=1)\n",
      " |            A     B\n",
      " |      0   1.0   5.0\n",
      " |      1   NaN   5.0\n",
      " |      2   4.0   7.0\n",
      " |      3   4.0   7.0\n",
      " |\n",
      " |  bool(self) -> 'bool_t'\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |\n",
      " |      .. deprecated:: 2.1.0\n",
      " |\n",
      " |         bool is deprecated and will be removed in future version of pandas.\n",
      " |         For ``Series`` use ``pandas.Series.item``.\n",
      " |\n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |\n",
      " |      >>> pd.Series([True]).bool()  # doctest: +SKIP\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()  # doctest: +SKIP\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      This is an alternative method and will only work\n",
      " |      for single element objects with a boolean value:\n",
      " |\n",
      " |      >>> pd.Series([True]).item()  # doctest: +SKIP\n",
      " |      True\n",
      " |      >>> pd.Series([False]).item()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  clip(self, lower=None, upper=None, *, axis: 'Axis | None' = None, inplace: 'bool_t' = False, **kwargs) -> 'Self | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |\n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |          For `Series` this parameter is unused and defaults to `None`.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |\n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |\n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |\n",
      " |      Clips using specific lower and upper thresholds per column:\n",
      " |\n",
      " |      >>> df.clip([-2, -1], [4, 5])\n",
      " |          col_0  col_1\n",
      " |      0      4     -1\n",
      " |      1     -2     -1\n",
      " |      2      0      5\n",
      " |      3     -1      5\n",
      " |      4      4     -1\n",
      " |\n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |\n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |\n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |\n",
      " |      >>> t = pd.Series([2, -4, np.nan, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |\n",
      " |  convert_dtypes(self, infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True, dtype_backend: 'DtypeBackend' = 'numpy_nullable') -> 'Self'\n",
      " |      Convert columns to the best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      " |          Back-end data type applied to the resultant :class:`DataFrame`\n",
      " |          (still experimental). Behaviour is as follows:\n",
      " |\n",
      " |          * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      " |            (default).\n",
      " |          * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      " |            DataFrame.\n",
      " |\n",
      " |          .. versionadded:: 2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_floating``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |\n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |\n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |\n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |\n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |\n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |\n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |\n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |\n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |\n",
      " |      >>> dfn.dtypes\n",
      " |      a             Int32\n",
      " |      b    string[python]\n",
      " |      c           boolean\n",
      " |      d    string[python]\n",
      " |      e             Int64\n",
      " |      f           Float64\n",
      " |      dtype: object\n",
      " |\n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |\n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |\n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |\n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |\n",
      " |  copy(self, deep: 'bool_t | None' = True) -> 'Self'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |\n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |\n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |\n",
      " |      .. note::\n",
      " |          The ``deep=False`` behaviour as described above will change\n",
      " |          in pandas 3.0. `Copy-on-Write\n",
      " |          <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |          will be enabled by default, which means that the \"shallow\" copy\n",
      " |          is that is returned with ``deep=False`` will still avoid making\n",
      " |          an eager copy, but changes to the data of the original will *no*\n",
      " |          longer be reflected in the shallow copy (or vice versa). Instead,\n",
      " |          it makes use of a lazy (deferred) copy mechanism that will copy\n",
      " |          the data only when any changes to the original or shallow copy is\n",
      " |          made.\n",
      " |\n",
      " |          You can already get the future behavior and improvements through\n",
      " |          enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |\n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |\n",
      " |      Since pandas is not thread safe, see the\n",
      " |      :ref:`gotchas <gotchas.thread-safety>` when copying in a threading\n",
      " |      environment.\n",
      " |\n",
      " |      When ``copy_on_write`` in pandas config is set to ``True``, the\n",
      " |      ``copy_on_write`` config takes effect even when ``deep=False``.\n",
      " |      This means that any changes to the copied data would make a new copy\n",
      " |      of the data upon write (and vice versa). Changes made to either the\n",
      " |      original or copied variable would not be reflected in the counterpart.\n",
      " |      See :ref:`Copy_on_Write <copy_on_write>` for more information.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |\n",
      " |      Shallow copy shares data and index with original.\n",
      " |\n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |\n",
      " |      Deep copy has own copy of data and index.\n",
      " |\n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |\n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both (NOTE: this will no longer be true for pandas >= 3.0);\n",
      " |      deep copy remains unchanged.\n",
      " |\n",
      " |      >>> s.iloc[0] = 3\n",
      " |      >>> shallow.iloc[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |\n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |\n",
      " |      **Copy-on-Write is set to true**, the shallow copy is not modified\n",
      " |      when the original data is changed:\n",
      " |\n",
      " |      >>> with pd.option_context(\"mode.copy_on_write\", True):\n",
      " |      ...     s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      ...     copy = s.copy(deep=False)\n",
      " |      ...     s.iloc[0] = 100\n",
      " |      ...     s\n",
      " |      a    100\n",
      " |      b      2\n",
      " |      dtype: int64\n",
      " |      >>> copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |  describe(self, percentiles=None, include=None, exclude=None) -> 'Self'\n",
      " |      Generate descriptive statistics.\n",
      " |\n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |\n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |\n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |\n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |\n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |\n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |\n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |\n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Describing a categorical ``Series``.\n",
      " |\n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |\n",
      " |      Describing a timestamp ``Series``.\n",
      " |\n",
      " |      >>> s = pd.Series([\n",
      " |      ...     np.datetime64(\"2000-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |\n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                    })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |\n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |\n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |\n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |\n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |\n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |\n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |\n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |\n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |\n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |\n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |\n",
      " |  droplevel(self, level: 'IndexLabel', axis: 'Axis' = 0) -> 'Self'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |\n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |\n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |\n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |\n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |\n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |\n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |\n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |\n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns and\n",
      " |      index must be of the same dtype.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |\n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |\n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |\n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |\n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |\n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |\n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |\n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis | lib.NoDefault' = <no_default>, times: 'np.ndarray | DataFrame | Series | None' = None, method: \"Literal['single', 'table']\" = 'single') -> 'ExponentialMovingWindow'\n",
      " |      Provide exponentially weighted (EW) calculations.\n",
      " |\n",
      " |      Exactly one of ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided if ``times`` is not provided. If ``times`` is provided,\n",
      " |      ``halflife`` and one of ``com``, ``span`` or ``alpha`` may be provided.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass\n",
      " |\n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span\n",
      " |\n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |\n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life\n",
      " |\n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |\n",
      " |          If ``times`` is specified, a timedelta convertible unit over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``,\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly\n",
      " |\n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |\n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |\n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |\n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |\n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |\n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |\n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights.\n",
      " |\n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |\n",
      " |          - When ``ignore_na=True``, weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |\n",
      " |      axis : {0, 1}, default 0\n",
      " |          If ``0`` or ``'index'``, calculate across the rows.\n",
      " |\n",
      " |          If ``1`` or ``'columns'``, calculate across the columns.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      times : np.ndarray, Series, default None\n",
      " |\n",
      " |          Only applicable to ``mean()``.\n",
      " |\n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |\n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |\n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |\n",
      " |          Only applicable to ``mean()``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.ExponentialMovingWindow\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.exponentially_weighted>`\n",
      " |      for further usage details and examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |\n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(alpha=2 / 3).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |\n",
      " |      **adjust**\n",
      " |\n",
      " |      >>> df.ewm(com=0.5, adjust=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(com=0.5, adjust=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.666667\n",
      " |      2  1.555556\n",
      " |      3  1.555556\n",
      " |      4  3.650794\n",
      " |\n",
      " |      **ignore_na**\n",
      " |\n",
      " |      >>> df.ewm(com=0.5, ignore_na=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.225000\n",
      " |      >>> df.ewm(com=0.5, ignore_na=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |\n",
      " |      **times**\n",
      " |\n",
      " |      Exponentially weighted mean with weights calculated with a timedelta ``halflife``\n",
      " |      relative to ``times``.\n",
      " |\n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |\n",
      " |  expanding(self, min_periods: 'int' = 1, axis: 'Axis | lib.NoDefault' = <no_default>, method: \"Literal['single', 'table']\" = 'single') -> 'Expanding'\n",
      " |      Provide expanding window calculations.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |\n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |\n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |\n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.Expanding\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.expanding>` for further usage details\n",
      " |      and examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |\n",
      " |      **min_periods**\n",
      " |\n",
      " |      Expanding sum with 1 vs 3 observations needed to calculate a value.\n",
      " |\n",
      " |      >>> df.expanding(1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      >>> df.expanding(3).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |\n",
      " |  ffill(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, limit_area: \"Literal['inside', 'outside'] | None\" = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by propagating the last valid observation to next valid.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      limit_area : {`None`, 'inside', 'outside'}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |          .. versionadded:: 2.2.0\n",
      " |\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |\n",
      " |      >>> df.ffill()\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  3.0  4.0 NaN  1.0\n",
      " |      3  3.0  3.0 NaN  4.0\n",
      " |\n",
      " |      >>> ser = pd.Series([1, np.nan, 2, 3])\n",
      " |      >>> ser.ffill()\n",
      " |      0   1.0\n",
      " |      1   1.0\n",
      " |      2   2.0\n",
      " |      3   3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |  fillna(self, value: 'Hashable | Mapping | Series | DataFrame | None' = None, *, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool_t' = False, limit: 'int | None' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |\n",
      " |          * ffill: propagate last valid observation forward to next valid.\n",
      " |          * backfill / bfill: use next valid observation to fill gap.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |              Use ffill or bfill instead.\n",
      " |\n",
      " |      axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      ffill : Fill values by propagating the last valid observation to next valid.\n",
      " |      bfill : Fill values by using the next valid observation to fill the gap.\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |\n",
      " |      Replace all NaN elements with 0s.\n",
      " |\n",
      " |      >>> df.fillna(0)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  0.0\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |\n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |\n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  2.0  1.0\n",
      " |      2  0.0  1.0  2.0  3.0\n",
      " |      3  0.0  3.0  2.0  4.0\n",
      " |\n",
      " |      Only replace the first NaN element.\n",
      " |\n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  NaN  1.0\n",
      " |      2  NaN  1.0  NaN  3.0\n",
      " |      3  NaN  3.0  NaN  4.0\n",
      " |\n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  NaN\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |\n",
      " |      Note that column D is not affected since it is not present in df2.\n",
      " |\n",
      " |  filter(self, items=None, like: 'str | None' = None, regex: 'str | None' = None, axis: 'Axis | None' = None) -> 'Self'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |\n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis, 'columns' for\n",
      " |          DataFrame. For `Series` this parameter is unused and defaults to `None`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |\n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |\n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |\n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |\n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |\n",
      " |  first(self, offset) -> 'Self'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |\n",
      " |      .. deprecated:: 2.1\n",
      " |          :meth:`.first` is deprecated and will be removed in a future version.\n",
      " |          Please create a mask and filter using `.loc` instead.\n",
      " |\n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1ME' will display all the rows having their index within the first month.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |\n",
      " |      Get the rows for the first 3 days:\n",
      " |\n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |\n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |\n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no non-NA value is found.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series([None, 3, 4])\n",
      " |      >>> s.first_valid_index()\n",
      " |      1\n",
      " |      >>> s.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> s = pd.Series([None, None])\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in Series are NA/null, returns None.\n",
      " |\n",
      " |      >>> s = pd.Series()\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If Series is empty, returns None.\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  NaN    NaN\n",
      " |      1  NaN    3.0\n",
      " |      2  2.0    4.0\n",
      " |      >>> df.first_valid_index()\n",
      " |      1\n",
      " |      >>> df.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  None   None\n",
      " |      1  None   None\n",
      " |      2  None   None\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in DataFrame are NA/null, returns None.\n",
      " |\n",
      " |      >>> df = pd.DataFrame()\n",
      " |      >>> df\n",
      " |      Empty DataFrame\n",
      " |      Columns: []\n",
      " |      Index: []\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If DataFrame is empty, returns None.\n",
      " |\n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |\n",
      " |      Returns default value if not found.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as items contained in object\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [\n",
      " |      ...         [24.3, 75.7, \"high\"],\n",
      " |      ...         [31, 87.8, \"high\"],\n",
      " |      ...         [22, 71.6, \"medium\"],\n",
      " |      ...         [35, 95, \"medium\"],\n",
      " |      ...     ],\n",
      " |      ...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
      " |      ...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
      " |      ... )\n",
      " |\n",
      " |      >>> df\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |\n",
      " |      >>> df.get([\"temp_celsius\", \"windspeed\"])\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          24.3      high\n",
      " |      2014-02-13          31.0      high\n",
      " |      2014-02-14          22.0    medium\n",
      " |      2014-02-15          35.0    medium\n",
      " |\n",
      " |      >>> ser = df['windspeed']\n",
      " |      >>> ser.get('2014-02-13')\n",
      " |      'high'\n",
      " |\n",
      " |      If the key isn't found, the default value will be used.\n",
      " |\n",
      " |      >>> df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
      " |      'default_value'\n",
      " |\n",
      " |      >>> ser.get('2014-02-10', '[unknown]')\n",
      " |      '[unknown]'\n",
      " |\n",
      " |  head(self, n: 'int' = 5) -> 'Self'\n",
      " |      Return the first `n` rows.\n",
      " |\n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |\n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `|n|` rows, equivalent to ``df[:n]``.\n",
      " |\n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |\n",
      " |      Viewing the first 5 lines\n",
      " |\n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |\n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |\n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |\n",
      " |      For negative values of `n`\n",
      " |\n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |\n",
      " |  infer_objects(self, copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |\n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy for non-object or non-inferable columns\n",
      " |          or Series.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |\n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |\n",
      " |  interpolate(self, method: 'InterpolateOptions' = 'linear', *, axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool_t' = False, limit_direction: \"Literal['forward', 'backward', 'both'] | None\" = None, limit_area: \"Literal['inside', 'outside'] | None\" = None, downcast: \"Literal['infer'] | None | lib.NoDefault\" = <no_default>, **kwargs) -> 'Self | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |\n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |\n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`, whereas 'spline' is passed to\n",
      " |            `scipy.interpolate.UnivariateSpline`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``. Note that,\n",
      " |            `slinear` method in Pandas refers to the Scipy first order `spline`\n",
      " |            instead of Pandas first order `spline`.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives`.\n",
      " |\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along. For `Series` this parameter is unused\n",
      " |          and defaults to 0.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |\n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |\n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |\n",
      " |          raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |              method is 'backfill' or 'bfill'.\n",
      " |          raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |              method is 'pad' or 'ffill'.\n",
      " |\n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |\n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |\n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |\n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |\n",
      " |      Using polynomial interpolation.\n",
      " |\n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |\n",
      " |  last(self, offset) -> 'Self'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |\n",
      " |      .. deprecated:: 2.1\n",
      " |          :meth:`.last` is deprecated and will be removed in a future version.\n",
      " |          Please create a mask and filter using `.loc` instead.\n",
      " |\n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: 2.1.0\n",
      " |          Please create a mask and filter using `.loc` instead\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |\n",
      " |      Get the rows for the last 3 days:\n",
      " |\n",
      " |      >>> ts.last('3D')  # doctest: +SKIP\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |\n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |\n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no non-NA value is found.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series([None, 3, 4])\n",
      " |      >>> s.first_valid_index()\n",
      " |      1\n",
      " |      >>> s.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> s = pd.Series([None, None])\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in Series are NA/null, returns None.\n",
      " |\n",
      " |      >>> s = pd.Series()\n",
      " |      >>> print(s.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(s.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If Series is empty, returns None.\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, 2], 'B': [None, 3, 4]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  NaN    NaN\n",
      " |      1  NaN    3.0\n",
      " |      2  2.0    4.0\n",
      " |      >>> df.first_valid_index()\n",
      " |      1\n",
      " |      >>> df.last_valid_index()\n",
      " |      2\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [None, None, None], 'B': [None, None, None]})\n",
      " |      >>> df\n",
      " |           A      B\n",
      " |      0  None   None\n",
      " |      1  None   None\n",
      " |      2  None   None\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If all elements in DataFrame are NA/null, returns None.\n",
      " |\n",
      " |      >>> df = pd.DataFrame()\n",
      " |      >>> df\n",
      " |      Empty DataFrame\n",
      " |      Columns: []\n",
      " |      Index: []\n",
      " |      >>> print(df.first_valid_index())\n",
      " |      None\n",
      " |      >>> print(df.last_valid_index())\n",
      " |      None\n",
      " |\n",
      " |      If DataFrame is empty, returns None.\n",
      " |\n",
      " |  mask(self, cond, other=<no_default>, *, inplace: 'bool_t' = False, axis: 'Axis | None' = None, level: 'Level | None' = None) -> 'Self | None'\n",
      " |      Replace values where the condition is True.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |          If not specified, entries will be filled with the corresponding\n",
      " |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension\n",
      " |          dtypes).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      True.\n",
      " |\n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |\n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |\n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |\n",
      " |  pad(self, *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      " |      Fill NA/NaN values by propagating the last valid observation to next valid.\n",
      " |\n",
      " |      .. deprecated:: 2.0\n",
      " |\n",
      " |          Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Please see examples for :meth:`DataFrame.ffill` or :meth:`Series.ffill`.\n",
      " |\n",
      " |  pct_change(self, periods: 'int' = 1, fill_method: 'FillnaOptions | None | lib.NoDefault' = <no_default>, limit: 'int | None | lib.NoDefault' = <no_default>, freq=None, **kwargs) -> 'Self'\n",
      " |      Fractional change between the current and a prior element.\n",
      " |\n",
      " |      Computes the fractional change from the immediately previous row by\n",
      " |      default. This is useful in comparing the fraction of change in a time\n",
      " |      series of elements.\n",
      " |\n",
      " |      .. note::\n",
      " |\n",
      " |          Despite the name of this method, it calculates fractional change\n",
      " |          (also known as per unit change or relative change) and not\n",
      " |          percentage change. If you need the percentage change, multiply\n",
      " |          these values by 100.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'\n",
      " |          How to handle NAs **before** computing percent changes.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |              All options of `fill_method` are deprecated except `fill_method=None`.\n",
      " |\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |\n",
      " |          .. deprecated:: 2.1\n",
      " |\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'ME' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |\n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |\n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |\n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.ffill().pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |\n",
      " |      **DataFrame**\n",
      " |\n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |\n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |\n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |\n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |\n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply chainable functions that expect Series or DataFrames.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      *args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      **kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      the return type of ``func``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.map : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing a income DataFrame from a dictionary.\n",
      " |\n",
      " |      >>> data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n",
      " |      >>> df = pd.DataFrame(data, columns=['Salary', 'Others'])\n",
      " |      >>> df\n",
      " |         Salary  Others\n",
      " |      0    8000  1000.0\n",
      " |      1    9500     NaN\n",
      " |      2    5000  2000.0\n",
      " |\n",
      " |      Functions that perform tax reductions on an income DataFrame.\n",
      " |\n",
      " |      >>> def subtract_federal_tax(df):\n",
      " |      ...     return df * 0.9\n",
      " |      >>> def subtract_state_tax(df, rate):\n",
      " |      ...     return df * (1 - rate)\n",
      " |      >>> def subtract_national_insurance(df, rate, rate_increase):\n",
      " |      ...     new_rate = rate + rate_increase\n",
      " |      ...     return df * (1 - new_rate)\n",
      " |\n",
      " |      Instead of writing\n",
      " |\n",
      " |      >>> subtract_national_insurance(\n",
      " |      ...     subtract_state_tax(subtract_federal_tax(df), rate=0.12),\n",
      " |      ...     rate=0.05,\n",
      " |      ...     rate_increase=0.02)  # doctest: +SKIP\n",
      " |\n",
      " |      You can write\n",
      " |\n",
      " |      >>> (\n",
      " |      ...     df.pipe(subtract_federal_tax)\n",
      " |      ...     .pipe(subtract_state_tax, rate=0.12)\n",
      " |      ...     .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)\n",
      " |      ... )\n",
      " |          Salary   Others\n",
      " |      0  5892.48   736.56\n",
      " |      1  6997.32      NaN\n",
      " |      2  3682.80  1473.12\n",
      " |\n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``national_insurance`` takes its data as ``df``\n",
      " |      in the second argument:\n",
      " |\n",
      " |      >>> def subtract_national_insurance(rate, df, rate_increase):\n",
      " |      ...     new_rate = rate + rate_increase\n",
      " |      ...     return df * (1 - new_rate)\n",
      " |      >>> (\n",
      " |      ...     df.pipe(subtract_federal_tax)\n",
      " |      ...     .pipe(subtract_state_tax, rate=0.12)\n",
      " |      ...     .pipe(\n",
      " |      ...         (subtract_national_insurance, 'df'),\n",
      " |      ...         rate=0.05,\n",
      " |      ...         rate_increase=0.02\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |          Salary   Others\n",
      " |      0  5892.48   736.56\n",
      " |      1  6997.32      NaN\n",
      " |      2  3682.80  1473.12\n",
      " |\n",
      " |  rank(self, axis: 'Axis' = 0, method: \"Literal['average', 'min', 'max', 'first', 'dense']\" = 'average', numeric_only: 'bool_t' = False, na_option: \"Literal['keep', 'top', 'bottom']\" = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'Self'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |\n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |\n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |\n",
      " |      numeric_only : bool, default False\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |\n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |\n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.DataFrameGroupBy.rank : Rank of values within each group.\n",
      " |      core.groupby.SeriesGroupBy.rank : Rank of values within each group.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |\n",
      " |      Ties are assigned the mean of the ranks (by default) for the group.\n",
      " |\n",
      " |      >>> s = pd.Series(range(5), index=list(\"abcde\"))\n",
      " |      >>> s[\"d\"] = s[\"b\"]\n",
      " |      >>> s.rank()\n",
      " |      a    1.0\n",
      " |      b    2.5\n",
      " |      c    4.0\n",
      " |      d    2.5\n",
      " |      e    5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |\n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |\n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |\n",
      " |  reindex_like(self, other, method: \"Literal['backfill', 'bfill', 'pad', 'ffill', 'nearest'] | None\" = None, copy: 'bool_t | None' = None, limit: 'int | None' = None, tolerance=None) -> 'Self'\n",
      " |      Return an object with matching indices as other object.\n",
      " |\n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |\n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |\n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |\n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |\n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |\n",
      " |  replace(self, to_replace=None, value=<no_default>, *, inplace: 'bool_t' = False, limit: 'int | None' = None, regex: 'bool_t' = False, method: \"Literal['pad', 'ffill', 'bfill'] | lib.NoDefault\" = <no_default>) -> 'Self | None'\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |\n",
      " |      Values of the Series/DataFrame are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |\n",
      " |          * numeric, str or regex:\n",
      " |\n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |\n",
      " |          * list of str, regex, or numeric:\n",
      " |\n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |\n",
      " |          * dict:\n",
      " |\n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way, the optional `value`\n",
      " |                parameter should not be given.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The optional `value`\n",
      " |                parameter should not be specified to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |\n",
      " |          * None:\n",
      " |\n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |\n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |\n",
      " |      inplace : bool, default False\n",
      " |          If True, performs operation inplace and returns None.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Object after replacement.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |\n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values.\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      Series.where : Replace values based on boolean condition.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      DataFrame.map: Apply a function to a Dataframe elementwise.\n",
      " |      Series.map: Map values of Series according to an input mapping or function.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5])\n",
      " |      >>> s.replace(1, 5)\n",
      " |      0    5\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |\n",
      " |      **List-like `to_replace`**\n",
      " |\n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |\n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |\n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    3\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |\n",
      " |      **dict-like `to_replace`**\n",
      " |\n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |\n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |\n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |\n",
      " |      **Regular expression `to_replace`**\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |\n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |\n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |\n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |\n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |\n",
      " |      When ``value`` is not explicitly passed and `to_replace` is a scalar, list\n",
      " |      or tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |\n",
      " |      >>> s.replace('a')\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |              The 'method' parameter and padding behavior are deprecated.\n",
      " |\n",
      " |      On the other hand, if ``None`` is explicitly passed for ``value``, it will\n",
      " |      be respected:\n",
      " |\n",
      " |      >>> s.replace('a', None)\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Previously the explicit ``None`` was silently ignored.\n",
      " |\n",
      " |      When ``regex=True``, ``value`` is not ``None`` and `to_replace` is a string,\n",
      " |      the replacement will be applied in all columns of the DataFrame.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'C': ['f', 'g', 'h', 'i', 'j']})\n",
      " |\n",
      " |      >>> df.replace(to_replace='^[a-g]', value='e', regex=True)\n",
      " |          A  B  C\n",
      " |      0  0  e  e\n",
      " |      1  1  e  e\n",
      " |      2  2  e  h\n",
      " |      3  3  e  i\n",
      " |      4  4  e  j\n",
      " |\n",
      " |      If ``value`` is not ``None`` and `to_replace` is a dictionary, the dictionary\n",
      " |      keys will be the DataFrame columns that the replacement will be applied.\n",
      " |\n",
      " |      >>> df.replace(to_replace={'B': '^[a-c]', 'C': '^[h-j]'}, value='e', regex=True)\n",
      " |          A  B  C\n",
      " |      0  0  e  f\n",
      " |      1  1  e  g\n",
      " |      2  2  e  e\n",
      " |      3  3  d  e\n",
      " |      4  4  e  e\n",
      " |\n",
      " |  resample(self, rule, axis: 'Axis | lib.NoDefault' = <no_default>, closed: \"Literal['right', 'left'] | None\" = None, label: \"Literal['right', 'left'] | None\" = None, convention: \"Literal['start', 'end', 's', 'e'] | lib.NoDefault\" = <no_default>, kind: \"Literal['timestamp', 'period'] | None | lib.NoDefault\" = <no_default>, on: 'Level | None' = None, level: 'Level | None' = None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None, group_keys: 'bool_t' = False) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |\n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this parameter\n",
      " |          is unused and defaults to 0. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |\n",
      " |          .. deprecated:: 2.0.0\n",
      " |              Use frame.T.resample(...) instead.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'ME', 'YE', 'QE', 'BME',\n",
      " |          'BA', 'BQE', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'ME', 'YE', 'QE', 'BME',\n",
      " |          'BA', 'BQE', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |              Convert PeriodIndex to DatetimeIndex before resampling instead.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |\n",
      " |          .. deprecated:: 2.2.0\n",
      " |              Convert index to desired type explicitly instead.\n",
      " |\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : Timestamp or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If string, must be one of the following:\n",
      " |\n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |\n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |          .. note::\n",
      " |\n",
      " |              Only takes effect for Tick-frequencies (i.e. fixed frequencies like\n",
      " |              days, hours, and minutes, rather than months or quarters).\n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |\n",
      " |      group_keys : bool, default False\n",
      " |          Whether to include the group keys in the result index when using\n",
      " |          ``.apply()`` on the resampled object.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |              Not specifying ``group_keys`` will retain values-dependent behavior\n",
      " |              from pandas 1.4 and earlier (see :ref:`pandas 1.5.0 Release notes\n",
      " |              <whatsnew_150.enhancements.resample_group_keys>` for examples).\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |\n",
      " |              ``group_keys`` now defaults to ``False``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group Series/DataFrame by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a Series/DataFrame with the given frequency without grouping.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |\n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |\n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='min')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: min, dtype: int64\n",
      " |\n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |\n",
      " |      >>> series.resample('3min').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |\n",
      " |      >>> series.resample('3min', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      To include this value close the right side of the bin interval,\n",
      " |      as shown below.\n",
      " |\n",
      " |      >>> series.resample('3min', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      Upsample the series into 30 second bins.\n",
      " |\n",
      " |      >>> series.resample('30s').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30s, dtype: float64\n",
      " |\n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``ffill`` method.\n",
      " |\n",
      " |      >>> series.resample('30s').ffill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30s, dtype: int64\n",
      " |\n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |\n",
      " |      >>> series.resample('30s').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30s, dtype: int64\n",
      " |\n",
      " |      Pass a custom function via ``apply``\n",
      " |\n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3min').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3min, dtype: int64\n",
      " |\n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |\n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('ME', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |\n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |\n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |\n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |\n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |\n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17min, dtype: int64\n",
      " |\n",
      " |  rolling(self, window: 'int | dt.timedelta | str | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis | lib.NoDefault' = <no_default>, closed: 'IntervalClosedType | None' = None, step: 'int | None' = None, method: 'str' = 'single') -> 'Window | Rolling'\n",
      " |      Provide rolling window calculations.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, timedelta, str, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |\n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |\n",
      " |          If a timedelta, str, or offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |\n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and\n",
      " |          ``step`` will be passed to ``get_window_bounds``.\n",
      " |\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |\n",
      " |          For a window that is specified by an offset, ``min_periods`` will default to 1.\n",
      " |\n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |\n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |\n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |\n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |\n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |\n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |\n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |\n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |\n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |              The axis keyword is deprecated. For ``axis=1``,\n",
      " |              transpose the DataFrame first instead.\n",
      " |\n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |\n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |\n",
      " |          If ``'both'``, the no points in the window are excluded from calculations.\n",
      " |\n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |\n",
      " |          Default ``None`` (``'right'``).\n",
      " |\n",
      " |      step : int, default None\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |          Evaluate the window at every ``step`` result, equivalent to slicing as\n",
      " |          ``[::step]``. ``window`` must be an integer. Using a step argument other\n",
      " |          than None or 1 will produce a result with a different shape than the input.\n",
      " |\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |\n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.api.typing.Window or pandas.api.typing.Rolling\n",
      " |          An instance of Window is returned if ``win_type`` is passed. Otherwise,\n",
      " |          an instance of Rolling is returned.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.generic>` for further usage details\n",
      " |      and examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |\n",
      " |      **window**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 observations.\n",
      " |\n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |\n",
      " |      Rolling sum with a window span of 2 seconds.\n",
      " |\n",
      " |      >>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                        index=[pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                               pd.Timestamp('20130101 09:00:06')])\n",
      " |\n",
      " |      >>> df_time\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |\n",
      " |      >>> df_time.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |\n",
      " |      Rolling sum with forward looking windows with 2 observations.\n",
      " |\n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      **min_periods**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 observations, but only needs a minimum of 1\n",
      " |      observation to calculate a value.\n",
      " |\n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      **center**\n",
      " |\n",
      " |      Rolling sum with the result assigned to the center of the window index.\n",
      " |\n",
      " |      >>> df.rolling(3, min_periods=1, center=True).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  3.0\n",
      " |      3  6.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      >>> df.rolling(3, min_periods=1, center=False).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  6.0\n",
      " |\n",
      " |      **step**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 observations, minimum of 1 observation to\n",
      " |      calculate a value, and a step of 2.\n",
      " |\n",
      " |      >>> df.rolling(2, min_periods=1, step=2).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      2  3.0\n",
      " |      4  4.0\n",
      " |\n",
      " |      **win_type**\n",
      " |\n",
      " |      Rolling sum with a window length of 2, using the Scipy ``'gaussian'``\n",
      " |      window type. ``std`` is required in the aggregation function.\n",
      " |\n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |\n",
      " |      **on**\n",
      " |\n",
      " |      Rolling sum with a window length of 2 days.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'A': [pd.to_datetime('2020-01-01'),\n",
      " |      ...           pd.to_datetime('2020-01-01'),\n",
      " |      ...           pd.to_datetime('2020-01-02'),],\n",
      " |      ...     'B': [1, 2, 3], },\n",
      " |      ...     index=pd.date_range('2020', periods=3))\n",
      " |\n",
      " |      >>> df\n",
      " |                          A  B\n",
      " |      2020-01-01 2020-01-01  1\n",
      " |      2020-01-02 2020-01-01  2\n",
      " |      2020-01-03 2020-01-02  3\n",
      " |\n",
      " |      >>> df.rolling('2D', on='A').sum()\n",
      " |                          A    B\n",
      " |      2020-01-01 2020-01-01  1.0\n",
      " |      2020-01-02 2020-01-01  3.0\n",
      " |      2020-01-03 2020-01-02  6.0\n",
      " |\n",
      " |  sample(self, n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state: 'RandomState | None' = None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'Self'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |\n",
      " |      You can use `random_state` for reproducibility.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0\n",
      " |\n",
      " |              np.random.Generator objects now accepted\n",
      " |\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, â€¦, n - 1.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |\n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |\n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |\n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |\n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |\n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |\n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |\n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |\n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |\n",
      " |  set_flags(self, *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'Self'\n",
      " |      Return a new object with updated flags.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          Specify if a copy of the object should be made.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |\n",
      " |      This method is intended to be used in method chains.\n",
      " |\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |\n",
      " |  shift(self, periods: 'int | Sequence[int]' = 1, freq=None, axis: 'Axis' = 0, fill_value: 'Hashable' = <no_default>, suffix: 'str | None' = None) -> 'Self | DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |\n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int or Sequence\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |          If an iterable of ints, the data will be shifted once by each int.\n",
      " |          This is equivalent to shifting by one value at a time and\n",
      " |          concatenating all resulting frames. The resulting columns will have\n",
      " |          the shift suffixed to their column names. For multiple periods,\n",
      " |          axis must not be 1.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction. For `Series` this parameter is unused and defaults to 0.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      suffix : str, optional\n",
      " |          If str and periods is an iterable, this is added after the column\n",
      " |          name and before the shift value for each shifted column name.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |\n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |\n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |\n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |\n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |\n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |\n",
      " |      >>> df['Col1'].shift(periods=[0, 1, 2])\n",
      " |                  Col1_0  Col1_1  Col1_2\n",
      " |      2020-01-01      10     NaN     NaN\n",
      " |      2020-01-02      20    10.0     NaN\n",
      " |      2020-01-03      15    20.0    10.0\n",
      " |      2020-01-04      30    15.0    20.0\n",
      " |      2020-01-05      45    30.0    15.0\n",
      " |\n",
      " |  squeeze(self, axis: 'Axis | None' = None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |\n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |\n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed. For `Series` this parameter is unused and defaults to `None`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |\n",
      " |      Slicing might produce a Series with a single value:\n",
      " |\n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |\n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |\n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |\n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |\n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |\n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |\n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |\n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |\n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |\n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |\n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |\n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |\n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |\n",
      " |  swapaxes(self, axis1: 'Axis', axis2: 'Axis', copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |\n",
      " |      .. deprecated:: 2.1.0\n",
      " |          ``swapaxes`` is deprecated and will be removed.\n",
      " |          Please use ``transpose`` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same as input\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Please see examples for :meth:`DataFrame.transpose`.\n",
      " |\n",
      " |  tail(self, n: 'int' = 5) -> 'Self'\n",
      " |      Return the last `n` rows.\n",
      " |\n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |\n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `|n|` rows, equivalent to ``df[|n|:]``.\n",
      " |\n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |\n",
      " |      Viewing the last 5 lines\n",
      " |\n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |\n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |\n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |\n",
      " |      For negative values of `n`\n",
      " |\n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |\n",
      " |  take(self, indices, axis: 'Axis' = 0, **kwargs) -> 'Self'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |\n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |\n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |\n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |\n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |\n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |\n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |\n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |\n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |\n",
      " |  to_clipboard(self, *, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |\n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |\n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |\n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_csv.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |\n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - macOS : none\n",
      " |\n",
      " |      This method uses the processes developed for the package `pyperclip`. A\n",
      " |      solution to render any output string format is given in the examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |\n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |\n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |\n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |\n",
      " |      Using the original `pyperclip` package for any string output format.\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |         import pyperclip\n",
      " |         html = df.style.to_html()\n",
      " |         pyperclip.copy(html)\n",
      " |\n",
      " |  to_csv(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'OpenFileErrors' = 'strict', storage_options: 'StorageOptions | None' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string. If a non-binary file object is passed, it should\n",
      " |          be opened with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, Callable, default None\n",
      " |          Format string for floating point numbers. If a Callable is given, it takes\n",
      " |          precedence over other numeric formatting parameters, like decimal.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : {'w', 'x', 'a'}, default 'w'\n",
      " |          Forwarded to either `open(mode=)` or `fsspec.open(mode=)` to control\n",
      " |          the file opening. Typical values include:\n",
      " |\n",
      " |          - 'w', truncate the file first.\n",
      " |          - 'x', exclusive creation, failing if the file already exists.\n",
      " |          - 'a', append to the end of file if it exists.\n",
      " |\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |             May be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |\n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      lineterminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |\n",
      " |          .. versionchanged:: 1.5.0\n",
      " |\n",
      " |              Previously was line_terminator, changed for consistency with\n",
      " |              read_csv and the standard library 'csv' module.\n",
      " |\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create 'out.csv' containing 'df' without indices\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv('out.csv', index=False)  # doctest: +SKIP\n",
      " |\n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |\n",
      " |      To write a csv file to a new folder or nested folder you will first\n",
      " |      need to create it using either Pathlib or os:\n",
      " |\n",
      " |      >>> from pathlib import Path  # doctest: +SKIP\n",
      " |      >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |      >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      " |\n",
      " |      >>> import os  # doctest: +SKIP\n",
      " |      >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |\n",
      " |  to_excel(self, excel_writer: 'FilePath | WriteExcelBuffer | ExcelWriter', *, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'Sequence[Hashable] | bool_t' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, startrow: 'int' = 0, startcol: 'int' = 0, engine: \"Literal['openpyxl', 'xlsxwriter'] | None\" = None, merge_cells: 'bool_t' = True, inf_rep: 'str' = 'inf', freeze_panes: 'tuple[int, int] | None' = None, storage_options: 'StorageOptions | None' = None, engine_kwargs: 'dict[str, Any] | None' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |\n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |\n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer`` or\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |\n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |          .. versionadded:: 1.2.0\n",
      " |      engine_kwargs : dict, optional\n",
      " |          Arbitrary keyword arguments passed to excel engine.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      io.formats.style.Styler.to_excel : Add styles to Excel sheet.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |\n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      Create, write to and save a workbook:\n",
      " |\n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |\n",
      " |      To specify the sheet name:\n",
      " |\n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |\n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |\n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |\n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |\n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |\n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |\n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |\n",
      " |  to_hdf(self, path_or_buf: 'FilePath | HDFStore', *, key: 'str', mode: \"Literal['a', 'w', 'r+']\" = 'a', complevel: 'int | None' = None, complib: \"Literal['zlib', 'lzo', 'bzip2', 'blosc'] | None\" = None, append: 'bool_t' = False, format: \"Literal['fixed', 'table'] | None\" = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'OpenFileErrors' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |\n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |\n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |\n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |\n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, default None\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 or None disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          These additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |\n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\".\n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      dropna : bool, default False, optional\n",
      " |          Remove missing values.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See\n",
      " |          :ref:`Query via data columns<io.hdf5-query-data-columns>`. for\n",
      " |          more information.\n",
      " |          Applicable only to format='table'.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_orc : Write a DataFrame to the binary orc format.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])  # doctest: +SKIP\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')  # doctest: +SKIP\n",
      " |\n",
      " |      We can add another object to the same file:\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])  # doctest: +SKIP\n",
      " |      >>> s.to_hdf('data.h5', key='s')  # doctest: +SKIP\n",
      " |\n",
      " |      Reading from HDF file:\n",
      " |\n",
      " |      >>> pd.read_hdf('data.h5', 'df')  # doctest: +SKIP\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')  # doctest: +SKIP\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |\n",
      " |  to_json(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, orient: \"Literal['split', 'records', 'index', 'table', 'columns', 'values'] | None\" = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'TimeUnit' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t | None' = None, indent: 'int | None' = None, storage_options: 'StorageOptions | None' = None, mode: \"Literal['a', 'w']\" = 'w') -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |\n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |\n",
      " |          * Series:\n",
      " |\n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |\n",
      " |          * DataFrame:\n",
      " |\n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |\n",
      " |          * The format of the JSON string:\n",
      " |\n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |\n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |\n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values. The possible maximal value is 15.\n",
      " |          Passing double_precision greater than 15 will raise a ValueError.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |\n",
      " |      index : bool or None, default None\n",
      " |          The index is only used when 'orient' is 'split', 'index', 'column',\n",
      " |          or 'table'. Of these, 'index' and 'column' do not support\n",
      " |          `index=False`.\n",
      " |\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      mode : str, default 'w' (writing)\n",
      " |          Specify the IO mode for output when supplying a path_or_buf.\n",
      " |          Accepted args are 'w' (writing) and 'a' (append) only.\n",
      " |          mode='a' is only supported when lines is True and orient is 'records'.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |\n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from json import loads, dumps\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |\n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |\n",
      " |      Encoding with Table Schema:\n",
      " |\n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"1.4.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |\n",
      " |  to_latex(self, buf: 'FilePath | WriteBuffer[str] | None' = None, *, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | SequenceNotStr[str]' = True, index: 'bool_t' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool_t | None' = None, index_names: 'bool_t' = True, bold_rows: 'bool_t' = False, column_format: 'str | None' = None, longtable: 'bool_t | None' = None, escape: 'bool_t | None' = None, encoding: 'str | None' = None, decimal: 'str' = '.', multicolumn: 'bool_t | None' = None, multicolumn_format: 'str | None' = None, multirow: 'bool_t | None' = None, caption: 'str | tuple[str, str] | None' = None, label: 'str | None' = None, position: 'str | None' = None) -> 'str | None'\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table.\n",
      " |\n",
      " |      Requires ``\\usepackage{{booktabs}}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{{table.tex}}``.\n",
      " |\n",
      " |      .. versionchanged:: 2.0.0\n",
      " |         Refactored to use the Styler implementation via jinja2 templating.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {{str: function}}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{{:0.2f}}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{{longtable}} to your LaTeX preamble.\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module, and set to `True` if the option ``styler.latex.environment`` is\n",
      " |          `\"longtable\"`.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module and set to `True` if the option ``styler.format.escape`` is\n",
      " |          `\"latex\"`. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to `False`.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module, and is set\n",
      " |          as the option ``styler.sparse.columns``.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed.\n",
      " |      multicolumn_format : str, default 'r'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module, and is set as the option\n",
      " |          ``styler.latex.multicol_align``.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to \"r\".\n",
      " |      multirow : bool, default True\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{{multirow}} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module, and is set as the option\n",
      " |          ``styler.sparse.index``.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to `True`.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{{full_caption}}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{{}}`` in the output.\n",
      " |          This is used with ``\\ref{{}}`` in the main ``.tex`` file.\n",
      " |\n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{{}}`` in the output.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler.to_latex : Render a DataFrame to LaTeX\n",
      " |          with conditional formatting.\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      As of v2.0.0 this method has changed to use the Styler implementation as\n",
      " |      part of :meth:`.Styler.to_latex` via ``jinja2`` templating. This means\n",
      " |      that ``jinja2`` is a requirement, and needs to be installed, for this method\n",
      " |      to function. It is advised that users switch to using Styler, since that\n",
      " |      implementation is more frequently updated and contains much more\n",
      " |      flexibility with the output.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Convert a general DataFrame to LaTeX with formatting:\n",
      " |\n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                        age=[26, 45],\n",
      " |      ...                        height=[181.23, 177.65]))\n",
      " |      >>> print(df.to_latex(index=False,\n",
      " |      ...                   formatters={\"name\": str.upper},\n",
      " |      ...                   float_format=\"{:.1f}\".format,\n",
      " |      ... ))  # doctest: +SKIP\n",
      " |      \\begin{tabular}{lrr}\n",
      " |      \\toprule\n",
      " |      name & age & height \\\\\n",
      " |      \\midrule\n",
      " |      RAPHAEL & 26 & 181.2 \\\\\n",
      " |      DONATELLO & 45 & 177.7 \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |\n",
      " |  to_pickle(self, path: 'FilePath | WriteBuffer[bytes]', *, compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions | None' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. File path where\n",
      " |          the pickled object will be stored.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |\n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})  # doctest: +SKIP\n",
      " |      >>> original_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |\n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      >>> unpickled_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |\n",
      " |  to_sql(self, name: 'str', con, *, schema: 'str | None' = None, if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail', index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, chunksize: 'int | None' = None, dtype: 'DtypeArg | None' = None, method: \"Literal['multi'] | Callable | None\" = None) -> 'int | None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |\n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable. See `here                 <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
      " |          If passing a sqlalchemy.engine.Connection which is already in a transaction,\n",
      " |          the transaction will not be committed.  If passing a sqlite3.Connection,\n",
      " |          it will not be possible to roll back the record insertion.\n",
      " |\n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |\n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |\n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table. Creates a table index for this column.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |\n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |\n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or int\n",
      " |          Number of rows affected by to_sql. None is returned if the callable\n",
      " |          passed into ``method`` does not return an integer number of rows.\n",
      " |\n",
      " |          The number of returned rows affected is the sum of the ``rowcount``\n",
      " |          attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
      " |          reflect the exact number of written rows as stipulated in the\n",
      " |          `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      " |          `SQLAlchemy <https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.CursorResult.rowcount>`__.\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |\n",
      " |      Not all datastores support ``method=\"multi\"``. Oracle, for example,\n",
      " |      does not support multi-value insert.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |\n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |\n",
      " |      Create a table from scratch with 3 rows.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |\n",
      " |      >>> df.to_sql(name='users', con=engine)\n",
      " |      3\n",
      " |      >>> from sqlalchemy import text\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |\n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |\n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql(name='users', con=connection, if_exists='append')\n",
      " |      2\n",
      " |\n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql(name='users', con=engine, if_exists='append')\n",
      " |      2\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |\n",
      " |      Overwrite the table with just ``df2``.\n",
      " |\n",
      " |      >>> df2.to_sql(name='users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      2\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |\n",
      " |      Use ``method`` to define a callable insertion method to do nothing\n",
      " |      if there's a primary key conflict on a table in a PostgreSQL database.\n",
      " |\n",
      " |      >>> from sqlalchemy.dialects.postgresql import insert\n",
      " |      >>> def insert_on_conflict_nothing(table, conn, keys, data_iter):\n",
      " |      ...     # \"a\" is the primary key in \"conflict_table\"\n",
      " |      ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
      " |      ...     stmt = insert(table.table).values(data).on_conflict_do_nothing(index_elements=[\"a\"])\n",
      " |      ...     result = conn.execute(stmt)\n",
      " |      ...     return result.rowcount\n",
      " |      >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_nothing)  # doctest: +SKIP\n",
      " |      0\n",
      " |\n",
      " |      For MySQL, a callable to update columns ``b`` and ``c`` if there's a conflict\n",
      " |      on a primary key.\n",
      " |\n",
      " |      >>> from sqlalchemy.dialects.mysql import insert\n",
      " |      >>> def insert_on_conflict_update(table, conn, keys, data_iter):\n",
      " |      ...     # update columns \"b\" and \"c\" on primary key conflict\n",
      " |      ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
      " |      ...     stmt = (\n",
      " |      ...         insert(table.table)\n",
      " |      ...         .values(data)\n",
      " |      ...     )\n",
      " |      ...     stmt = stmt.on_duplicate_key_update(b=stmt.inserted.b, c=stmt.inserted.c)\n",
      " |      ...     result = conn.execute(stmt)\n",
      " |      ...     return result.rowcount\n",
      " |      >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_update)  # doctest: +SKIP\n",
      " |      2\n",
      " |\n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |\n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql(name='integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      3\n",
      " |\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...   conn.execute(text(\"SELECT * FROM integers\")).fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |\n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |\n",
      " |      >>> df.to_xarray()  # doctest: +SKIP\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 32B 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 32B 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 32B 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 32B 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 32B 2 2 4 4\n",
      " |\n",
      " |      >>> df['max_speed'].to_xarray()  # doctest: +SKIP\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |\n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |\n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |\n",
      " |      >>> df_multiindex.to_xarray()  # doctest: +SKIP\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (date: 2, animal: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |\n",
      " |  truncate(self, before=None, after=None, axis: 'Axis | None' = None, copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |\n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |\n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |\n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |\n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |\n",
      " |      For Series, only rows can be truncated.\n",
      " |\n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |\n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |\n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |\n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |\n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |\n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |\n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |\n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |\n",
      " |  tz_convert(self, tz, axis: 'Axis' = 0, level=None, copy: 'bool_t | None' = None) -> 'Self'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object or None\n",
      " |          Target time zone. Passing ``None`` will convert to\n",
      " |          UTC and remove the timezone information.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Object with time zone converted axis.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Change to another time zone:\n",
      " |\n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),\n",
      " |      ... )\n",
      " |      >>> s.tz_convert('Asia/Shanghai')\n",
      " |      2018-09-15 07:30:00+08:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Pass None to convert to UTC and get a tz-naive index:\n",
      " |\n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))\n",
      " |      >>> s.tz_convert(None)\n",
      " |      2018-09-14 23:30:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |  tz_localize(self, tz, axis: 'Axis' = 0, level=None, copy: 'bool_t | None' = None, ambiguous: 'TimeAmbiguous' = 'raise', nonexistent: 'TimeNonexistent' = 'raise') -> 'Self'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |\n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo or None\n",
      " |          Time zone to localize. Passing ``None`` will remove the\n",
      " |          time zone information and preserve local time.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |\n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Same type as the input.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |\n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),\n",
      " |      ... )\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Pass None to convert to tz-naive index and preserve local time:\n",
      " |\n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))\n",
      " |      >>> s.tz_localize(None)\n",
      " |      2018-09-15 01:30:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |\n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |\n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |\n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |\n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |\n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1h'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |\n",
      " |  where(self, cond, other=nan, *, inplace: 'bool_t' = False, axis: 'Axis | None' = None, level: 'Level | None' = None) -> 'Self | None'\n",
      " |      Replace values where the condition is False.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |          If not specified, entries will be filled with the corresponding\n",
      " |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension\n",
      " |          dtypes).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      False.\n",
      " |\n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |\n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |\n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |\n",
      " |  xs(self, key: 'IndexLabel', axis: 'Axis' = 0, level: 'IndexLabel | None' = None, drop_level: 'bool_t' = True) -> 'Self'\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |\n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |\n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |\n",
      " |      Get values at specified index\n",
      " |\n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |\n",
      " |      Get values at several indexes\n",
      " |\n",
      " |      >>> df.xs(('mammal', 'dog', 'walks'))\n",
      " |      num_legs     4\n",
      " |      num_wings    0\n",
      " |      Name: (mammal, dog, walks), dtype: int64\n",
      " |\n",
      " |      Get values at specified index and level\n",
      " |\n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |\n",
      " |      Get values at several indexes and levels\n",
      " |\n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |\n",
      " |      Get values at specified column and axis\n",
      " |\n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |\n",
      " |      The available flags are\n",
      " |\n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |\n",
      " |      Flags can be get or set using ``.``\n",
      " |\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |\n",
      " |      Or by slicing with a key\n",
      " |\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |\n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         attrs is experimental and may change without warning.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Many operations that create new datasets will copy ``attrs``. Copies\n",
      " |      are always deep so that changing ``attrs`` will only affect the\n",
      " |      present dataset. ``pandas.concat`` copies ``attrs`` only if all input\n",
      " |      datasets have the same ``attrs``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> ser.attrs = {\"A\": [10, 20, 30]}\n",
      " |      >>> ser.attrs\n",
      " |      {'A': [10, 20, 30]}\n",
      " |\n",
      " |      For DataFrame:\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
      " |      >>> df.attrs = {\"A\": [10, 20, 30]}\n",
      " |      >>> df.attrs\n",
      " |      {'A': [10, 20, 30]}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |\n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |\n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |\n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |\n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If getting a value and 'label' does not exist in a DataFrame or Series.\n",
      " |\n",
      " |      ValueError\n",
      " |          If row/column label pair is not a tuple or if any label\n",
      " |          from the pair is not a scalar for DataFrame.\n",
      " |          If label is list-like (*excluding* NamedTuple) for Series.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column pair by label.\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer\n",
      " |          position(s).\n",
      " |      Series.at : Access a single value by label.\n",
      " |      Series.iat : Access a single value by integer position.\n",
      " |      Series.loc : Access a group of rows by label(s).\n",
      " |      Series.iloc : Access a group of rows by integer position(s).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Fast scalar value getting and setting <indexing.basics.get_value>`\n",
      " |      for more details.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |\n",
      " |      Get value at specified row/column pair\n",
      " |\n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |\n",
      " |      Set value at specified row/column pair\n",
      " |\n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |\n",
      " |      Get value within a Series\n",
      " |\n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |\n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |\n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |\n",
      " |      Get value at specified row/column pair\n",
      " |\n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |\n",
      " |      Set value at specified row/column pair\n",
      " |\n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |\n",
      " |      Get value within a series\n",
      " |\n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |\n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |\n",
      " |      .. deprecated:: 2.2.0\n",
      " |\n",
      " |         Returning a tuple from a callable is deprecated.\n",
      " |\n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |\n",
      " |      Allowed inputs are:\n",
      " |\n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on\n",
      " |        some value.\n",
      " |      - A tuple of row and column indexes. The tuple elements consist of one of the\n",
      " |        above inputs, e.g. ``(0, 1)``.\n",
      " |\n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |\n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      **Indexing just the rows**\n",
      " |\n",
      " |      With a scalar integer.\n",
      " |\n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |\n",
      " |      With a list of integers.\n",
      " |\n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |\n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |\n",
      " |      With a `slice` object.\n",
      " |\n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      With a boolean mask the same length as the index.\n",
      " |\n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |\n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |\n",
      " |      **Indexing both axes**\n",
      " |\n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |\n",
      " |      With scalar integers.\n",
      " |\n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |\n",
      " |      With lists of integers.\n",
      " |\n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |\n",
      " |      With `slice` objects.\n",
      " |\n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |\n",
      " |      With a boolean array whose length matches the columns.\n",
      " |\n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |\n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |\n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |\n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |\n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |\n",
      " |      Allowed inputs are:\n",
      " |\n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |\n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |\n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |\n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |                     Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...                   index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...                   columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |\n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |\n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |\n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Single label for row and column\n",
      " |\n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |\n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |\n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |\n",
      " |      Boolean list with the same length as the row axis\n",
      " |\n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Alignable boolean Series:\n",
      " |\n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...                  index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                           max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |\n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |\n",
      " |      Conditional that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |\n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |\n",
      " |      Multiple conditional using ``&`` that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[(df['max_speed'] > 1) & (df['shield'] < 8)]\n",
      " |                  max_speed  shield\n",
      " |      viper          4       5\n",
      " |\n",
      " |      Multiple conditional using ``|`` that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[(df['max_speed'] > 4) | (df['shield'] < 5)]\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      Please ensure that each condition is wrapped in parentheses ``()``.\n",
      " |      See the :ref:`user guide<indexing.boolean>`\n",
      " |      for more details and explanations of Boolean indexing.\n",
      " |\n",
      " |      .. note::\n",
      " |          If you find yourself using 3 or more conditionals in ``.loc[]``,\n",
      " |          consider using :ref:`advanced indexing<advanced.advanced_hierarchical>`.\n",
      " |\n",
      " |          See below for using ``.loc[]`` on MultiIndex DataFrames.\n",
      " |\n",
      " |      Callable that returns a boolean Series\n",
      " |\n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |\n",
      " |      **Setting values**\n",
      " |\n",
      " |      Set value for all items matching the list of labels\n",
      " |\n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |\n",
      " |      Set value for an entire row\n",
      " |\n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |\n",
      " |      Set value for an entire column\n",
      " |\n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |\n",
      " |      Set value for rows matching callable condition\n",
      " |\n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |\n",
      " |      Add value matching location\n",
      " |\n",
      " |      >>> df.loc[\"viper\", \"shield\"] += 5\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       5\n",
      " |      sidewinder          0       0\n",
      " |\n",
      " |      Setting using a ``Series`` or a ``DataFrame`` sets the values matching the\n",
      " |      index labels, not the index positions.\n",
      " |\n",
      " |      >>> shuffled_df = df.loc[[\"viper\", \"cobra\", \"sidewinder\"]]\n",
      " |      >>> df.loc[:] += shuffled_df\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              60      20\n",
      " |      viper               0      10\n",
      " |      sidewinder          0       0\n",
      " |\n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |\n",
      " |      Another example using integers for the index\n",
      " |\n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...                   index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |\n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |\n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |\n",
      " |      **Getting values with a MultiIndex**\n",
      " |\n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |\n",
      " |      >>> tuples = [\n",
      " |      ...     ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...     ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...     ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...           [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |\n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |\n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |\n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |\n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |\n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |\n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |\n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |\n",
      " |      Single tuple for the index with a single label for the column\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |\n",
      " |      Slice from index tuple to single label\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |\n",
      " |      Slice from index tuple to index tuple\n",
      " |\n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |\n",
      " |      Please see the :ref:`user guide<advanced.advanced_hierarchical>`\n",
      " |      for more details and explanations of advanced indexing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "1333    False\n",
       "1334    False\n",
       "1335    False\n",
       "1336    False\n",
       "1337    False\n",
       "Name: region, Length: 1338, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.notna of 0             NaN\n",
       "1             NaN\n",
       "2             NaN\n",
       "3             NaN\n",
       "4             NaN\n",
       "          ...    \n",
       "1333    northwest\n",
       "1334    northeast\n",
       "1335    southeast\n",
       "1336    southwest\n",
       "1337    northwest\n",
       "Name: region, Length: 1338, dtype: object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region'].notna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338 values are 0 missing values\n",
      "1338 values are 0 missing values\n",
      "1337 values are 1 missing values\n",
      "1338 values are 0 missing values\n",
      "1338 values are 0 missing values\n",
      "1316 values are 22 missing values\n",
      "1338 values are 0 missing values\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(df[col].notna().sum(),\"values are\",df[col].isna().sum(),\"missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of df: 1338\n",
      "age         0.000000\n",
      "sex         0.000000\n",
      "bmi         0.074738\n",
      "children    0.000000\n",
      "smoker      0.000000\n",
      "region      1.644245\n",
      "charges     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of df:\", len(df))\n",
    "percentageOfMissingValues_DF = (df.isnull().sum() / len(df)) * 100\n",
    "print(percentageOfMissingValues_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi 0.06999999999999999\n",
      "region 1.6400000000000001\n",
      "There is no missing values in other columns of  this DF\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    if df[col].isnull().mean()>0:\n",
    "        print(col, round(df[col].isnull().mean(),4)*100)\n",
    "else:\n",
    "    print(\"There is no missing values in other columns of  this DF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       4\n",
       "2       4\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "1333    4\n",
       "1334    4\n",
       "1335    4\n",
       "1336    4\n",
       "1337    4\n",
       "Length: 1338, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(axis=1,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.corr of 0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "5     3756.62160\n",
       "6     8240.58960\n",
       "7     7281.50560\n",
       "8     6406.41070\n",
       "9    28923.13692\n",
       "Name: charges, dtype: float64>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['charges'][:10].corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D  E\n",
      "0   1   2   3   4  5\n",
      "1  13  24  55  66  1\n",
      "2   3   2  45   6  7\n"
     ]
    }
   ],
   "source": [
    "data=np.array([[1,2,3,4,5],[13,24,55,66,1],[3,2,45,6,7]])\n",
    "df=pd.DataFrame(data=data,columns=list(\"ABCDE\"))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.987829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B\n",
       "A  1.000000  0.987829\n",
       "B  0.987829  1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=df[['A','B']].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='A',y='B',)\n",
    "plt.xlabel(\"A\")\n",
    "plt.ylabel(\"B\")\n",
    "\n",
    "plt.title(\"The correlation diagram chart\")\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(1,4,.5))\n",
    "plt.yticks(np.arange(1,25,1))\n",
    "plt.grid(visible=True)\n",
    "plt.show()\n",
    "plt.figure(figsize=(5,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATPLOTLIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAADLCAYAAACF352YAAAAPXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjByYzEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvGVCRmQAAAAlwSFlzAAAPYQAAD2EBqD+naQAAD8xJREFUeJzt3X1MVHe+BvBnBsPAtcOIBlKRAQlrS6HSeKPpBdq4rVZjuK6a1aZEs1TcTbedFm3TbuE21r6sHbz10t40DRG7S9kqJU0raJP1BXoLXEONoLXRXq8vrUVaUkmaOjNSnbLM2T+moiAD/GbO+3k+ySQ9cGbOt4eZxzNnnpmxSZIkgYgsza71AESkPQYBETEIiIhBQERgEBARGAREBAYBEQGYovYGQ6EQ+vr64HQ6YbPZ1N48kaVIkoRAIIC0tDTY7ZH/3Vc9CPr6+uB2u9XeLJGl9fb2Ij09PeLvVQ8Cp9MZ/o+nATjU3jqRxQQBvHHT4y4C1YNg+OmAA0CC2lsnsqaJnobzZCERiQXB0NAQNm/ejKysLCQmJiI7Oxuvvvoq+L4lImMTemqwbds21NTUoL6+Hnl5eeju7sb69evhcrlQXl6u1IxEpDChIOjs7MSKFStQXFwMAJg9ezbef/99HD16VJHhiOhW064Cb/0deO1+4HSqPLcp9NSgsLAQn3zyCc6ePQsA+OKLL3D48GEsW7Ys4nWCwSD8fv+ICxFFp6gH+KIGWHcS+FsTAJmelQsdEVRUVMDv9yMnJwdxcXEYGhrC1q1bsXbt2ojX8Xq9ePnll2MelMjK7CHghQ5gSzsQJwHnk4HH/x2ATJ08oSOCDz74ALt370ZDQwOOHz+O+vp6bN++HfX19RGvU1lZCZ/PN3zp7e2NeWgiK5nlA/6nHnilLRwC7+UD8/4IdM+SbxtCRwTPPfccKioq8MgjjwAA5s6di56eHni9XpSWlo55HYfDAYeDzSGiaKw4DfxlHzDjKhCIB54oBnbdI/92hILgp59+uqWvHBcXh1AoJOtQRFaXMAhsPwR4usLL3TOBktXA+RnKbE8oCJYvX46tW7ciIyMDeXl5+Pzzz1FdXY2ysjJlpiOyoNx+oPFDYG5/ePn1QuCFB4FBBXvAQjf91ltvYfPmzXjiiSfQ39+PtLQ0PPbYY3jxxReVmo/IOiTgD8eANw8A//IP4NJU4HergEO/Un7TNrU/ztzv98PlcgEV4HsNiH4x7Sqwcx+w+nR4+WA2ULoSuDT+e4Umdg1AFeDz+ZCUlBRxNdXfdEREIxX1AA0fARl+YNAOVC4CqgsAScV3AjEIiDQyVjegZLW8LwtOFoOASAOzfMDuPcDCnvDye/nhlwavaPRKO4OASGVqdQNEMAiIVKJ2N0AEg4BIBVp0A0ToZAwik9KwGyCCQUCkEMW6AQpgEBApQA/dABEMAiIZ6akbIIJBQCQTvXUDRDAIiGSgx26ACAYBUQz03A0QwSAgipLeuwEiDDgykcYM0g0QwSAgEmCkboAIBgHRJBmtGyCCQUA0AaN2A0QwCIjGYeRugAgGAVEERu8GiGAQEI1ilm6ACAYB0U3M1A0QYfL/PaJJMmE3QASDgCzPrN0AEQwCsjQzdwNEMAjIkqzQDRDBICDLsUo3QASDgCzFSt0AEQwCsgQrdgNEMAjI9KzaDRDBXUHmZfFugAgGAZkSuwFiGARkOuwGiGMQkGmwGxA9BgGZArsBsWEQkOGxGxA7BgEZFrsB8hE6fTJ79mzYbLZbLh6PR6n5iMaU2w8c3XkjBF4vBAo3MASiJXRE0NXVhaGhoeHlU6dO4aGHHsKaNWtkH4xoTOwGKEIoCFJSUkYsV1VVITs7GwsXLpR1KKKxsBugnKjPEfz888/YtWsXnnnmGdhstojrBYNBBIPB4WW/3x/tJsnCinrCrwpk+tgNUELUu7G5uRmXL1/Go48+Ou56Xq8XLpdr+OJ2u6PdJFmQPQRsbgPa3w2HwPnk8LmA/ypiCMjJJkmSFM0Vly5divj4eHz88cfjrjfWEYHb7QYqACREs2WyCnYDZHANQBXg8/mQlJQUcbWonhr09PSgtbUVe/bsmXBdh8MBh4N/ORLDboC6ogqCuro6pKamori4WO55yOLYDdCGcBCEQiHU1dWhtLQUU6awj0Ty4ecGaEd4F7e2tuLixYsoKytTYh6yInYDNCccBEuWLEGU5xeJbsFugD7woIs0w88N0A8GAamOnxugPwwCUhW7AfrEICDVsBugXwwCUhy7AfrHICBFsRtgDPxzkDLYDTAUBgHJjt0A42EQkKzYDTAmBgHJwh4C/uN/gZfa2A0wIgYBxWyWD9i1B/g1uwGGxSCgmPzm/4G/7mU3wOgYBBSVhEHg9UPAk+wGmAKDgITd9Us3IJ/dANPgn44mj90A02IQ0KRMuwrUfgys+b/wMrsB5sIgoAkVXgx3A/idAubFIKCI2A2wDgYBjYndAGthENAt2A2wHgYBDWM3wLoYBASA3QCr45/Z6tgNIDAILI3dALqOQWBR7AbQzRgEFsNuAI2FQWAh7AZQJAwCi2A3gMbDIDA5dgNoMhgEJsZuAE0W7xJmxG4ACWIQmMzobsCBbKB0FdB/m7Zzkb4xCEzk5m7Az3agcjHwxr+xG0ATYxCYwOhuwLnpQMlvgWPsBtAkMQgMbnQ34G/5gIfdABLEIDAwdgNILgwCA3IMAq+3AE8dDS93pYWfCnzFbgBFiUFgMOwGkBKEzyd/9913WLduHWbMmIHExETMnTsX3d3dSsxGN5OA3x8DumvDIXBpKrB0HfCnJQwBip3QXejHH39EUVERHnjgAezfvx8pKSk4d+4ckpOTlZqPwG4AKU8oCLZt2wa32426urrhn2VlZck+FN1QcBF4n90AUpjQ3Wnfvn2YP38+1qxZg9TUVMybNw87d+4c9zrBYBB+v3/EhSZmDwEvtAMddeEQODcdKNwAVBcyBEh+Qnepr7/+GjU1NZgzZw4OHjyIxx9/HOXl5aivr494Ha/XC5fLNXxxu90xD212s3zAJ/XAnz8Fpkjhzw3418dYECLl2CRJkia7cnx8PObPn4/Ozs7hn5WXl6OrqwufffbZmNcJBoMIBoPDy36/PxwGFQASoh/crNgNIFldA1AF+Hw+JCUlRVxN6BzBzJkzkZubO+Jnd911Fz766KOI13E4HHA4WHObCLsBpCWhICgqKsKZM2dG/Ozs2bPIzMyUdSirYTeAtCZ0V3v66adRWFiI1157DQ8//DCOHj2K2tpa1NbWKjWfuUnA748D/72fnxtA2hIKggULFqCpqQmVlZV45ZVXkJWVhTfffBNr165Vaj7TYjeA9EToZKEc/H4/XC6XpU8W8nMDSDVKnCyk2PBzA0ivGAQq4ecGkJ4xCFTAbgDpHYNAQaO/U4DdANIrBoFC2A0gI+HdUm78TgEyIAaBjNgNIKNiEMiE3QAyMgZBjNgNIDNgEMRgdDfgvfzwS4PsBpDRMAiixG4AmQmDQNDobkD3TKBkNXCe3QAyMAaBAHYDyKx4F54MdgPI5BgEExjdDTiYDZSuBC45NR2LSFYMgnHc3A0YtAOVi4DqAnYDyHwYBGMY3Q04nxw+IdjNbgCZFINgFHYDyIoYBDdhN4CsikEAdgOILB8E7AYQWTkI2A0gGmbJIJh2Fdi5D1h9OrzMbgBZneWCoKgn3A3I8LMbQHSdZYLAHgJe6AC2tLMbQDSaJYJglg/YvQdYyG4A0ZhMHwQrTgN/2cduANF4TBsECYPA9kOAh90AogmZMghyf+kGzGU3gGhSzPXQYDeAKCqmCQJ2A4iiZ4ogYDeAKDaGDgJ2A4jkYdggYDeASD6GDAJ2A4jkZaggYDeASBmGCQJ2A4iUI3Re/aWXXoLNZhtxycnJUWq2MAn4QzfQVRsOgUtTgaXrgD8tYQgQyUX4oZSXl4fW1tYbNzBFuUcjuwFE6hB+FE+ZMgW33367ErOMwG4AkXqEg+DcuXNIS0tDQkICCgoK4PV6kZGREXH9YDCIYDA4vOz3+yfcxjOdwH+2sBtApBahf1/vvfdevPvuuzhw4ABqampw4cIF3H///QgEAhGv4/V64XK5hi9ut3vC7Vx0hUPgvXxg3h8ZAkRKs0mSJEV75cuXLyMzMxPV1dXYsGHDmOuMdUTgdruBCgAJkW+74CLwWeQDDSKajGsAqgCfz4ekpKSIq8V0pm/atGm44447cP78+YjrOBwOOBzidT+GAJF6Yjr1duXKFXz11VeYOXOmXPMQkQaEguDZZ59Fe3s7vvnmG3R2dmLVqlWIi4tDSUmJUvMRkQqEnhp8++23KCkpwQ8//ICUlBTcd999OHLkCFJSUpSaj4hUIBQEjY2NMW9w+NxkcPz1iEgGvzzOJnpNQPWS7vBLjW+ovWUi6woEAnC5XBF/H9PLh9EIhULo6+uD0+mEzWaLuN71lxl7e3vHfdnD7LgfbuC+uGGy+0KSJAQCAaSlpcFuj3xKUPUjArvdjvT09Emvn5SUZPk/OsD9cDPuixsmsy/GOxK4js19ImIQEJGOg8DhcGDLli1RtRLNhPvhBu6LG+TeF6qfLCQi/dHtEQERqYdBQEQMAiJiEBARGAREBB0GQUdHB5YvX460tDTYbDY0NzdrPZImvF4vFixYAKfTidTUVKxcuRJnzpzReixN1NTUID8/f7hFV1BQgP3792s9luaqqqpgs9mwadOmmG9Ld0EwMDCAe+65B2+//bbWo2iqvb0dHo8HR44cQUtLCwYHB7FkyRIMDAxoPZrq0tPTUVVVhWPHjqG7uxsPPvggVqxYgS+//FLr0TTT1dWFHTt2ID8/X54blHQMgNTU1KT1GLrQ398vAZDa29u1HkUXkpOTpXfeeUfrMTQRCASkOXPmSC0tLdLChQuljRs3xnybujsioLH5fD4AwPTp0zWeRFtDQ0NobGzEwMAACgoKtB5HEx6PB8XFxVi8eLFst8kvDTOAUCiETZs2oaioCHfffbfW42ji5MmTKCgowLVr13DbbbehqakJubm5Wo+lusbGRhw/fhxdXV2y3i6DwAA8Hg9OnTqFw4cPaz2KZu68806cOHECPp8PH374IUpLS9He3m6pMOjt7cXGjRvR0tKChIRxvgsgCrp+r4HNZkNTUxNWrlyp9SiaefLJJ7F37150dHQgKytL63F0Y/HixcjOzsaOHTu0HkU1zc3Nwx8YfN3Q0BBsNhvsdjuCweCI34ngEYFOSZKEp556Ck1NTWhra2MIjBIKhUZ8cY4VLFq0CCdPnhzxs/Xr1yMnJwfPP/981CEA6DAIrly5MuILUy5cuIATJ05g+vTp437Hotl4PB40NDRg7969cDqd+P777wGEP20mMTFR4+nUVVlZiWXLliEjIwOBQAANDQ1oa2vDwYMHtR5NVU6n85ZzRFOnTsWMGTNiP3cU8+sOMvv0008lALdcSktLtR5NVWPtAwBSXV2d1qOprqysTMrMzJTi4+OllJQUadGiRdKhQ4e0HksX5Hr5UNfnCIhIHewREBGDgIgYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARGAQEBEYBEQE4J88vUwaD6r8twAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1100x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure(figsize=(11,8),facecolor=\"white\")\n",
    "ax1=fig.add_axes([.1,.2,.2,.2],facecolor='g',frameon=True)\n",
    "ax1.plot([1,2,3,4],[5,6,7,8],color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19    male     NaN         0    yes        NaN  16884.92400\n",
       "1      18    male  33.770         1     no        NaN   1725.55230\n",
       "2      28    male  33.000         3     no        NaN   4449.46200\n",
       "3      33    male  22.705         0     no        NaN  21984.47061\n",
       "4      32    male  28.880         0     no        NaN   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1,2,],[20,30,],scalex=True,scaley=True)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "a=np.arange(0,math.pi*2,0.5)\n",
    "x=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.47942554  0.84147098  0.99749499  0.90929743  0.59847214\n",
      "  0.14112001 -0.35078323 -0.7568025  -0.97753012 -0.95892427 -0.70554033\n",
      " -0.2794155 ]\n"
     ]
    }
   ],
   "source": [
    "y = np.sin(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The data Labeled Chart')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,)\n",
    "# plt.figure(facecolor=\"r\")\n",
    "plt.xlabel(\"Centimeters\")\n",
    "plt.ylabel(\"TN Rain Forecast\")\n",
    "plt.title(\"The data Labeled Chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
